

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="Description" content="scikit-learn: machine learning in Python">

  
  <title>sklearn.linear_model.ElasticNet &mdash; scikit-learn 0.22 documentation</title>
  
  <link rel="canonical" href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html" />

  
  <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  

  <link rel="stylesheet" href="../../_static/css/vendor/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
<script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
<script src="../../_static/jquery.js"></script> 
</head>
<body>
<nav id="navbar" class="sk-docs-navbar navbar navbar-expand-md navbar-light bg-light py-0">
  <div class="container-fluid sk-docs-container px-0">
      <a class="navbar-brand py-0" href="../../index.html">
        <img
          class="sk-brand-img"
          src="../../_static/scikit-learn-logo-small.png"
          alt="logo"/>
      </a>
    <button
      id="sk-navbar-toggler"
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="sk-navbar-collapse collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../install.html">Install</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../user_guide.html">User Guide</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../classes.html">API</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../auto_examples/index.html">Examples</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../getting_started.html">Getting Started</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../tutorial/index.html">Tutorial</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../glossary.html">Glossary</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../developers/index.html">Development</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../faq.html">FAQ</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../related_projects.html">Related packages</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../roadmap.html">Roadmap</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../about.html">About us</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://github.com/scikit-learn/scikit-learn">GitHub</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://scikit-learn.org/dev/versions.html">Other Versions</a>
        </li>
        <li class="nav-item dropdown nav-more-item-dropdown">
          <a class="sk-nav-link nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">More</a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdown">
              <a class="sk-nav-dropdown-item dropdown-item" href="../../getting_started.html">Getting Started</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../tutorial/index.html">Tutorial</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../glossary.html">Glossary</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../developers/index.html">Development</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../faq.html">FAQ</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../related_projects.html">Related packages</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../roadmap.html">Roadmap</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../about.html">About us</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://github.com/scikit-learn/scikit-learn">GitHub</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://scikit-learn.org/dev/versions.html">Other Versions</a>
          </div>
        </li>
      </ul>
      <div id="searchbox" role="search">
          <div class="searchformwrapper">
          <form class="search" action="../../search.html" method="get">
            <input class="sk-search-text-input" type="text" name="q" aria-labelledby="searchlabel" />
            <input class="sk-search-text-btn" type="submit" value="Go" />
          </form>
          </div>
      </div>
    </div>
  </div>
</nav>
<div class="d-flex" id="sk-doc-wrapper">
    <input type="checkbox" name="sk-toggle-checkbox" id="sk-toggle-checkbox">
    <label id="sk-sidemenu-toggle" class="sk-btn-toggle-toc btn sk-btn-primary" for="sk-toggle-checkbox">Toggle Menu</label>
    <div id="sk-sidebar-wrapper" class="border-right">
      <div class="sk-sidebar-toc-wrapper">
        <div class="sk-sidebar-toc-logo">
          <a href="../../index.html">
            <img
              class="sk-brand-img"
              src="../../_static/scikit-learn-logo-small.png"
              alt="logo"/>
          </a>
        </div>
        <div class="btn-group w-100 mb-2" role="group" aria-label="rellinks">
            <a href="sklearn.linear_model.SGDRegressor.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="sklearn.linear_model.SGDRegressor">Prev</a><a href="../classes.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="API Reference">Up</a>
            <a href="sklearn.linear_model.Lars.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="sklearn.linear_model.Lars">Next</a>
        </div>
        <div class="alert alert-danger p-1 mb-2" role="alert">
          <p class="text-center mb-0">
          <strong>scikit-learn 0.22</strong><br/>
          <a href="http://scikit-learn.org/dev/versions.html">Other versions</a>
          </p>
        </div>
        <div class="alert alert-warning p-1 mb-2" role="alert">
          <p class="text-center mb-0">
            Please <a class="font-weight-bold" href="../../about.html#citing-scikit-learn"><string>cite us</string></a> if you use the software.
          </p>
        </div>
          <div class="sk-sidebar-toc">
            <ul>
<li><a class="reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.linear_model</span></code>.ElasticNet</a><ul>
<li><a class="reference internal" href="#examples-using-sklearn-linear-model-elasticnet">Examples using <code class="docutils literal notranslate"><span class="pre">sklearn.linear_model.ElasticNet</span></code></a></li>
</ul>
</li>
</ul>

          </div>
      </div>
    </div>
    <div id="sk-page-content-wrapper">
      <div class="sk-page-content container-fluid body px-md-3" role="main">
        
  <div class="section" id="sklearn-linear-model-elasticnet">
<h1><a class="reference internal" href="../classes.html#module-sklearn.linear_model" title="sklearn.linear_model"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.linear_model</span></code></a>.ElasticNet<a class="headerlink" href="#sklearn-linear-model-elasticnet" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="sklearn.linear_model.ElasticNet">
<em class="property">class </em><code class="sig-prename descclassname">sklearn.linear_model.</code><code class="sig-name descname">ElasticNet</code><span class="sig-paren">(</span><em class="sig-param">alpha=1.0</em>, <em class="sig-param">l1_ratio=0.5</em>, <em class="sig-param">fit_intercept=True</em>, <em class="sig-param">normalize=False</em>, <em class="sig-param">precompute=False</em>, <em class="sig-param">max_iter=1000</em>, <em class="sig-param">copy_X=True</em>, <em class="sig-param">tol=0.0001</em>, <em class="sig-param">warm_start=False</em>, <em class="sig-param">positive=False</em>, <em class="sig-param">random_state=None</em>, <em class="sig-param">selection='cyclic'</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/5f3c3f037/sklearn/linear_model/_coordinate_descent.py#L502"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.linear_model.ElasticNet" title="Permalink to this definition">¶</a></dt>
<dd><p>Linear regression with combined L1 and L2 priors as regularizer.</p>
<p>Minimizes the objective function:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">n_samples</span><span class="p">)</span> <span class="o">*</span> <span class="o">||</span><span class="n">y</span> <span class="o">-</span> <span class="n">Xw</span><span class="o">||^</span><span class="mi">2_2</span>
<span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">l1_ratio</span> <span class="o">*</span> <span class="o">||</span><span class="n">w</span><span class="o">||</span><span class="n">_1</span>
<span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">l1_ratio</span><span class="p">)</span> <span class="o">*</span> <span class="o">||</span><span class="n">w</span><span class="o">||^</span><span class="mi">2_2</span>
</pre></div>
</div>
<p>If you are interested in controlling the L1 and L2 penalty
separately, keep in mind that this is equivalent to:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">*</span> <span class="n">L1</span> <span class="o">+</span> <span class="n">b</span> <span class="o">*</span> <span class="n">L2</span>
</pre></div>
</div>
<p>where:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">alpha</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span> <span class="ow">and</span> <span class="n">l1_ratio</span> <span class="o">=</span> <span class="n">a</span> <span class="o">/</span> <span class="p">(</span><span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
<p>The parameter l1_ratio corresponds to alpha in the glmnet R package while
alpha corresponds to the lambda parameter in glmnet. Specifically, l1_ratio
= 1 is the lasso penalty. Currently, l1_ratio &lt;= 0.01 is not reliable,
unless you supply your own sequence of alpha.</p>
<p>Read more in the <a class="reference internal" href="../linear_model.html#elastic-net"><span class="std std-ref">User Guide</span></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>alpha</strong><span class="classifier">float, optional</span></dt><dd><p>Constant that multiplies the penalty terms. Defaults to 1.0.
See the notes for the exact mathematical meaning of this
parameter. <code class="docutils literal notranslate"><span class="pre">alpha</span> <span class="pre">=</span> <span class="pre">0</span></code> is equivalent to an ordinary least square,
solved by the <a class="reference internal" href="sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression" title="sklearn.linear_model.LinearRegression"><code class="xref py py-class docutils literal notranslate"><span class="pre">LinearRegression</span></code></a> object. For numerical
reasons, using <code class="docutils literal notranslate"><span class="pre">alpha</span> <span class="pre">=</span> <span class="pre">0</span></code> with the <code class="docutils literal notranslate"><span class="pre">Lasso</span></code> object is not advised.
Given this, you should use the <a class="reference internal" href="sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression" title="sklearn.linear_model.LinearRegression"><code class="xref py py-class docutils literal notranslate"><span class="pre">LinearRegression</span></code></a> object.</p>
</dd>
<dt><strong>l1_ratio</strong><span class="classifier">float</span></dt><dd><p>The ElasticNet mixing parameter, with <code class="docutils literal notranslate"><span class="pre">0</span> <span class="pre">&lt;=</span> <span class="pre">l1_ratio</span> <span class="pre">&lt;=</span> <span class="pre">1</span></code>. For
<code class="docutils literal notranslate"><span class="pre">l1_ratio</span> <span class="pre">=</span> <span class="pre">0</span></code> the penalty is an L2 penalty. <code class="docutils literal notranslate"><span class="pre">For</span> <span class="pre">l1_ratio</span> <span class="pre">=</span> <span class="pre">1</span></code> it
is an L1 penalty.  For <code class="docutils literal notranslate"><span class="pre">0</span> <span class="pre">&lt;</span> <span class="pre">l1_ratio</span> <span class="pre">&lt;</span> <span class="pre">1</span></code>, the penalty is a
combination of L1 and L2.</p>
</dd>
<dt><strong>fit_intercept</strong><span class="classifier">bool</span></dt><dd><p>Whether the intercept should be estimated or not. If <code class="docutils literal notranslate"><span class="pre">False</span></code>, the
data is assumed to be already centered.</p>
</dd>
<dt><strong>normalize</strong><span class="classifier">boolean, optional, default False</span></dt><dd><p>This parameter is ignored when <code class="docutils literal notranslate"><span class="pre">fit_intercept</span></code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
<a class="reference internal" href="sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler" title="sklearn.preprocessing.StandardScaler"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.preprocessing.StandardScaler</span></code></a> before calling <code class="docutils literal notranslate"><span class="pre">fit</span></code>
on an estimator with <code class="docutils literal notranslate"><span class="pre">normalize=False</span></code>.</p>
</dd>
<dt><strong>precompute</strong><span class="classifier">True | False | array-like</span></dt><dd><p>Whether to use a precomputed Gram matrix to speed up
calculations. The Gram matrix can also be passed as argument.
For sparse input this option is always <code class="docutils literal notranslate"><span class="pre">True</span></code> to preserve sparsity.</p>
</dd>
<dt><strong>max_iter</strong><span class="classifier">int, optional</span></dt><dd><p>The maximum number of iterations</p>
</dd>
<dt><strong>copy_X</strong><span class="classifier">boolean, optional, default True</span></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">True</span></code>, X will be copied; else, it may be overwritten.</p>
</dd>
<dt><strong>tol</strong><span class="classifier">float, optional</span></dt><dd><p>The tolerance for the optimization: if the updates are
smaller than <code class="docutils literal notranslate"><span class="pre">tol</span></code>, the optimization code checks the
dual gap for optimality and continues until it is smaller
than <code class="docutils literal notranslate"><span class="pre">tol</span></code>.</p>
</dd>
<dt><strong>warm_start</strong><span class="classifier">bool, optional</span></dt><dd><p>When set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, reuse the solution of the previous call to fit as
initialization, otherwise, just erase the previous solution.
See <a class="reference internal" href="../../glossary.html#term-warm-start"><span class="xref std std-term">the Glossary</span></a>.</p>
</dd>
<dt><strong>positive</strong><span class="classifier">bool, optional</span></dt><dd><p>When set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, forces the coefficients to be positive.</p>
</dd>
<dt><strong>random_state</strong><span class="classifier">int, RandomState instance or None, optional, default None</span></dt><dd><p>The seed of the pseudo random number generator that selects a random
feature to update.  If int, random_state is the seed used by the random
number generator; If RandomState instance, random_state is the random
number generator; If None, the random number generator is the
RandomState instance used by <code class="docutils literal notranslate"><span class="pre">np.random</span></code>. Used when <code class="docutils literal notranslate"><span class="pre">selection</span></code> ==
‘random’.</p>
</dd>
<dt><strong>selection</strong><span class="classifier">str, default ‘cyclic’</span></dt><dd><p>If set to ‘random’, a random coefficient is updated every iteration
rather than looping over features sequentially by default. This
(setting to ‘random’) often leads to significantly faster convergence
especially when tol is higher than 1e-4.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Attributes</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>coef_</strong><span class="classifier">array, shape (n_features,) | (n_targets, n_features)</span></dt><dd><p>parameter vector (w in the cost function formula)</p>
</dd>
<dt><a class="reference internal" href="#sklearn.linear_model.ElasticNet.sparse_coef_" title="sklearn.linear_model.ElasticNet.sparse_coef_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sparse_coef_</span></code></a><span class="classifier">scipy.sparse matrix, shape (n_features, 1) |             (n_targets, n_features)</span></dt><dd><p>sparse representation of the fitted <code class="docutils literal notranslate"><span class="pre">coef_</span></code></p>
</dd>
<dt><strong>intercept_</strong><span class="classifier">float | array, shape (n_targets,)</span></dt><dd><p>independent term in decision function.</p>
</dd>
<dt><strong>n_iter_</strong><span class="classifier">array-like, shape (n_targets,)</span></dt><dd><p>number of iterations run by the coordinate descent solver to reach
the specified tolerance.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="sklearn.linear_model.ElasticNetCV.html#sklearn.linear_model.ElasticNetCV" title="sklearn.linear_model.ElasticNetCV"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ElasticNetCV</span></code></a></dt><dd><p>Elastic net model with best model selection by cross-validation.</p>
</dd>
<dt><a class="reference internal" href="sklearn.linear_model.SGDRegressor.html#sklearn.linear_model.SGDRegressor" title="sklearn.linear_model.SGDRegressor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SGDRegressor</span></code></a></dt><dd><p>implements elastic net regression with incremental training.</p>
</dd>
<dt><a class="reference internal" href="sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier" title="sklearn.linear_model.SGDClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SGDClassifier</span></code></a></dt><dd><p>implements logistic regression with elastic net penalty (<code class="docutils literal notranslate"><span class="pre">SGDClassifier(loss=&quot;log&quot;,</span> <span class="pre">penalty=&quot;elasticnet&quot;)</span></code>).</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>To avoid unnecessary memory duplication the X argument of the fit method
should be directly passed as a Fortran-contiguous numpy array.</p>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">ElasticNet</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">regr</span> <span class="o">=</span> <span class="n">ElasticNet</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">regr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="go">ElasticNet(random_state=0)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">regr</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="go">[18.83816048 64.55968825]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">regr</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
<span class="go">1.451...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">regr</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]))</span>
<span class="go">[1.451...]</span>
</pre></div>
</div>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.linear_model.ElasticNet.fit" title="sklearn.linear_model.ElasticNet.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>(self, X, y[, check_input])</p></td>
<td><p>Fit model with coordinate descent.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.linear_model.ElasticNet.get_params" title="sklearn.linear_model.ElasticNet.get_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_params</span></code></a>(self[, deep])</p></td>
<td><p>Get parameters for this estimator.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.linear_model.ElasticNet.path" title="sklearn.linear_model.ElasticNet.path"><code class="xref py py-obj docutils literal notranslate"><span class="pre">path</span></code></a>(X, y[, l1_ratio, eps, n_alphas, …])</p></td>
<td><p>Compute elastic net path with coordinate descent.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.linear_model.ElasticNet.predict" title="sklearn.linear_model.ElasticNet.predict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict</span></code></a>(self, X)</p></td>
<td><p>Predict using the linear model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.linear_model.ElasticNet.score" title="sklearn.linear_model.ElasticNet.score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">score</span></code></a>(self, X, y[, sample_weight])</p></td>
<td><p>Return the coefficient of determination R^2 of the prediction.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.linear_model.ElasticNet.set_params" title="sklearn.linear_model.ElasticNet.set_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_params</span></code></a>(self, \*\*params)</p></td>
<td><p>Set the parameters of this estimator.</p></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="sklearn.linear_model.ElasticNet.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">alpha=1.0</em>, <em class="sig-param">l1_ratio=0.5</em>, <em class="sig-param">fit_intercept=True</em>, <em class="sig-param">normalize=False</em>, <em class="sig-param">precompute=False</em>, <em class="sig-param">max_iter=1000</em>, <em class="sig-param">copy_X=True</em>, <em class="sig-param">tol=0.0001</em>, <em class="sig-param">warm_start=False</em>, <em class="sig-param">positive=False</em>, <em class="sig-param">random_state=None</em>, <em class="sig-param">selection='cyclic'</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/5f3c3f037/sklearn/linear_model/_coordinate_descent.py#L642"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.linear_model.ElasticNet.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize self.  See help(type(self)) for accurate signature.</p>
</dd></dl>

<dl class="method">
<dt id="sklearn.linear_model.ElasticNet.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">X</em>, <em class="sig-param">y</em>, <em class="sig-param">check_input=True</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/5f3c3f037/sklearn/linear_model/_coordinate_descent.py#L659"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.linear_model.ElasticNet.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit model with coordinate descent.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">ndarray or scipy.sparse matrix, (n_samples, n_features)</span></dt><dd><p>Data</p>
</dd>
<dt><strong>y</strong><span class="classifier">ndarray, shape (n_samples,) or (n_samples, n_targets)</span></dt><dd><p>Target. Will be cast to X’s dtype if necessary</p>
</dd>
<dt><strong>check_input</strong><span class="classifier">boolean, (default=True)</span></dt><dd><p>Allow to bypass several input checking.
Don’t use this parameter unless you know what you do.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Coordinate descent is an algorithm that considers each column of
data at a time hence it will automatically convert the X input
as a Fortran-contiguous numpy array if necessary.</p>
<p>To avoid memory re-allocation it is advised to allocate the
initial data in memory directly using that format.</p>
</dd></dl>

<dl class="method">
<dt id="sklearn.linear_model.ElasticNet.get_params">
<code class="sig-name descname">get_params</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">deep=True</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/5f3c3f037/sklearn/base.py#L173"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.linear_model.ElasticNet.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>deep</strong><span class="classifier">bool, default=True</span></dt><dd><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>params</strong><span class="classifier">mapping of string to any</span></dt><dd><p>Parameter names mapped to their values.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="sklearn.linear_model.ElasticNet.path">
<em class="property">static </em><code class="sig-name descname">path</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">y</em>, <em class="sig-param">l1_ratio=0.5</em>, <em class="sig-param">eps=0.001</em>, <em class="sig-param">n_alphas=100</em>, <em class="sig-param">alphas=None</em>, <em class="sig-param">precompute='auto'</em>, <em class="sig-param">Xy=None</em>, <em class="sig-param">copy_X=True</em>, <em class="sig-param">coef_init=None</em>, <em class="sig-param">verbose=False</em>, <em class="sig-param">return_n_iter=False</em>, <em class="sig-param">positive=False</em>, <em class="sig-param">check_input=True</em>, <em class="sig-param">**params</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/5f3c3f037/sklearn/linear_model/_coordinate_descent.py#L266"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.linear_model.ElasticNet.path" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute elastic net path with coordinate descent.</p>
<p>The elastic net optimization function varies for mono and multi-outputs.</p>
<p>For mono-output tasks it is:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">n_samples</span><span class="p">)</span> <span class="o">*</span> <span class="o">||</span><span class="n">y</span> <span class="o">-</span> <span class="n">Xw</span><span class="o">||^</span><span class="mi">2_2</span>
<span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">l1_ratio</span> <span class="o">*</span> <span class="o">||</span><span class="n">w</span><span class="o">||</span><span class="n">_1</span>
<span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">l1_ratio</span><span class="p">)</span> <span class="o">*</span> <span class="o">||</span><span class="n">w</span><span class="o">||^</span><span class="mi">2_2</span>
</pre></div>
</div>
<p>For multi-output tasks it is:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">n_samples</span><span class="p">))</span> <span class="o">*</span> <span class="o">||</span><span class="n">Y</span> <span class="o">-</span> <span class="n">XW</span><span class="o">||^</span><span class="n">Fro_2</span>
<span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">l1_ratio</span> <span class="o">*</span> <span class="o">||</span><span class="n">W</span><span class="o">||</span><span class="n">_21</span>
<span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">l1_ratio</span><span class="p">)</span> <span class="o">*</span> <span class="o">||</span><span class="n">W</span><span class="o">||</span><span class="n">_Fro</span><span class="o">^</span><span class="mi">2</span>
</pre></div>
</div>
<p>Where:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">||</span><span class="n">W</span><span class="o">||</span><span class="n">_21</span> <span class="o">=</span> \<span class="n">sum_i</span> \<span class="n">sqrt</span><span class="p">{</span>\<span class="n">sum_j</span> <span class="n">w_</span><span class="p">{</span><span class="n">ij</span><span class="p">}</span><span class="o">^</span><span class="mi">2</span><span class="p">}</span>
</pre></div>
</div>
<p>i.e. the sum of norm of each row.</p>
<p>Read more in the <a class="reference internal" href="../linear_model.html#elastic-net"><span class="std std-ref">User Guide</span></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">{array-like}, shape (n_samples, n_features)</span></dt><dd><p>Training data. Pass directly as Fortran-contiguous data to avoid
unnecessary memory duplication. If <code class="docutils literal notranslate"><span class="pre">y</span></code> is mono-output then <code class="docutils literal notranslate"><span class="pre">X</span></code>
can be sparse.</p>
</dd>
<dt><strong>y</strong><span class="classifier">ndarray, shape (n_samples,) or (n_samples, n_outputs)</span></dt><dd><p>Target values.</p>
</dd>
<dt><strong>l1_ratio</strong><span class="classifier">float, optional</span></dt><dd><p>Number between 0 and 1 passed to elastic net (scaling between
l1 and l2 penalties). <code class="docutils literal notranslate"><span class="pre">l1_ratio=1</span></code> corresponds to the Lasso.</p>
</dd>
<dt><strong>eps</strong><span class="classifier">float</span></dt><dd><p>Length of the path. <code class="docutils literal notranslate"><span class="pre">eps=1e-3</span></code> means that
<code class="docutils literal notranslate"><span class="pre">alpha_min</span> <span class="pre">/</span> <span class="pre">alpha_max</span> <span class="pre">=</span> <span class="pre">1e-3</span></code>.</p>
</dd>
<dt><strong>n_alphas</strong><span class="classifier">int, optional</span></dt><dd><p>Number of alphas along the regularization path.</p>
</dd>
<dt><strong>alphas</strong><span class="classifier">ndarray, optional</span></dt><dd><p>List of alphas where to compute the models.
If None alphas are set automatically.</p>
</dd>
<dt><strong>precompute</strong><span class="classifier">True | False | ‘auto’ | array-like</span></dt><dd><p>Whether to use a precomputed Gram matrix to speed up
calculations. If set to <code class="docutils literal notranslate"><span class="pre">'auto'</span></code> let us decide. The Gram
matrix can also be passed as argument.</p>
</dd>
<dt><strong>Xy</strong><span class="classifier">array-like, optional</span></dt><dd><p>Xy = np.dot(X.T, y) that can be precomputed. It is useful
only when the Gram matrix is precomputed.</p>
</dd>
<dt><strong>copy_X</strong><span class="classifier">bool, optional, default True</span></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">True</span></code>, X will be copied; else, it may be overwritten.</p>
</dd>
<dt><strong>coef_init</strong><span class="classifier">array, shape (n_features, ) | None</span></dt><dd><p>The initial values of the coefficients.</p>
</dd>
<dt><strong>verbose</strong><span class="classifier">bool or int</span></dt><dd><p>Amount of verbosity.</p>
</dd>
<dt><strong>return_n_iter</strong><span class="classifier">bool</span></dt><dd><p>Whether to return the number of iterations or not.</p>
</dd>
<dt><strong>positive</strong><span class="classifier">bool, default False</span></dt><dd><p>If set to True, forces coefficients to be positive.
(Only allowed when <code class="docutils literal notranslate"><span class="pre">y.ndim</span> <span class="pre">==</span> <span class="pre">1</span></code>).</p>
</dd>
<dt><strong>check_input</strong><span class="classifier">bool, default True</span></dt><dd><p>Skip input validation checks, including the Gram matrix when provided
assuming there are handled by the caller when check_input=False.</p>
</dd>
<dt><strong>**params</strong><span class="classifier">kwargs</span></dt><dd><p>Keyword arguments passed to the coordinate descent solver.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>alphas</strong><span class="classifier">array, shape (n_alphas,)</span></dt><dd><p>The alphas along the path where models are computed.</p>
</dd>
<dt><strong>coefs</strong><span class="classifier">array, shape (n_features, n_alphas) or             (n_outputs, n_features, n_alphas)</span></dt><dd><p>Coefficients along the path.</p>
</dd>
<dt><strong>dual_gaps</strong><span class="classifier">array, shape (n_alphas,)</span></dt><dd><p>The dual gaps at the end of the optimization for each alpha.</p>
</dd>
<dt><strong>n_iters</strong><span class="classifier">array-like, shape (n_alphas,)</span></dt><dd><p>The number of iterations taken by the coordinate descent optimizer to
reach the specified tolerance for each alpha.
(Is returned when <code class="docutils literal notranslate"><span class="pre">return_n_iter</span></code> is set to True).</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="sklearn.linear_model.MultiTaskElasticNet.html#sklearn.linear_model.MultiTaskElasticNet" title="sklearn.linear_model.MultiTaskElasticNet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MultiTaskElasticNet</span></code></a></dt><dd></dd>
<dt><a class="reference internal" href="sklearn.linear_model.MultiTaskElasticNetCV.html#sklearn.linear_model.MultiTaskElasticNetCV" title="sklearn.linear_model.MultiTaskElasticNetCV"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MultiTaskElasticNetCV</span></code></a></dt><dd></dd>
<dt><a class="reference internal" href="#sklearn.linear_model.ElasticNet" title="sklearn.linear_model.ElasticNet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ElasticNet</span></code></a></dt><dd></dd>
<dt><a class="reference internal" href="sklearn.linear_model.ElasticNetCV.html#sklearn.linear_model.ElasticNetCV" title="sklearn.linear_model.ElasticNetCV"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ElasticNetCV</span></code></a></dt><dd></dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>For an example, see
<a class="reference internal" href="../../auto_examples/linear_model/plot_lasso_coordinate_descent_path.html#sphx-glr-auto-examples-linear-model-plot-lasso-coordinate-descent-path-py"><span class="std std-ref">examples/linear_model/plot_lasso_coordinate_descent_path.py</span></a>.</p>
</dd></dl>

<dl class="method">
<dt id="sklearn.linear_model.ElasticNet.predict">
<code class="sig-name descname">predict</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">X</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/5f3c3f037/sklearn/linear_model/_base.py#L211"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.linear_model.ElasticNet.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict using the linear model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array_like or sparse matrix, shape (n_samples, n_features)</span></dt><dd><p>Samples.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>C</strong><span class="classifier">array, shape (n_samples,)</span></dt><dd><p>Returns predicted values.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="sklearn.linear_model.ElasticNet.score">
<code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">X</em>, <em class="sig-param">y</em>, <em class="sig-param">sample_weight=None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/5f3c3f037/sklearn/base.py#L376"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.linear_model.ElasticNet.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) ** 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) ** 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like of shape (n_samples, n_features)</span></dt><dd><p>Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
</dd>
<dt><strong>y</strong><span class="classifier">array-like of shape (n_samples,) or (n_samples, n_outputs)</span></dt><dd><p>True values for X.</p>
</dd>
<dt><strong>sample_weight</strong><span class="classifier">array-like of shape (n_samples,), default=None</span></dt><dd><p>Sample weights.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>score</strong><span class="classifier">float</span></dt><dd><p>R^2 of self.predict(X) wrt. y.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The R2 score used when calling <code class="docutils literal notranslate"><span class="pre">score</span></code> on a regressor will use
<code class="docutils literal notranslate"><span class="pre">multioutput='uniform_average'</span></code> from version 0.23 to keep consistent
with <a class="reference internal" href="sklearn.metrics.r2_score.html#sklearn.metrics.r2_score" title="sklearn.metrics.r2_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">r2_score</span></code></a>. This will influence the
<code class="docutils literal notranslate"><span class="pre">score</span></code> method of all the multioutput regressors (except for
<a class="reference internal" href="sklearn.multioutput.MultiOutputRegressor.html#sklearn.multioutput.MultiOutputRegressor" title="sklearn.multioutput.MultiOutputRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiOutputRegressor</span></code></a>). To specify the
default value manually and avoid the warning, please either call
<a class="reference internal" href="sklearn.metrics.r2_score.html#sklearn.metrics.r2_score" title="sklearn.metrics.r2_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">r2_score</span></code></a> directly or make a custom scorer with
<a class="reference internal" href="sklearn.metrics.make_scorer.html#sklearn.metrics.make_scorer" title="sklearn.metrics.make_scorer"><code class="xref py py-func docutils literal notranslate"><span class="pre">make_scorer</span></code></a> (the built-in scorer <code class="docutils literal notranslate"><span class="pre">'r2'</span></code> uses
<code class="docutils literal notranslate"><span class="pre">multioutput='uniform_average'</span></code>).</p>
</dd></dl>

<dl class="method">
<dt id="sklearn.linear_model.ElasticNet.set_params">
<code class="sig-name descname">set_params</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">**params</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/5f3c3f037/sklearn/base.py#L205"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.linear_model.ElasticNet.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s possible to update each
component of a nested object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>**params</strong><span class="classifier">dict</span></dt><dd><p>Estimator parameters.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">object</span></dt><dd><p>Estimator instance.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="sklearn.linear_model.ElasticNet.sparse_coef_">
<em class="property">property </em><code class="sig-name descname">sparse_coef_</code><a class="headerlink" href="#sklearn.linear_model.ElasticNet.sparse_coef_" title="Permalink to this definition">¶</a></dt>
<dd><p>sparse representation of the fitted <code class="docutils literal notranslate"><span class="pre">coef_</span></code></p>
</dd></dl>

</dd></dl>

<div class="section" id="examples-using-sklearn-linear-model-elasticnet">
<h2>Examples using <code class="docutils literal notranslate"><span class="pre">sklearn.linear_model.ElasticNet</span></code><a class="headerlink" href="#examples-using-sklearn-linear-model-elasticnet" title="Permalink to this headline">¶</a></h2>
<div class="sphx-glr-thumbcontainer" tooltip="Estimates Lasso and Elastic-Net regression models on a manually generated sparse signal corrupt..."><div class="figure align-default" id="id1">
<img alt="../../_images/sphx_glr_plot_lasso_and_elasticnet_thumb.png" src="../../_images/sphx_glr_plot_lasso_and_elasticnet_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/linear_model/plot_lasso_and_elasticnet.html#sphx-glr-auto-examples-linear-model-plot-lasso-and-elasticnet-py"><span class="std std-ref">Lasso and Elastic Net for Sparse Signals</span></a></span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Illustration of how the performance of an estimator on unseen data (test data) is not the same ..."><div class="figure align-default" id="id2">
<img alt="../../_images/sphx_glr_plot_train_error_vs_test_error_thumb.png" src="../../_images/sphx_glr_plot_train_error_vs_test_error_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/model_selection/plot_train_error_vs_test_error.html#sphx-glr-auto-examples-model-selection-plot-train-error-vs-test-error-py"><span class="std std-ref">Train error vs Test error</span></a></span><a class="headerlink" href="#id2" title="Permalink to this image">¶</a></p>
</div>
</div><div class="clearer"></div></div>
</div>


      </div>
    <div class="container">
      <footer class="sk-content-footer">
            &copy; 2007 - 2019, scikit-learn developers (BSD License).
          <a href="../../_sources/modules/generated/sklearn.linear_model.ElasticNet.rst.txt" rel="nofollow">Show this page source</a>
      </footer>
    </div>
  </div>
</div>
<script src="../../_static/js/vendor/bootstrap.min.js"></script>

<script>
    window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
    ga('create', 'UA-22606712-2', 'auto');
    ga('set', 'anonymizeIp', true);
    ga('send', 'pageview');
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


<script>
$(document).ready(function() {
    /* Add a [>>>] button on the top-right corner of code samples to hide
     * the >>> and ... prompts and the output and thus make the code
     * copyable. */
    var div = $('.highlight-python .highlight,' +
                '.highlight-python3 .highlight,' +
                '.highlight-pycon .highlight,' +
		'.highlight-default .highlight')
    var pre = div.find('pre');

    // get the styles from the current theme
    pre.parent().parent().css('position', 'relative');
    var hide_text = 'Hide prompts and outputs';
    var show_text = 'Show prompts and outputs';

    // create and add the button to all the code blocks that contain >>>
    div.each(function(index) {
        var jthis = $(this);
        if (jthis.find('.gp').length > 0) {
            var button = $('<span class="copybutton">&gt;&gt;&gt;</span>');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
            jthis.prepend(button);
        }
        // tracebacks (.gt) contain bare text elements that need to be
        // wrapped in a span to work with .nextUntil() (see later)
        jthis.find('pre:has(.gt)').contents().filter(function() {
            return ((this.nodeType == 3) && (this.data.trim().length > 0));
        }).wrap('<span>');
    });

    // define the behavior of the button when it's clicked
    $('.copybutton').click(function(e){
        e.preventDefault();
        var button = $(this);
        if (button.data('hidden') === 'false') {
            // hide the code output
            button.parent().find('.go, .gp, .gt').hide();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'hidden');
            button.css('text-decoration', 'line-through');
            button.attr('title', show_text);
            button.data('hidden', 'true');
        } else {
            // show the code output
            button.parent().find('.go, .gp, .gt').show();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'visible');
            button.css('text-decoration', 'none');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
        }
    });

	/*** Add permalink buttons next to glossary terms ***/
	$('dl.glossary > dt[id]').append(function() {
		return ('<a class="headerlink" href="#' +
			    this.getAttribute('id') +
			    '" title="Permalink to this term">¶</a>');
	});
  /*** Hide navbar when scrolling down ***/
  // Returns true when headerlink target matches hash in url
  (function() {
    hashTargetOnTop = function() {
        var hash = window.location.hash;
        if ( hash.length < 2 ) { return false; }

        var target = document.getElementById( hash.slice(1) );
        if ( target === null ) { return false; }

        var top = target.getBoundingClientRect().top;
        return (top < 2) && (top > -2);
    };

    // Hide navbar on load if hash target is on top
    var navBar = document.getElementById("navbar");
    var navBarToggler = document.getElementById("sk-navbar-toggler");
    var navBarHeightHidden = "-" + navBar.getBoundingClientRect().height + "px";
    var $window = $(window);

    hideNavBar = function() {
        navBar.style.top = navBarHeightHidden;
    };

    showNavBar = function() {
        navBar.style.top = "0";
    }

    if (hashTargetOnTop()) {
        hideNavBar()
    }

    var prevScrollpos = window.pageYOffset;
    hideOnScroll = function(lastScrollTop) {
        if (($window.width() < 768) && (navBarToggler.getAttribute("aria-expanded") === 'true')) {
            return;
        }
        if (lastScrollTop > 2 && (prevScrollpos <= lastScrollTop) || hashTargetOnTop()){
            hideNavBar()
        } else {
            showNavBar()
        }
        prevScrollpos = lastScrollTop;
    };

    /*** high preformance scroll event listener***/
    var raf = window.requestAnimationFrame ||
        window.webkitRequestAnimationFrame ||
        window.mozRequestAnimationFrame ||
        window.msRequestAnimationFrame ||
        window.oRequestAnimationFrame;
    var lastScrollTop = $window.scrollTop();

    if (raf) {
        loop();
    }

    function loop() {
        var scrollTop = $window.scrollTop();
        if (lastScrollTop === scrollTop) {
            raf(loop);
            return;
        } else {
            lastScrollTop = scrollTop;
            hideOnScroll(lastScrollTop);
            raf(loop);
        }
    }
  })();
});

</script>
    
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    
</body>
</html>