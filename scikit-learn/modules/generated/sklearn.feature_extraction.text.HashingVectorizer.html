

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="sklearn.feature_extraction.text.HashingVectorizer" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://scikit-learn/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html" />
<meta property="og:site_name" content="scikit-learn" />
<meta property="og:description" content="Examples using sklearn.feature_extraction.text.HashingVectorizer: Out-of-core classification of text documents Clustering text documents using k-means FeatureHasher and DictVectorizer Comparison" />
<meta property="og:image" content="https://scikit-learn/stable/_images/sphx_glr_plot_out_of_core_classification_thumb.png" />
<meta property="og:image:alt" content="" />
<meta name="description" content="Examples using sklearn.feature_extraction.text.HashingVectorizer: Out-of-core classification of text documents Clustering text documents using k-means FeatureHasher and DictVectorizer Comparison" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <title>sklearn.feature_extraction.text.HashingVectorizer &mdash; scikit-learn 1.3.2 documentation</title>
  
  <link rel="canonical" href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html" />

  
  <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  

  <link rel="stylesheet" href="../../_static/css/vendor/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/plot_directive.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
<script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
<script src="../../_static/js/vendor/jquery-3.6.3.slim.min.js"></script> 
</head>
<body>






<nav id="navbar" class="sk-docs-navbar navbar navbar-expand-md navbar-light bg-light py-0">
  <div class="container-fluid sk-docs-container px-0">
      <a class="navbar-brand py-0" href="../../index.html">
        <img
          class="sk-brand-img"
          src="../../_static/scikit-learn-logo-small.png"
          alt="logo"/>
      </a>
    <button
      id="sk-navbar-toggler"
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="sk-navbar-collapse collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../install.html">Install</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../user_guide.html">User Guide</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../classes.html">API</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../auto_examples/index.html">Examples</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" target="_blank" rel="noopener noreferrer" href="https://blog.scikit-learn.org/">Community</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../getting_started.html" >Getting Started</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../tutorial/index.html" >Tutorial</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../whats_new/v1.3.html" >What's new</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../glossary.html" >Glossary</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://scikit-learn.org/dev/developers/index.html" target="_blank" rel="noopener noreferrer">Development</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../faq.html" >FAQ</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../support.html" >Support</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../related_projects.html" >Related packages</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../roadmap.html" >Roadmap</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../governance.html" >Governance</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../about.html" >About us</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://github.com/scikit-learn/scikit-learn" >GitHub</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://scikit-learn.org/dev/versions.html" >Other Versions and Download</a>
        </li>
        <li class="nav-item dropdown nav-more-item-dropdown">
          <a class="sk-nav-link nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">More</a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdown">
              <a class="sk-nav-dropdown-item dropdown-item" href="../../getting_started.html" >Getting Started</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../tutorial/index.html" >Tutorial</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../whats_new/v1.3.html" >What's new</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../glossary.html" >Glossary</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://scikit-learn.org/dev/developers/index.html" target="_blank" rel="noopener noreferrer">Development</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../faq.html" >FAQ</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../support.html" >Support</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../related_projects.html" >Related packages</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../roadmap.html" >Roadmap</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../governance.html" >Governance</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../about.html" >About us</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://github.com/scikit-learn/scikit-learn" >GitHub</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://scikit-learn.org/dev/versions.html" >Other Versions and Download</a>
          </div>
        </li>
      </ul>
      <div id="searchbox" role="search">
          <div class="searchformwrapper">
          <form class="search" action="../../search.html" method="get">
            <input class="sk-search-text-input" type="text" name="q" aria-labelledby="searchlabel" />
            <input class="sk-search-text-btn" type="submit" value="Go" />
          </form>
          </div>
      </div>
    </div>
  </div>
</nav>
<div class="d-flex" id="sk-doc-wrapper">
    <input type="checkbox" name="sk-toggle-checkbox" id="sk-toggle-checkbox">
    <label id="sk-sidemenu-toggle" class="sk-btn-toggle-toc btn sk-btn-primary" for="sk-toggle-checkbox">Toggle Menu</label>
    <div id="sk-sidebar-wrapper" class="border-right">
      <div class="sk-sidebar-toc-wrapper">
        <div class="btn-group w-100 mb-2" role="group" aria-label="rellinks">
            <a href="sklearn.feature_extraction.text.CountVectorizer.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="sklearn.feature_extraction.text.CountVectorizer">Prev</a><a href="../classes.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="API Reference">Up</a>
            <a href="sklearn.feature_extraction.text.TfidfTransformer.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="sklearn.feature_extraction.text.TfidfTransformer">Next</a>
        </div>
        <div class="alert alert-danger p-1 mb-2" role="alert">
          <p class="text-center mb-0">
          <strong>scikit-learn 1.3.2</strong><br/>
          <a href="http://scikit-learn.org/dev/versions.html">Other versions</a>
          </p>
        </div>
        <div class="alert alert-warning p-1 mb-2" role="alert">
          <p class="text-center mb-0">
            Please <a class="font-weight-bold" href="../../about.html#citing-scikit-learn"><string>cite us</string></a> if you use the software.
          </p>
        </div>
            <div class="sk-sidebar-toc">
              <ul>
<li><a class="reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.feature_extraction.text</span></code>.HashingVectorizer</a><ul>
<li><a class="reference internal" href="#sklearn.feature_extraction.text.HashingVectorizer"><code class="docutils literal notranslate"><span class="pre">HashingVectorizer</span></code></a><ul>
<li><a class="reference internal" href="#sklearn.feature_extraction.text.HashingVectorizer.build_analyzer"><code class="docutils literal notranslate"><span class="pre">HashingVectorizer.build_analyzer</span></code></a></li>
<li><a class="reference internal" href="#sklearn.feature_extraction.text.HashingVectorizer.build_preprocessor"><code class="docutils literal notranslate"><span class="pre">HashingVectorizer.build_preprocessor</span></code></a></li>
<li><a class="reference internal" href="#sklearn.feature_extraction.text.HashingVectorizer.build_tokenizer"><code class="docutils literal notranslate"><span class="pre">HashingVectorizer.build_tokenizer</span></code></a></li>
<li><a class="reference internal" href="#sklearn.feature_extraction.text.HashingVectorizer.decode"><code class="docutils literal notranslate"><span class="pre">HashingVectorizer.decode</span></code></a></li>
<li><a class="reference internal" href="#sklearn.feature_extraction.text.HashingVectorizer.fit"><code class="docutils literal notranslate"><span class="pre">HashingVectorizer.fit</span></code></a></li>
<li><a class="reference internal" href="#sklearn.feature_extraction.text.HashingVectorizer.fit_transform"><code class="docutils literal notranslate"><span class="pre">HashingVectorizer.fit_transform</span></code></a></li>
<li><a class="reference internal" href="#sklearn.feature_extraction.text.HashingVectorizer.get_metadata_routing"><code class="docutils literal notranslate"><span class="pre">HashingVectorizer.get_metadata_routing</span></code></a></li>
<li><a class="reference internal" href="#sklearn.feature_extraction.text.HashingVectorizer.get_params"><code class="docutils literal notranslate"><span class="pre">HashingVectorizer.get_params</span></code></a></li>
<li><a class="reference internal" href="#sklearn.feature_extraction.text.HashingVectorizer.get_stop_words"><code class="docutils literal notranslate"><span class="pre">HashingVectorizer.get_stop_words</span></code></a></li>
<li><a class="reference internal" href="#sklearn.feature_extraction.text.HashingVectorizer.partial_fit"><code class="docutils literal notranslate"><span class="pre">HashingVectorizer.partial_fit</span></code></a></li>
<li><a class="reference internal" href="#sklearn.feature_extraction.text.HashingVectorizer.set_output"><code class="docutils literal notranslate"><span class="pre">HashingVectorizer.set_output</span></code></a></li>
<li><a class="reference internal" href="#sklearn.feature_extraction.text.HashingVectorizer.set_params"><code class="docutils literal notranslate"><span class="pre">HashingVectorizer.set_params</span></code></a></li>
<li><a class="reference internal" href="#sklearn.feature_extraction.text.HashingVectorizer.transform"><code class="docutils literal notranslate"><span class="pre">HashingVectorizer.transform</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#examples-using-sklearn-feature-extraction-text-hashingvectorizer">Examples using <code class="docutils literal notranslate"><span class="pre">sklearn.feature_extraction.text.HashingVectorizer</span></code></a></li>
</ul>
</li>
</ul>

            </div>
      </div>
    </div>
    <div id="sk-page-content-wrapper">
      <div class="sk-page-content container-fluid body px-md-3" role="main">
        
  <section id="sklearn-feature-extraction-text-hashingvectorizer">
<h1><a class="reference internal" href="../classes.html#module-sklearn.feature_extraction.text" title="sklearn.feature_extraction.text"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.feature_extraction.text</span></code></a>.HashingVectorizer<a class="headerlink" href="#sklearn-feature-extraction-text-hashingvectorizer" title="Link to this heading">¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="sklearn.feature_extraction.text.HashingVectorizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">sklearn.feature_extraction.text.</span></span><span class="sig-name descname"><span class="pre">HashingVectorizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input='content'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoding='utf-8'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decode_error='strict'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strip_accents=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lowercase=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preprocessor=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tokenizer=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop_words=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_pattern='(?u)\\b\\w\\w+\\b'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ngram_range=(1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">1)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">analyzer='word'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_features=1048576</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">binary=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm='l2'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alternate_sign=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype=&lt;class</span> <span class="pre">'numpy.float64'&gt;</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.feature_extraction.text.HashingVectorizer" title="Link to this definition">¶</a></dt>
<dd><p>Convert a collection of text documents to a matrix of token occurrences.</p>
<p>It turns a collection of text documents into a scipy.sparse matrix holding
token occurrence counts (or binary occurrence information), possibly
normalized as token frequencies if norm=’l1’ or projected on the euclidean
unit sphere if norm=’l2’.</p>
<p>This text vectorizer implementation uses the hashing trick to find the
token string name to feature integer index mapping.</p>
<p>This strategy has several advantages:</p>
<ul class="simple">
<li><p>it is very low memory scalable to large datasets as there is no need to
store a vocabulary dictionary in memory.</p></li>
<li><p>it is fast to pickle and un-pickle as it holds no state besides the
constructor parameters.</p></li>
<li><p>it can be used in a streaming (partial fit) or parallel pipeline as there
is no state computed during fit.</p></li>
</ul>
<p>There are also a couple of cons (vs using a CountVectorizer with an
in-memory vocabulary):</p>
<ul class="simple">
<li><p>there is no way to compute the inverse transform (from feature indices to
string feature names) which can be a problem when trying to introspect
which features are most important to a model.</p></li>
<li><p>there can be collisions: distinct tokens can be mapped to the same
feature index. However in practice this is rarely an issue if n_features
is large enough (e.g. 2 ** 18 for text classification problems).</p></li>
<li><p>no IDF weighting as this would render the transformer stateful.</p></li>
</ul>
<p>The hash function employed is the signed 32-bit version of Murmurhash3.</p>
<p>For an efficiency comparision of the different feature extractors, see
<a class="reference internal" href="../../auto_examples/text/plot_hashing_vs_dict_vectorizer.html#sphx-glr-auto-examples-text-plot-hashing-vs-dict-vectorizer-py"><span class="std std-ref">FeatureHasher and DictVectorizer Comparison</span></a>.</p>
<p>Read more in the <a class="reference internal" href="../feature_extraction.html#text-feature-extraction"><span class="std std-ref">User Guide</span></a>.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>input</strong><span class="classifier">{‘filename’, ‘file’, ‘content’}, default=’content’</span></dt><dd><ul class="simple">
<li><p>If <code class="docutils literal notranslate"><span class="pre">'filename'</span></code>, the sequence passed as an argument to fit is
expected to be a list of filenames that need reading to fetch
the raw content to analyze.</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">'file'</span></code>, the sequence items must have a ‘read’ method (file-like
object) that is called to fetch the bytes in memory.</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">'content'</span></code>, the input is expected to be a sequence of items that
can be of type string or byte.</p></li>
</ul>
</dd>
<dt><strong>encoding</strong><span class="classifier">str, default=’utf-8’</span></dt><dd><p>If bytes or files are given to analyze, this encoding is used to
decode.</p>
</dd>
<dt><strong>decode_error</strong><span class="classifier">{‘strict’, ‘ignore’, ‘replace’}, default=’strict’</span></dt><dd><p>Instruction on what to do if a byte sequence is given to analyze that
contains characters not of the given <code class="docutils literal notranslate"><span class="pre">encoding</span></code>. By default, it is
‘strict’, meaning that a UnicodeDecodeError will be raised. Other
values are ‘ignore’ and ‘replace’.</p>
</dd>
<dt><strong>strip_accents</strong><span class="classifier">{‘ascii’, ‘unicode’} or callable, default=None</span></dt><dd><p>Remove accents and perform other character normalization
during the preprocessing step.
‘ascii’ is a fast method that only works on characters that have
a direct ASCII mapping.
‘unicode’ is a slightly slower method that works on any character.
None (default) means no character normalization is performed.</p>
<p>Both ‘ascii’ and ‘unicode’ use NFKD normalization from
<a class="reference external" href="https://docs.python.org/3/library/unicodedata.html#unicodedata.normalize" title="(in Python v3.12)"><code class="xref py py-func docutils literal notranslate"><span class="pre">unicodedata.normalize</span></code></a>.</p>
</dd>
<dt><strong>lowercase</strong><span class="classifier">bool, default=True</span></dt><dd><p>Convert all characters to lowercase before tokenizing.</p>
</dd>
<dt><strong>preprocessor</strong><span class="classifier">callable, default=None</span></dt><dd><p>Override the preprocessing (string transformation) stage while
preserving the tokenizing and n-grams generation steps.
Only applies if <code class="docutils literal notranslate"><span class="pre">analyzer</span></code> is not callable.</p>
</dd>
<dt><strong>tokenizer</strong><span class="classifier">callable, default=None</span></dt><dd><p>Override the string tokenization step while preserving the
preprocessing and n-grams generation steps.
Only applies if <code class="docutils literal notranslate"><span class="pre">analyzer</span> <span class="pre">==</span> <span class="pre">'word'</span></code>.</p>
</dd>
<dt><strong>stop_words</strong><span class="classifier">{‘english’}, list, default=None</span></dt><dd><p>If ‘english’, a built-in stop word list for English is used.
There are several known issues with ‘english’ and you should
consider an alternative (see <a class="reference internal" href="../feature_extraction.html#stop-words"><span class="std std-ref">Using stop words</span></a>).</p>
<p>If a list, that list is assumed to contain stop words, all of which
will be removed from the resulting tokens.
Only applies if <code class="docutils literal notranslate"><span class="pre">analyzer</span> <span class="pre">==</span> <span class="pre">'word'</span></code>.</p>
</dd>
<dt><strong>token_pattern</strong><span class="classifier">str or None, default=r”(?u)\b\w\w+\b”</span></dt><dd><p>Regular expression denoting what constitutes a “token”, only used
if <code class="docutils literal notranslate"><span class="pre">analyzer</span> <span class="pre">==</span> <span class="pre">'word'</span></code>. The default regexp selects tokens of 2
or more alphanumeric characters (punctuation is completely ignored
and always treated as a token separator).</p>
<p>If there is a capturing group in token_pattern then the
captured group content, not the entire match, becomes the token.
At most one capturing group is permitted.</p>
</dd>
<dt><strong>ngram_range</strong><span class="classifier">tuple (min_n, max_n), default=(1, 1)</span></dt><dd><p>The lower and upper boundary of the range of n-values for different
n-grams to be extracted. All values of n such that min_n &lt;= n &lt;= max_n
will be used. For example an <code class="docutils literal notranslate"><span class="pre">ngram_range</span></code> of <code class="docutils literal notranslate"><span class="pre">(1,</span> <span class="pre">1)</span></code> means only
unigrams, <code class="docutils literal notranslate"><span class="pre">(1,</span> <span class="pre">2)</span></code> means unigrams and bigrams, and <code class="docutils literal notranslate"><span class="pre">(2,</span> <span class="pre">2)</span></code> means
only bigrams.
Only applies if <code class="docutils literal notranslate"><span class="pre">analyzer</span></code> is not callable.</p>
</dd>
<dt><strong>analyzer</strong><span class="classifier">{‘word’, ‘char’, ‘char_wb’} or callable, default=’word’</span></dt><dd><p>Whether the feature should be made of word or character n-grams.
Option ‘char_wb’ creates character n-grams only from text inside
word boundaries; n-grams at the edges of words are padded with space.</p>
<p>If a callable is passed it is used to extract the sequence of features
out of the raw, unprocessed input.</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.21: </span>Since v0.21, if <code class="docutils literal notranslate"><span class="pre">input</span></code> is <code class="docutils literal notranslate"><span class="pre">'filename'</span></code> or <code class="docutils literal notranslate"><span class="pre">'file'</span></code>, the data
is first read from the file and then passed to the given callable
analyzer.</p>
</div>
</dd>
<dt><strong>n_features</strong><span class="classifier">int, default=(2 ** 20)</span></dt><dd><p>The number of features (columns) in the output matrices. Small numbers
of features are likely to cause hash collisions, but large numbers
will cause larger coefficient dimensions in linear learners.</p>
</dd>
<dt><strong>binary</strong><span class="classifier">bool, default=False</span></dt><dd><p>If True, all non zero counts are set to 1. This is useful for discrete
probabilistic models that model binary events rather than integer
counts.</p>
</dd>
<dt><strong>norm</strong><span class="classifier">{‘l1’, ‘l2’}, default=’l2’</span></dt><dd><p>Norm used to normalize term vectors. None for no normalization.</p>
</dd>
<dt><strong>alternate_sign</strong><span class="classifier">bool, default=True</span></dt><dd><p>When True, an alternating sign is added to the features as to
approximately conserve the inner product in the hashed space even for
small n_features. This approach is similar to sparse random projection.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.19.</span></p>
</div>
</dd>
<dt><strong>dtype</strong><span class="classifier">type, default=np.float64</span></dt><dd><p>Type of the matrix returned by fit_transform() or transform().</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer" title="sklearn.feature_extraction.text.CountVectorizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CountVectorizer</span></code></a></dt><dd><p>Convert a collection of text documents to a matrix of token counts.</p>
</dd>
<dt><a class="reference internal" href="sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer" title="sklearn.feature_extraction.text.TfidfVectorizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TfidfVectorizer</span></code></a></dt><dd><p>Convert a collection of raw documents to a matrix of TF-IDF features.</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>This estimator is <a class="reference internal" href="../../glossary.html#term-stateless"><span class="xref std std-term">stateless</span></a> and does not need to be fitted.
However, we recommend to call <a class="reference internal" href="#sklearn.feature_extraction.text.HashingVectorizer.fit_transform" title="sklearn.feature_extraction.text.HashingVectorizer.fit_transform"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit_transform</span></code></a> instead of
<a class="reference internal" href="#sklearn.feature_extraction.text.HashingVectorizer.transform" title="sklearn.feature_extraction.text.HashingVectorizer.transform"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transform</span></code></a>, as parameter validation is only performed in
<a class="reference internal" href="#sklearn.feature_extraction.text.HashingVectorizer.fit" title="sklearn.feature_extraction.text.HashingVectorizer.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit</span></code></a>.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">HashingVectorizer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">corpus</span> <span class="o">=</span> <span class="p">[</span>
<span class="gp">... </span>    <span class="s1">&#39;This is the first document.&#39;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="s1">&#39;This document is the second document.&#39;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="s1">&#39;And this is the third one.&#39;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="s1">&#39;Is this the first document?&#39;</span><span class="p">,</span>
<span class="gp">... </span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">HashingVectorizer</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="o">**</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(4, 16)</span>
</pre></div>
</div>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.feature_extraction.text.HashingVectorizer.build_analyzer" title="sklearn.feature_extraction.text.HashingVectorizer.build_analyzer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">build_analyzer</span></code></a>()</p></td>
<td><p>Return a callable to process input data.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.feature_extraction.text.HashingVectorizer.build_preprocessor" title="sklearn.feature_extraction.text.HashingVectorizer.build_preprocessor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">build_preprocessor</span></code></a>()</p></td>
<td><p>Return a function to preprocess the text before tokenization.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.feature_extraction.text.HashingVectorizer.build_tokenizer" title="sklearn.feature_extraction.text.HashingVectorizer.build_tokenizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">build_tokenizer</span></code></a>()</p></td>
<td><p>Return a function that splits a string into a sequence of tokens.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.feature_extraction.text.HashingVectorizer.decode" title="sklearn.feature_extraction.text.HashingVectorizer.decode"><code class="xref py py-obj docutils literal notranslate"><span class="pre">decode</span></code></a>(doc)</p></td>
<td><p>Decode the input into a string of unicode symbols.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.feature_extraction.text.HashingVectorizer.fit" title="sklearn.feature_extraction.text.HashingVectorizer.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>(X[, y])</p></td>
<td><p>Only validates estimator's parameters.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.feature_extraction.text.HashingVectorizer.fit_transform" title="sklearn.feature_extraction.text.HashingVectorizer.fit_transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit_transform</span></code></a>(X[, y])</p></td>
<td><p>Transform a sequence of documents to a document-term matrix.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.feature_extraction.text.HashingVectorizer.get_metadata_routing" title="sklearn.feature_extraction.text.HashingVectorizer.get_metadata_routing"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_metadata_routing</span></code></a>()</p></td>
<td><p>Get metadata routing of this object.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.feature_extraction.text.HashingVectorizer.get_params" title="sklearn.feature_extraction.text.HashingVectorizer.get_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_params</span></code></a>([deep])</p></td>
<td><p>Get parameters for this estimator.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.feature_extraction.text.HashingVectorizer.get_stop_words" title="sklearn.feature_extraction.text.HashingVectorizer.get_stop_words"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_stop_words</span></code></a>()</p></td>
<td><p>Build or fetch the effective stop words list.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.feature_extraction.text.HashingVectorizer.partial_fit" title="sklearn.feature_extraction.text.HashingVectorizer.partial_fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">partial_fit</span></code></a>(X[, y])</p></td>
<td><p>Only validates estimator's parameters.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.feature_extraction.text.HashingVectorizer.set_output" title="sklearn.feature_extraction.text.HashingVectorizer.set_output"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_output</span></code></a>(*[, transform])</p></td>
<td><p>Set output container.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.feature_extraction.text.HashingVectorizer.set_params" title="sklearn.feature_extraction.text.HashingVectorizer.set_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_params</span></code></a>(**params)</p></td>
<td><p>Set the parameters of this estimator.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.feature_extraction.text.HashingVectorizer.transform" title="sklearn.feature_extraction.text.HashingVectorizer.transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">transform</span></code></a>(X)</p></td>
<td><p>Transform a sequence of documents to a document-term matrix.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.feature_extraction.text.HashingVectorizer.build_analyzer">
<span class="sig-name descname"><span class="pre">build_analyzer</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.feature_extraction.text.HashingVectorizer.build_analyzer" title="Link to this definition">¶</a></dt>
<dd><p>Return a callable to process input data.</p>
<p>The callable handles preprocessing, tokenization, and n-grams generation.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt>analyzer: callable</dt><dd><p>A function to handle preprocessing, tokenization
and n-grams generation.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.feature_extraction.text.HashingVectorizer.build_preprocessor">
<span class="sig-name descname"><span class="pre">build_preprocessor</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.feature_extraction.text.HashingVectorizer.build_preprocessor" title="Link to this definition">¶</a></dt>
<dd><p>Return a function to preprocess the text before tokenization.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt>preprocessor: callable</dt><dd><p>A function to preprocess the text before tokenization.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.feature_extraction.text.HashingVectorizer.build_tokenizer">
<span class="sig-name descname"><span class="pre">build_tokenizer</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.feature_extraction.text.HashingVectorizer.build_tokenizer" title="Link to this definition">¶</a></dt>
<dd><p>Return a function that splits a string into a sequence of tokens.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt>tokenizer: callable</dt><dd><p>A function to split a string into a sequence of tokens.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.feature_extraction.text.HashingVectorizer.decode">
<span class="sig-name descname"><span class="pre">decode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">doc</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.feature_extraction.text.HashingVectorizer.decode" title="Link to this definition">¶</a></dt>
<dd><p>Decode the input into a string of unicode symbols.</p>
<p>The decoding strategy depends on the vectorizer parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>doc</strong><span class="classifier">bytes or str</span></dt><dd><p>The string to decode.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>doc: str</dt><dd><p>A string of unicode symbols.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.feature_extraction.text.HashingVectorizer.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.feature_extraction.text.HashingVectorizer.fit" title="Link to this definition">¶</a></dt>
<dd><p>Only validates estimator’s parameters.</p>
<p>This method allows to: (i) validate the estimator’s parameters and
(ii) be consistent with the scikit-learn transformer API.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">ndarray of shape [n_samples, n_features]</span></dt><dd><p>Training data.</p>
</dd>
<dt><strong>y</strong><span class="classifier">Ignored</span></dt><dd><p>Not used, present for API consistency by convention.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">object</span></dt><dd><p>HashingVectorizer instance.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.feature_extraction.text.HashingVectorizer.fit_transform">
<span class="sig-name descname"><span class="pre">fit_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.feature_extraction.text.HashingVectorizer.fit_transform" title="Link to this definition">¶</a></dt>
<dd><p>Transform a sequence of documents to a document-term matrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">iterable over raw text documents, length = n_samples</span></dt><dd><p>Samples. Each sample must be a text document (either bytes or
unicode strings, file name or file object depending on the
constructor argument) which will be tokenized and hashed.</p>
</dd>
<dt><strong>y</strong><span class="classifier">any</span></dt><dd><p>Ignored. This parameter exists only for compatibility with
sklearn.pipeline.Pipeline.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>X</strong><span class="classifier">sparse matrix of shape (n_samples, n_features)</span></dt><dd><p>Document-term matrix.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.feature_extraction.text.HashingVectorizer.get_metadata_routing">
<span class="sig-name descname"><span class="pre">get_metadata_routing</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.feature_extraction.text.HashingVectorizer.get_metadata_routing" title="Link to this definition">¶</a></dt>
<dd><p>Get metadata routing of this object.</p>
<p>Please check <a class="reference internal" href="../../metadata_routing.html#metadata-routing"><span class="std std-ref">User Guide</span></a> on how the routing
mechanism works.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>routing</strong><span class="classifier">MetadataRequest</span></dt><dd><p>A <a class="reference internal" href="sklearn.utils.metadata_routing.MetadataRequest.html#sklearn.utils.metadata_routing.MetadataRequest" title="sklearn.utils.metadata_routing.MetadataRequest"><code class="xref py py-class docutils literal notranslate"><span class="pre">MetadataRequest</span></code></a> encapsulating
routing information.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.feature_extraction.text.HashingVectorizer.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.feature_extraction.text.HashingVectorizer.get_params" title="Link to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>deep</strong><span class="classifier">bool, default=True</span></dt><dd><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>params</strong><span class="classifier">dict</span></dt><dd><p>Parameter names mapped to their values.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.feature_extraction.text.HashingVectorizer.get_stop_words">
<span class="sig-name descname"><span class="pre">get_stop_words</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.feature_extraction.text.HashingVectorizer.get_stop_words" title="Link to this definition">¶</a></dt>
<dd><p>Build or fetch the effective stop words list.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt>stop_words: list or None</dt><dd><p>A list of stop words.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.feature_extraction.text.HashingVectorizer.partial_fit">
<span class="sig-name descname"><span class="pre">partial_fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.feature_extraction.text.HashingVectorizer.partial_fit" title="Link to this definition">¶</a></dt>
<dd><p>Only validates estimator’s parameters.</p>
<p>This method allows to: (i) validate the estimator’s parameters and
(ii) be consistent with the scikit-learn transformer API.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">ndarray of shape [n_samples, n_features]</span></dt><dd><p>Training data.</p>
</dd>
<dt><strong>y</strong><span class="classifier">Ignored</span></dt><dd><p>Not used, present for API consistency by convention.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">object</span></dt><dd><p>HashingVectorizer instance.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.feature_extraction.text.HashingVectorizer.set_output">
<span class="sig-name descname"><span class="pre">set_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.feature_extraction.text.HashingVectorizer.set_output" title="Link to this definition">¶</a></dt>
<dd><p>Set output container.</p>
<p>See <a class="reference internal" href="../../auto_examples/miscellaneous/plot_set_output.html#sphx-glr-auto-examples-miscellaneous-plot-set-output-py"><span class="std std-ref">Introducing the set_output API</span></a>
for an example on how to use the API.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>transform</strong><span class="classifier">{“default”, “pandas”}, default=None</span></dt><dd><p>Configure output of <code class="docutils literal notranslate"><span class="pre">transform</span></code> and <code class="docutils literal notranslate"><span class="pre">fit_transform</span></code>.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;default&quot;</span></code>: Default output format of a transformer</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;pandas&quot;</span></code>: DataFrame output</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">None</span></code>: Transform configuration is unchanged</p></li>
</ul>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">estimator instance</span></dt><dd><p>Estimator instance.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.feature_extraction.text.HashingVectorizer.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.feature_extraction.text.HashingVectorizer.set_params" title="Link to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as <a class="reference internal" href="sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code></a>). The latter have
parameters of the form <code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s
possible to update each component of a nested object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>**params</strong><span class="classifier">dict</span></dt><dd><p>Estimator parameters.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">estimator instance</span></dt><dd><p>Estimator instance.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.feature_extraction.text.HashingVectorizer.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.feature_extraction.text.HashingVectorizer.transform" title="Link to this definition">¶</a></dt>
<dd><p>Transform a sequence of documents to a document-term matrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">iterable over raw text documents, length = n_samples</span></dt><dd><p>Samples. Each sample must be a text document (either bytes or
unicode strings, file name or file object depending on the
constructor argument) which will be tokenized and hashed.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>X</strong><span class="classifier">sparse matrix of shape (n_samples, n_features)</span></dt><dd><p>Document-term matrix.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<section id="examples-using-sklearn-feature-extraction-text-hashingvectorizer">
<h2>Examples using <code class="docutils literal notranslate"><span class="pre">sklearn.feature_extraction.text.HashingVectorizer</span></code><a class="headerlink" href="#examples-using-sklearn-feature-extraction-text-hashingvectorizer" title="Link to this heading">¶</a></h2>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This is an example showing how scikit-learn can be used for classification using an out-of-core..."><img alt="" src="../../_images/sphx_glr_plot_out_of_core_classification_thumb.png" />
<p><a class="reference internal" href="../../auto_examples/applications/plot_out_of_core_classification.html#sphx-glr-auto-examples-applications-plot-out-of-core-classification-py"><span class="std std-ref">Out-of-core classification of text documents</span></a></p>
  <div class="sphx-glr-thumbnail-title">Out-of-core classification of text documents</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This is an example showing how the scikit-learn API can be used to cluster documents by topics ..."><img alt="" src="../../_images/sphx_glr_plot_document_clustering_thumb.png" />
<p><a class="reference internal" href="../../auto_examples/text/plot_document_clustering.html#sphx-glr-auto-examples-text-plot-document-clustering-py"><span class="std std-ref">Clustering text documents using k-means</span></a></p>
  <div class="sphx-glr-thumbnail-title">Clustering text documents using k-means</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example we illustrate text vectorization, which is the process of representing non-nume..."><img alt="" src="../../_images/sphx_glr_plot_hashing_vs_dict_vectorizer_thumb.png" />
<p><a class="reference internal" href="../../auto_examples/text/plot_hashing_vs_dict_vectorizer.html#sphx-glr-auto-examples-text-plot-hashing-vs-dict-vectorizer-py"><span class="std std-ref">FeatureHasher and DictVectorizer Comparison</span></a></p>
  <div class="sphx-glr-thumbnail-title">FeatureHasher and DictVectorizer Comparison</div>
</div></div><div class="clearer"></div></section>
</section>


      </div>
    <div class="container">
      <footer class="sk-content-footer">
            &copy; 2007 - 2023, scikit-learn developers (BSD License).
          <a href="../../_sources/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.rst.txt" rel="nofollow">Show this page source</a>
      </footer>
    </div>
  </div>
</div>
<script src="../../_static/js/vendor/bootstrap.min.js"></script>

<script>
    window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
    ga('create', 'UA-22606712-2', 'auto');
    ga('set', 'anonymizeIp', true);
    ga('send', 'pageview');
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>



<script defer data-domain="scikit-learn.org" src="https://views.scientific-python.org/js/script.js">
</script>


<script src="../../_static/clipboard.min.js"></script>
<script src="../../_static/copybutton.js"></script>

<script>
$(document).ready(function() {
    /* Add a [>>>] button on the top-right corner of code samples to hide
     * the >>> and ... prompts and the output and thus make the code
     * copyable. */
    var div = $('.highlight-python .highlight,' +
                '.highlight-python3 .highlight,' +
                '.highlight-pycon .highlight,' +
		'.highlight-default .highlight')
    var pre = div.find('pre');

    // get the styles from the current theme
    pre.parent().parent().css('position', 'relative');

    // create and add the button to all the code blocks that contain >>>
    div.each(function(index) {
        var jthis = $(this);
        // tracebacks (.gt) contain bare text elements that need to be
        // wrapped in a span to work with .nextUntil() (see later)
        jthis.find('pre:has(.gt)').contents().filter(function() {
            return ((this.nodeType == 3) && (this.data.trim().length > 0));
        }).wrap('<span>');
    });

	/*** Add permalink buttons next to glossary terms ***/
	$('dl.glossary > dt[id]').append(function() {
		return ('<a class="headerlink" href="#' +
			    this.getAttribute('id') +
			    '" title="Permalink to this term">¶</a>');
	});
});

</script>
    
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    
</body>
</html>