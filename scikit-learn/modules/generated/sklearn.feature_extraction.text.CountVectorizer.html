

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="sklearn.feature_extraction.text.CountVectorizer" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://scikit-learn/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html" />
<meta property="og:site_name" content="scikit-learn" />
<meta property="og:description" content="Examples using sklearn.feature_extraction.text.CountVectorizer: Topic extraction with Non-negative Matrix Factorization and Latent Dirichlet Allocation Semi-supervised Classification on a Text Data..." />
<meta property="og:image" content="https://scikit-learn/stable/_images/sphx_glr_plot_topics_extraction_with_nmf_lda_thumb.png" />
<meta property="og:image:alt" content="" />
<meta name="description" content="Examples using sklearn.feature_extraction.text.CountVectorizer: Topic extraction with Non-negative Matrix Factorization and Latent Dirichlet Allocation Semi-supervised Classification on a Text Data..." />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <title>sklearn.feature_extraction.text.CountVectorizer &mdash; scikit-learn 1.3.2 documentation</title>
  
  <link rel="canonical" href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html" />

  
  <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  

  <link rel="stylesheet" href="../../_static/css/vendor/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/plot_directive.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
<script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
<script src="../../_static/js/vendor/jquery-3.6.3.slim.min.js"></script> 
</head>
<body>






<nav id="navbar" class="sk-docs-navbar navbar navbar-expand-md navbar-light bg-light py-0">
  <div class="container-fluid sk-docs-container px-0">
      <a class="navbar-brand py-0" href="../../index.html">
        <img
          class="sk-brand-img"
          src="../../_static/scikit-learn-logo-small.png"
          alt="logo"/>
      </a>
    <button
      id="sk-navbar-toggler"
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="sk-navbar-collapse collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../install.html">Install</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../user_guide.html">User Guide</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../classes.html">API</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../auto_examples/index.html">Examples</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" target="_blank" rel="noopener noreferrer" href="https://blog.scikit-learn.org/">Community</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../getting_started.html" >Getting Started</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../tutorial/index.html" >Tutorial</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../whats_new/v1.3.html" >What's new</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../glossary.html" >Glossary</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://scikit-learn.org/dev/developers/index.html" target="_blank" rel="noopener noreferrer">Development</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../faq.html" >FAQ</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../support.html" >Support</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../related_projects.html" >Related packages</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../roadmap.html" >Roadmap</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../governance.html" >Governance</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../about.html" >About us</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://github.com/scikit-learn/scikit-learn" >GitHub</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://scikit-learn.org/dev/versions.html" >Other Versions and Download</a>
        </li>
        <li class="nav-item dropdown nav-more-item-dropdown">
          <a class="sk-nav-link nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">More</a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdown">
              <a class="sk-nav-dropdown-item dropdown-item" href="../../getting_started.html" >Getting Started</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../tutorial/index.html" >Tutorial</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../whats_new/v1.3.html" >What's new</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../glossary.html" >Glossary</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://scikit-learn.org/dev/developers/index.html" target="_blank" rel="noopener noreferrer">Development</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../faq.html" >FAQ</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../support.html" >Support</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../related_projects.html" >Related packages</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../roadmap.html" >Roadmap</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../governance.html" >Governance</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../about.html" >About us</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://github.com/scikit-learn/scikit-learn" >GitHub</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://scikit-learn.org/dev/versions.html" >Other Versions and Download</a>
          </div>
        </li>
      </ul>
      <div id="searchbox" role="search">
          <div class="searchformwrapper">
          <form class="search" action="../../search.html" method="get">
            <input class="sk-search-text-input" type="text" name="q" aria-labelledby="searchlabel" />
            <input class="sk-search-text-btn" type="submit" value="Go" />
          </form>
          </div>
      </div>
    </div>
  </div>
</nav>
<div class="d-flex" id="sk-doc-wrapper">
    <input type="checkbox" name="sk-toggle-checkbox" id="sk-toggle-checkbox">
    <label id="sk-sidemenu-toggle" class="sk-btn-toggle-toc btn sk-btn-primary" for="sk-toggle-checkbox">Toggle Menu</label>
    <div id="sk-sidebar-wrapper" class="border-right">
      <div class="sk-sidebar-toc-wrapper">
        <div class="btn-group w-100 mb-2" role="group" aria-label="rellinks">
            <a href="sklearn.feature_extraction.image.PatchExtractor.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="sklearn.feature_extraction.image.PatchExtractor">Prev</a><a href="../classes.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="API Reference">Up</a>
            <a href="sklearn.feature_extraction.text.HashingVectorizer.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="sklearn.feature_extraction.text.HashingVectorizer">Next</a>
        </div>
        <div class="alert alert-danger p-1 mb-2" role="alert">
          <p class="text-center mb-0">
          <strong>scikit-learn 1.3.2</strong><br/>
          <a href="http://scikit-learn.org/dev/versions.html">Other versions</a>
          </p>
        </div>
        <div class="alert alert-warning p-1 mb-2" role="alert">
          <p class="text-center mb-0">
            Please <a class="font-weight-bold" href="../../about.html#citing-scikit-learn"><string>cite us</string></a> if you use the software.
          </p>
        </div>
            <div class="sk-sidebar-toc">
              <ul>
<li><a class="reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.feature_extraction.text</span></code>.CountVectorizer</a><ul>
<li><a class="reference internal" href="#sklearn.feature_extraction.text.CountVectorizer"><code class="docutils literal notranslate"><span class="pre">CountVectorizer</span></code></a><ul>
<li><a class="reference internal" href="#sklearn.feature_extraction.text.CountVectorizer.build_analyzer"><code class="docutils literal notranslate"><span class="pre">CountVectorizer.build_analyzer</span></code></a></li>
<li><a class="reference internal" href="#sklearn.feature_extraction.text.CountVectorizer.build_preprocessor"><code class="docutils literal notranslate"><span class="pre">CountVectorizer.build_preprocessor</span></code></a></li>
<li><a class="reference internal" href="#sklearn.feature_extraction.text.CountVectorizer.build_tokenizer"><code class="docutils literal notranslate"><span class="pre">CountVectorizer.build_tokenizer</span></code></a></li>
<li><a class="reference internal" href="#sklearn.feature_extraction.text.CountVectorizer.decode"><code class="docutils literal notranslate"><span class="pre">CountVectorizer.decode</span></code></a></li>
<li><a class="reference internal" href="#sklearn.feature_extraction.text.CountVectorizer.fit"><code class="docutils literal notranslate"><span class="pre">CountVectorizer.fit</span></code></a></li>
<li><a class="reference internal" href="#sklearn.feature_extraction.text.CountVectorizer.fit_transform"><code class="docutils literal notranslate"><span class="pre">CountVectorizer.fit_transform</span></code></a></li>
<li><a class="reference internal" href="#sklearn.feature_extraction.text.CountVectorizer.get_feature_names_out"><code class="docutils literal notranslate"><span class="pre">CountVectorizer.get_feature_names_out</span></code></a></li>
<li><a class="reference internal" href="#sklearn.feature_extraction.text.CountVectorizer.get_metadata_routing"><code class="docutils literal notranslate"><span class="pre">CountVectorizer.get_metadata_routing</span></code></a></li>
<li><a class="reference internal" href="#sklearn.feature_extraction.text.CountVectorizer.get_params"><code class="docutils literal notranslate"><span class="pre">CountVectorizer.get_params</span></code></a></li>
<li><a class="reference internal" href="#sklearn.feature_extraction.text.CountVectorizer.get_stop_words"><code class="docutils literal notranslate"><span class="pre">CountVectorizer.get_stop_words</span></code></a></li>
<li><a class="reference internal" href="#sklearn.feature_extraction.text.CountVectorizer.inverse_transform"><code class="docutils literal notranslate"><span class="pre">CountVectorizer.inverse_transform</span></code></a></li>
<li><a class="reference internal" href="#sklearn.feature_extraction.text.CountVectorizer.set_fit_request"><code class="docutils literal notranslate"><span class="pre">CountVectorizer.set_fit_request</span></code></a></li>
<li><a class="reference internal" href="#sklearn.feature_extraction.text.CountVectorizer.set_params"><code class="docutils literal notranslate"><span class="pre">CountVectorizer.set_params</span></code></a></li>
<li><a class="reference internal" href="#sklearn.feature_extraction.text.CountVectorizer.set_transform_request"><code class="docutils literal notranslate"><span class="pre">CountVectorizer.set_transform_request</span></code></a></li>
<li><a class="reference internal" href="#sklearn.feature_extraction.text.CountVectorizer.transform"><code class="docutils literal notranslate"><span class="pre">CountVectorizer.transform</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#examples-using-sklearn-feature-extraction-text-countvectorizer">Examples using <code class="docutils literal notranslate"><span class="pre">sklearn.feature_extraction.text.CountVectorizer</span></code></a></li>
</ul>
</li>
</ul>

            </div>
      </div>
    </div>
    <div id="sk-page-content-wrapper">
      <div class="sk-page-content container-fluid body px-md-3" role="main">
        
  <section id="sklearn-feature-extraction-text-countvectorizer">
<h1><a class="reference internal" href="../classes.html#module-sklearn.feature_extraction.text" title="sklearn.feature_extraction.text"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.feature_extraction.text</span></code></a>.CountVectorizer<a class="headerlink" href="#sklearn-feature-extraction-text-countvectorizer" title="Link to this heading">¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="sklearn.feature_extraction.text.CountVectorizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">sklearn.feature_extraction.text.</span></span><span class="sig-name descname"><span class="pre">CountVectorizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input='content'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoding='utf-8'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decode_error='strict'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strip_accents=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lowercase=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preprocessor=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tokenizer=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop_words=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_pattern='(?u)\\b\\w\\w+\\b'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ngram_range=(1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">1)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">analyzer='word'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_df=1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_df=1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_features=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocabulary=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">binary=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype=&lt;class</span> <span class="pre">'numpy.int64'&gt;</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.feature_extraction.text.CountVectorizer" title="Link to this definition">¶</a></dt>
<dd><p>Convert a collection of text documents to a matrix of token counts.</p>
<p>This implementation produces a sparse representation of the counts using
scipy.sparse.csr_matrix.</p>
<p>If you do not provide an a-priori dictionary and you do not use an analyzer
that does some kind of feature selection then the number of features will
be equal to the vocabulary size found by analyzing the data.</p>
<p>For an efficiency comparision of the different feature extractors, see
<a class="reference internal" href="../../auto_examples/text/plot_hashing_vs_dict_vectorizer.html#sphx-glr-auto-examples-text-plot-hashing-vs-dict-vectorizer-py"><span class="std std-ref">FeatureHasher and DictVectorizer Comparison</span></a>.</p>
<p>Read more in the <a class="reference internal" href="../feature_extraction.html#text-feature-extraction"><span class="std std-ref">User Guide</span></a>.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>input</strong><span class="classifier">{‘filename’, ‘file’, ‘content’}, default=’content’</span></dt><dd><ul class="simple">
<li><p>If <code class="docutils literal notranslate"><span class="pre">'filename'</span></code>, the sequence passed as an argument to fit is
expected to be a list of filenames that need reading to fetch
the raw content to analyze.</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">'file'</span></code>, the sequence items must have a ‘read’ method (file-like
object) that is called to fetch the bytes in memory.</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">'content'</span></code>, the input is expected to be a sequence of items that
can be of type string or byte.</p></li>
</ul>
</dd>
<dt><strong>encoding</strong><span class="classifier">str, default=’utf-8’</span></dt><dd><p>If bytes or files are given to analyze, this encoding is used to
decode.</p>
</dd>
<dt><strong>decode_error</strong><span class="classifier">{‘strict’, ‘ignore’, ‘replace’}, default=’strict’</span></dt><dd><p>Instruction on what to do if a byte sequence is given to analyze that
contains characters not of the given <code class="docutils literal notranslate"><span class="pre">encoding</span></code>. By default, it is
‘strict’, meaning that a UnicodeDecodeError will be raised. Other
values are ‘ignore’ and ‘replace’.</p>
</dd>
<dt><strong>strip_accents</strong><span class="classifier">{‘ascii’, ‘unicode’} or callable, default=None</span></dt><dd><p>Remove accents and perform other character normalization
during the preprocessing step.
‘ascii’ is a fast method that only works on characters that have
a direct ASCII mapping.
‘unicode’ is a slightly slower method that works on any characters.
None (default) means no character normalization is performed.</p>
<p>Both ‘ascii’ and ‘unicode’ use NFKD normalization from
<a class="reference external" href="https://docs.python.org/3/library/unicodedata.html#unicodedata.normalize" title="(in Python v3.12)"><code class="xref py py-func docutils literal notranslate"><span class="pre">unicodedata.normalize</span></code></a>.</p>
</dd>
<dt><strong>lowercase</strong><span class="classifier">bool, default=True</span></dt><dd><p>Convert all characters to lowercase before tokenizing.</p>
</dd>
<dt><strong>preprocessor</strong><span class="classifier">callable, default=None</span></dt><dd><p>Override the preprocessing (strip_accents and lowercase) stage while
preserving the tokenizing and n-grams generation steps.
Only applies if <code class="docutils literal notranslate"><span class="pre">analyzer</span></code> is not callable.</p>
</dd>
<dt><strong>tokenizer</strong><span class="classifier">callable, default=None</span></dt><dd><p>Override the string tokenization step while preserving the
preprocessing and n-grams generation steps.
Only applies if <code class="docutils literal notranslate"><span class="pre">analyzer</span> <span class="pre">==</span> <span class="pre">'word'</span></code>.</p>
</dd>
<dt><strong>stop_words</strong><span class="classifier">{‘english’}, list, default=None</span></dt><dd><p>If ‘english’, a built-in stop word list for English is used.
There are several known issues with ‘english’ and you should
consider an alternative (see <a class="reference internal" href="../feature_extraction.html#stop-words"><span class="std std-ref">Using stop words</span></a>).</p>
<p>If a list, that list is assumed to contain stop words, all of which
will be removed from the resulting tokens.
Only applies if <code class="docutils literal notranslate"><span class="pre">analyzer</span> <span class="pre">==</span> <span class="pre">'word'</span></code>.</p>
<p>If None, no stop words will be used. In this case, setting <code class="docutils literal notranslate"><span class="pre">max_df</span></code>
to a higher value, such as in the range (0.7, 1.0), can automatically detect
and filter stop words based on intra corpus document frequency of terms.</p>
</dd>
<dt><strong>token_pattern</strong><span class="classifier">str or None, default=r”(?u)\b\w\w+\b”</span></dt><dd><p>Regular expression denoting what constitutes a “token”, only used
if <code class="docutils literal notranslate"><span class="pre">analyzer</span> <span class="pre">==</span> <span class="pre">'word'</span></code>. The default regexp select tokens of 2
or more alphanumeric characters (punctuation is completely ignored
and always treated as a token separator).</p>
<p>If there is a capturing group in token_pattern then the
captured group content, not the entire match, becomes the token.
At most one capturing group is permitted.</p>
</dd>
<dt><strong>ngram_range</strong><span class="classifier">tuple (min_n, max_n), default=(1, 1)</span></dt><dd><p>The lower and upper boundary of the range of n-values for different
word n-grams or char n-grams to be extracted. All values of n such
such that min_n &lt;= n &lt;= max_n will be used. For example an
<code class="docutils literal notranslate"><span class="pre">ngram_range</span></code> of <code class="docutils literal notranslate"><span class="pre">(1,</span> <span class="pre">1)</span></code> means only unigrams, <code class="docutils literal notranslate"><span class="pre">(1,</span> <span class="pre">2)</span></code> means
unigrams and bigrams, and <code class="docutils literal notranslate"><span class="pre">(2,</span> <span class="pre">2)</span></code> means only bigrams.
Only applies if <code class="docutils literal notranslate"><span class="pre">analyzer</span></code> is not callable.</p>
</dd>
<dt><strong>analyzer</strong><span class="classifier">{‘word’, ‘char’, ‘char_wb’} or callable, default=’word’</span></dt><dd><p>Whether the feature should be made of word n-gram or character
n-grams.
Option ‘char_wb’ creates character n-grams only from text inside
word boundaries; n-grams at the edges of words are padded with space.</p>
<p>If a callable is passed it is used to extract the sequence of features
out of the raw, unprocessed input.</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.21.</span></p>
</div>
<p>Since v0.21, if <code class="docutils literal notranslate"><span class="pre">input</span></code> is <code class="docutils literal notranslate"><span class="pre">filename</span></code> or <code class="docutils literal notranslate"><span class="pre">file</span></code>, the data is
first read from the file and then passed to the given callable
analyzer.</p>
</dd>
<dt><strong>max_df</strong><span class="classifier">float in range [0.0, 1.0] or int, default=1.0</span></dt><dd><p>When building the vocabulary ignore terms that have a document
frequency strictly higher than the given threshold (corpus-specific
stop words).
If float, the parameter represents a proportion of documents, integer
absolute counts.
This parameter is ignored if vocabulary is not None.</p>
</dd>
<dt><strong>min_df</strong><span class="classifier">float in range [0.0, 1.0] or int, default=1</span></dt><dd><p>When building the vocabulary ignore terms that have a document
frequency strictly lower than the given threshold. This value is also
called cut-off in the literature.
If float, the parameter represents a proportion of documents, integer
absolute counts.
This parameter is ignored if vocabulary is not None.</p>
</dd>
<dt><strong>max_features</strong><span class="classifier">int, default=None</span></dt><dd><p>If not None, build a vocabulary that only consider the top
<code class="docutils literal notranslate"><span class="pre">max_features</span></code> ordered by term frequency across the corpus.
Otherwise, all features are used.</p>
<p>This parameter is ignored if vocabulary is not None.</p>
</dd>
<dt><strong>vocabulary</strong><span class="classifier">Mapping or iterable, default=None</span></dt><dd><p>Either a Mapping (e.g., a dict) where keys are terms and values are
indices in the feature matrix, or an iterable over terms. If not
given, a vocabulary is determined from the input documents. Indices
in the mapping should not be repeated and should not have any gap
between 0 and the largest index.</p>
</dd>
<dt><strong>binary</strong><span class="classifier">bool, default=False</span></dt><dd><p>If True, all non zero counts are set to 1. This is useful for discrete
probabilistic models that model binary events rather than integer
counts.</p>
</dd>
<dt><strong>dtype</strong><span class="classifier">dtype, default=np.int64</span></dt><dd><p>Type of the matrix returned by fit_transform() or transform().</p>
</dd>
</dl>
</dd>
<dt class="field-even">Attributes<span class="colon">:</span></dt>
<dd class="field-even"><dl>
<dt><strong>vocabulary_</strong><span class="classifier">dict</span></dt><dd><p>A mapping of terms to feature indices.</p>
</dd>
<dt><strong>fixed_vocabulary_</strong><span class="classifier">bool</span></dt><dd><p>True if a fixed vocabulary of term to indices mapping
is provided by the user.</p>
</dd>
<dt><strong>stop_words_</strong><span class="classifier">set</span></dt><dd><p>Terms that were ignored because they either:</p>
<blockquote>
<div><ul class="simple">
<li><p>occurred in too many documents (<code class="docutils literal notranslate"><span class="pre">max_df</span></code>)</p></li>
<li><p>occurred in too few documents (<code class="docutils literal notranslate"><span class="pre">min_df</span></code>)</p></li>
<li><p>were cut off by feature selection (<code class="docutils literal notranslate"><span class="pre">max_features</span></code>).</p></li>
</ul>
</div></blockquote>
<p>This is only available if no vocabulary was given.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="sklearn.feature_extraction.text.HashingVectorizer.html#sklearn.feature_extraction.text.HashingVectorizer" title="sklearn.feature_extraction.text.HashingVectorizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">HashingVectorizer</span></code></a></dt><dd><p>Convert a collection of text documents to a matrix of token counts.</p>
</dd>
<dt><a class="reference internal" href="sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer" title="sklearn.feature_extraction.text.TfidfVectorizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TfidfVectorizer</span></code></a></dt><dd><p>Convert a collection of raw documents to a matrix of TF-IDF features.</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>The <code class="docutils literal notranslate"><span class="pre">stop_words_</span></code> attribute can get large and increase the model size
when pickling. This attribute is provided only for introspection and can
be safely removed using delattr or set to None before pickling.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">corpus</span> <span class="o">=</span> <span class="p">[</span>
<span class="gp">... </span>    <span class="s1">&#39;This is the first document.&#39;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="s1">&#39;This document is the second document.&#39;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="s1">&#39;And this is the third one.&#39;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="s1">&#39;Is this the first document?&#39;</span><span class="p">,</span>
<span class="gp">... </span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vectorizer</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">()</span>
<span class="go">array([&#39;and&#39;, &#39;document&#39;, &#39;first&#39;, &#39;is&#39;, &#39;one&#39;, &#39;second&#39;, &#39;the&#39;, &#39;third&#39;,</span>
<span class="go">       &#39;this&#39;], ...)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">toarray</span><span class="p">())</span>
<span class="go">[[0 1 1 1 0 0 1 0 1]</span>
<span class="go"> [0 2 0 1 0 1 1 0 1]</span>
<span class="go"> [1 0 0 1 1 0 1 1 1]</span>
<span class="go"> [0 1 1 1 0 0 1 0 1]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vectorizer2</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">analyzer</span><span class="o">=</span><span class="s1">&#39;word&#39;</span><span class="p">,</span> <span class="n">ngram_range</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X2</span> <span class="o">=</span> <span class="n">vectorizer2</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vectorizer2</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">()</span>
<span class="go">array([&#39;and this&#39;, &#39;document is&#39;, &#39;first document&#39;, &#39;is the&#39;, &#39;is this&#39;,</span>
<span class="go">       &#39;second document&#39;, &#39;the first&#39;, &#39;the second&#39;, &#39;the third&#39;, &#39;third one&#39;,</span>
<span class="go">       &#39;this document&#39;, &#39;this is&#39;, &#39;this the&#39;], ...)</span>
<span class="go"> &gt;&gt;&gt; print(X2.toarray())</span>
<span class="go"> [[0 0 1 1 0 0 1 0 0 0 0 1 0]</span>
<span class="go"> [0 1 0 1 0 1 0 1 0 0 1 0 0]</span>
<span class="go"> [1 0 0 1 0 0 0 0 1 1 0 1 0]</span>
<span class="go"> [0 0 1 0 1 0 1 0 0 0 0 0 1]]</span>
</pre></div>
</div>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.feature_extraction.text.CountVectorizer.build_analyzer" title="sklearn.feature_extraction.text.CountVectorizer.build_analyzer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">build_analyzer</span></code></a>()</p></td>
<td><p>Return a callable to process input data.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.feature_extraction.text.CountVectorizer.build_preprocessor" title="sklearn.feature_extraction.text.CountVectorizer.build_preprocessor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">build_preprocessor</span></code></a>()</p></td>
<td><p>Return a function to preprocess the text before tokenization.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.feature_extraction.text.CountVectorizer.build_tokenizer" title="sklearn.feature_extraction.text.CountVectorizer.build_tokenizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">build_tokenizer</span></code></a>()</p></td>
<td><p>Return a function that splits a string into a sequence of tokens.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.feature_extraction.text.CountVectorizer.decode" title="sklearn.feature_extraction.text.CountVectorizer.decode"><code class="xref py py-obj docutils literal notranslate"><span class="pre">decode</span></code></a>(doc)</p></td>
<td><p>Decode the input into a string of unicode symbols.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.feature_extraction.text.CountVectorizer.fit" title="sklearn.feature_extraction.text.CountVectorizer.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>(raw_documents[, y])</p></td>
<td><p>Learn a vocabulary dictionary of all tokens in the raw documents.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.feature_extraction.text.CountVectorizer.fit_transform" title="sklearn.feature_extraction.text.CountVectorizer.fit_transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit_transform</span></code></a>(raw_documents[, y])</p></td>
<td><p>Learn the vocabulary dictionary and return document-term matrix.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.feature_extraction.text.CountVectorizer.get_feature_names_out" title="sklearn.feature_extraction.text.CountVectorizer.get_feature_names_out"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_feature_names_out</span></code></a>([input_features])</p></td>
<td><p>Get output feature names for transformation.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.feature_extraction.text.CountVectorizer.get_metadata_routing" title="sklearn.feature_extraction.text.CountVectorizer.get_metadata_routing"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_metadata_routing</span></code></a>()</p></td>
<td><p>Get metadata routing of this object.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.feature_extraction.text.CountVectorizer.get_params" title="sklearn.feature_extraction.text.CountVectorizer.get_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_params</span></code></a>([deep])</p></td>
<td><p>Get parameters for this estimator.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.feature_extraction.text.CountVectorizer.get_stop_words" title="sklearn.feature_extraction.text.CountVectorizer.get_stop_words"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_stop_words</span></code></a>()</p></td>
<td><p>Build or fetch the effective stop words list.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.feature_extraction.text.CountVectorizer.inverse_transform" title="sklearn.feature_extraction.text.CountVectorizer.inverse_transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">inverse_transform</span></code></a>(X)</p></td>
<td><p>Return terms per document with nonzero entries in X.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.feature_extraction.text.CountVectorizer.set_fit_request" title="sklearn.feature_extraction.text.CountVectorizer.set_fit_request"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_fit_request</span></code></a>(*[, raw_documents])</p></td>
<td><p>Request metadata passed to the <code class="docutils literal notranslate"><span class="pre">fit</span></code> method.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.feature_extraction.text.CountVectorizer.set_params" title="sklearn.feature_extraction.text.CountVectorizer.set_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_params</span></code></a>(**params)</p></td>
<td><p>Set the parameters of this estimator.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.feature_extraction.text.CountVectorizer.set_transform_request" title="sklearn.feature_extraction.text.CountVectorizer.set_transform_request"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_transform_request</span></code></a>(*[, raw_documents])</p></td>
<td><p>Request metadata passed to the <code class="docutils literal notranslate"><span class="pre">transform</span></code> method.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.feature_extraction.text.CountVectorizer.transform" title="sklearn.feature_extraction.text.CountVectorizer.transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">transform</span></code></a>(raw_documents)</p></td>
<td><p>Transform documents to document-term matrix.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.feature_extraction.text.CountVectorizer.build_analyzer">
<span class="sig-name descname"><span class="pre">build_analyzer</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.feature_extraction.text.CountVectorizer.build_analyzer" title="Link to this definition">¶</a></dt>
<dd><p>Return a callable to process input data.</p>
<p>The callable handles preprocessing, tokenization, and n-grams generation.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt>analyzer: callable</dt><dd><p>A function to handle preprocessing, tokenization
and n-grams generation.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.feature_extraction.text.CountVectorizer.build_preprocessor">
<span class="sig-name descname"><span class="pre">build_preprocessor</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.feature_extraction.text.CountVectorizer.build_preprocessor" title="Link to this definition">¶</a></dt>
<dd><p>Return a function to preprocess the text before tokenization.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt>preprocessor: callable</dt><dd><p>A function to preprocess the text before tokenization.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.feature_extraction.text.CountVectorizer.build_tokenizer">
<span class="sig-name descname"><span class="pre">build_tokenizer</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.feature_extraction.text.CountVectorizer.build_tokenizer" title="Link to this definition">¶</a></dt>
<dd><p>Return a function that splits a string into a sequence of tokens.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt>tokenizer: callable</dt><dd><p>A function to split a string into a sequence of tokens.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.feature_extraction.text.CountVectorizer.decode">
<span class="sig-name descname"><span class="pre">decode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">doc</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.feature_extraction.text.CountVectorizer.decode" title="Link to this definition">¶</a></dt>
<dd><p>Decode the input into a string of unicode symbols.</p>
<p>The decoding strategy depends on the vectorizer parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>doc</strong><span class="classifier">bytes or str</span></dt><dd><p>The string to decode.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>doc: str</dt><dd><p>A string of unicode symbols.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.feature_extraction.text.CountVectorizer.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">raw_documents</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.feature_extraction.text.CountVectorizer.fit" title="Link to this definition">¶</a></dt>
<dd><p>Learn a vocabulary dictionary of all tokens in the raw documents.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>raw_documents</strong><span class="classifier">iterable</span></dt><dd><p>An iterable which generates either str, unicode or file objects.</p>
</dd>
<dt><strong>y</strong><span class="classifier">None</span></dt><dd><p>This parameter is ignored.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">object</span></dt><dd><p>Fitted vectorizer.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.feature_extraction.text.CountVectorizer.fit_transform">
<span class="sig-name descname"><span class="pre">fit_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">raw_documents</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.feature_extraction.text.CountVectorizer.fit_transform" title="Link to this definition">¶</a></dt>
<dd><p>Learn the vocabulary dictionary and return document-term matrix.</p>
<p>This is equivalent to fit followed by transform, but more efficiently
implemented.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>raw_documents</strong><span class="classifier">iterable</span></dt><dd><p>An iterable which generates either str, unicode or file objects.</p>
</dd>
<dt><strong>y</strong><span class="classifier">None</span></dt><dd><p>This parameter is ignored.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array of shape (n_samples, n_features)</span></dt><dd><p>Document-term matrix.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.feature_extraction.text.CountVectorizer.get_feature_names_out">
<span class="sig-name descname"><span class="pre">get_feature_names_out</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.feature_extraction.text.CountVectorizer.get_feature_names_out" title="Link to this definition">¶</a></dt>
<dd><p>Get output feature names for transformation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>input_features</strong><span class="classifier">array-like of str or None, default=None</span></dt><dd><p>Not used, present here for API consistency by convention.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>feature_names_out</strong><span class="classifier">ndarray of str objects</span></dt><dd><p>Transformed feature names.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.feature_extraction.text.CountVectorizer.get_metadata_routing">
<span class="sig-name descname"><span class="pre">get_metadata_routing</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.feature_extraction.text.CountVectorizer.get_metadata_routing" title="Link to this definition">¶</a></dt>
<dd><p>Get metadata routing of this object.</p>
<p>Please check <a class="reference internal" href="../../metadata_routing.html#metadata-routing"><span class="std std-ref">User Guide</span></a> on how the routing
mechanism works.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>routing</strong><span class="classifier">MetadataRequest</span></dt><dd><p>A <a class="reference internal" href="sklearn.utils.metadata_routing.MetadataRequest.html#sklearn.utils.metadata_routing.MetadataRequest" title="sklearn.utils.metadata_routing.MetadataRequest"><code class="xref py py-class docutils literal notranslate"><span class="pre">MetadataRequest</span></code></a> encapsulating
routing information.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.feature_extraction.text.CountVectorizer.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.feature_extraction.text.CountVectorizer.get_params" title="Link to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>deep</strong><span class="classifier">bool, default=True</span></dt><dd><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>params</strong><span class="classifier">dict</span></dt><dd><p>Parameter names mapped to their values.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.feature_extraction.text.CountVectorizer.get_stop_words">
<span class="sig-name descname"><span class="pre">get_stop_words</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.feature_extraction.text.CountVectorizer.get_stop_words" title="Link to this definition">¶</a></dt>
<dd><p>Build or fetch the effective stop words list.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt>stop_words: list or None</dt><dd><p>A list of stop words.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.feature_extraction.text.CountVectorizer.inverse_transform">
<span class="sig-name descname"><span class="pre">inverse_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.feature_extraction.text.CountVectorizer.inverse_transform" title="Link to this definition">¶</a></dt>
<dd><p>Return terms per document with nonzero entries in X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">{array-like, sparse matrix} of shape (n_samples, n_features)</span></dt><dd><p>Document-term matrix.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>X_inv</strong><span class="classifier">list of arrays of shape (n_samples,)</span></dt><dd><p>List of arrays of terms.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.feature_extraction.text.CountVectorizer.set_fit_request">
<span class="sig-name descname"><span class="pre">set_fit_request</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw_documents</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><span class="pre">bool</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'$UNCHANGED$'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#sklearn.feature_extraction.text.CountVectorizer" title="sklearn.feature_extraction.text.CountVectorizer"><span class="pre">CountVectorizer</span></a></span></span><a class="headerlink" href="#sklearn.feature_extraction.text.CountVectorizer.set_fit_request" title="Link to this definition">¶</a></dt>
<dd><p>Request metadata passed to the <code class="docutils literal notranslate"><span class="pre">fit</span></code> method.</p>
<p>Note that this method is only relevant if
<code class="docutils literal notranslate"><span class="pre">enable_metadata_routing=True</span></code> (see <a class="reference internal" href="sklearn.set_config.html#sklearn.set_config" title="sklearn.set_config"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.set_config</span></code></a>).
Please see <a class="reference internal" href="../../metadata_routing.html#metadata-routing"><span class="std std-ref">User Guide</span></a> on how the routing
mechanism works.</p>
<p>The options for each parameter are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">True</span></code>: metadata is requested, and passed to <code class="docutils literal notranslate"><span class="pre">fit</span></code> if provided. The request is ignored if metadata is not provided.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">False</span></code>: metadata is not requested and the meta-estimator will not pass it to <code class="docutils literal notranslate"><span class="pre">fit</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">None</span></code>: metadata is not requested, and the meta-estimator will raise an error if the user provides it.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">str</span></code>: metadata should be passed to the meta-estimator with this given alias instead of the original name.</p></li>
</ul>
<p>The default (<code class="docutils literal notranslate"><span class="pre">sklearn.utils.metadata_routing.UNCHANGED</span></code>) retains the
existing request. This allows you to change the request for some
parameters and not others.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.3.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method is only relevant if this estimator is used as a
sub-estimator of a meta-estimator, e.g. used inside a
<a class="reference internal" href="sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code></a>. Otherwise it has no effect.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>raw_documents</strong><span class="classifier">str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED</span></dt><dd><p>Metadata routing for <code class="docutils literal notranslate"><span class="pre">raw_documents</span></code> parameter in <code class="docutils literal notranslate"><span class="pre">fit</span></code>.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">object</span></dt><dd><p>The updated object.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.feature_extraction.text.CountVectorizer.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.feature_extraction.text.CountVectorizer.set_params" title="Link to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as <a class="reference internal" href="sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code></a>). The latter have
parameters of the form <code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s
possible to update each component of a nested object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>**params</strong><span class="classifier">dict</span></dt><dd><p>Estimator parameters.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">estimator instance</span></dt><dd><p>Estimator instance.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.feature_extraction.text.CountVectorizer.set_transform_request">
<span class="sig-name descname"><span class="pre">set_transform_request</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw_documents</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><span class="pre">bool</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'$UNCHANGED$'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#sklearn.feature_extraction.text.CountVectorizer" title="sklearn.feature_extraction.text.CountVectorizer"><span class="pre">CountVectorizer</span></a></span></span><a class="headerlink" href="#sklearn.feature_extraction.text.CountVectorizer.set_transform_request" title="Link to this definition">¶</a></dt>
<dd><p>Request metadata passed to the <code class="docutils literal notranslate"><span class="pre">transform</span></code> method.</p>
<p>Note that this method is only relevant if
<code class="docutils literal notranslate"><span class="pre">enable_metadata_routing=True</span></code> (see <a class="reference internal" href="sklearn.set_config.html#sklearn.set_config" title="sklearn.set_config"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.set_config</span></code></a>).
Please see <a class="reference internal" href="../../metadata_routing.html#metadata-routing"><span class="std std-ref">User Guide</span></a> on how the routing
mechanism works.</p>
<p>The options for each parameter are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">True</span></code>: metadata is requested, and passed to <code class="docutils literal notranslate"><span class="pre">transform</span></code> if provided. The request is ignored if metadata is not provided.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">False</span></code>: metadata is not requested and the meta-estimator will not pass it to <code class="docutils literal notranslate"><span class="pre">transform</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">None</span></code>: metadata is not requested, and the meta-estimator will raise an error if the user provides it.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">str</span></code>: metadata should be passed to the meta-estimator with this given alias instead of the original name.</p></li>
</ul>
<p>The default (<code class="docutils literal notranslate"><span class="pre">sklearn.utils.metadata_routing.UNCHANGED</span></code>) retains the
existing request. This allows you to change the request for some
parameters and not others.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.3.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method is only relevant if this estimator is used as a
sub-estimator of a meta-estimator, e.g. used inside a
<a class="reference internal" href="sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code></a>. Otherwise it has no effect.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>raw_documents</strong><span class="classifier">str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED</span></dt><dd><p>Metadata routing for <code class="docutils literal notranslate"><span class="pre">raw_documents</span></code> parameter in <code class="docutils literal notranslate"><span class="pre">transform</span></code>.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">object</span></dt><dd><p>The updated object.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.feature_extraction.text.CountVectorizer.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">raw_documents</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.feature_extraction.text.CountVectorizer.transform" title="Link to this definition">¶</a></dt>
<dd><p>Transform documents to document-term matrix.</p>
<p>Extract token counts out of raw text documents using the vocabulary
fitted with fit or the one provided to the constructor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>raw_documents</strong><span class="classifier">iterable</span></dt><dd><p>An iterable which generates either str, unicode or file objects.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>X</strong><span class="classifier">sparse matrix of shape (n_samples, n_features)</span></dt><dd><p>Document-term matrix.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<section id="examples-using-sklearn-feature-extraction-text-countvectorizer">
<h2>Examples using <code class="docutils literal notranslate"><span class="pre">sklearn.feature_extraction.text.CountVectorizer</span></code><a class="headerlink" href="#examples-using-sklearn-feature-extraction-text-countvectorizer" title="Link to this heading">¶</a></h2>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This is an example of applying NMF and LatentDirichletAllocation on a corpus of documents and e..."><img alt="" src="../../_images/sphx_glr_plot_topics_extraction_with_nmf_lda_thumb.png" />
<p><a class="reference internal" href="../../auto_examples/applications/plot_topics_extraction_with_nmf_lda.html#sphx-glr-auto-examples-applications-plot-topics-extraction-with-nmf-lda-py"><span class="std std-ref">Topic extraction with Non-negative Matrix Factorization and Latent Dirichlet Allocation</span></a></p>
  <div class="sphx-glr-thumbnail-title">Topic extraction with Non-negative Matrix Factorization and Latent Dirichlet Allocation</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, semi-supervised classifiers are trained on the 20 newsgroups dataset (which wi..."><img alt="" src="../../_images/sphx_glr_plot_semi_supervised_newsgroups_thumb.png" />
<p><a class="reference internal" href="../../auto_examples/semi_supervised/plot_semi_supervised_newsgroups.html#sphx-glr-auto-examples-semi-supervised-plot-semi-supervised-newsgroups-py"><span class="std std-ref">Semi-supervised Classification on a Text Dataset</span></a></p>
  <div class="sphx-glr-thumbnail-title">Semi-supervised Classification on a Text Dataset</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example we illustrate text vectorization, which is the process of representing non-nume..."><img alt="" src="../../_images/sphx_glr_plot_hashing_vs_dict_vectorizer_thumb.png" />
<p><a class="reference internal" href="../../auto_examples/text/plot_hashing_vs_dict_vectorizer.html#sphx-glr-auto-examples-text-plot-hashing-vs-dict-vectorizer-py"><span class="std std-ref">FeatureHasher and DictVectorizer Comparison</span></a></p>
  <div class="sphx-glr-thumbnail-title">FeatureHasher and DictVectorizer Comparison</div>
</div></div><div class="clearer"></div></section>
</section>


      </div>
    <div class="container">
      <footer class="sk-content-footer">
            &copy; 2007 - 2023, scikit-learn developers (BSD License).
          <a href="../../_sources/modules/generated/sklearn.feature_extraction.text.CountVectorizer.rst.txt" rel="nofollow">Show this page source</a>
      </footer>
    </div>
  </div>
</div>
<script src="../../_static/js/vendor/bootstrap.min.js"></script>

<script>
    window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
    ga('create', 'UA-22606712-2', 'auto');
    ga('set', 'anonymizeIp', true);
    ga('send', 'pageview');
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>



<script defer data-domain="scikit-learn.org" src="https://views.scientific-python.org/js/script.js">
</script>


<script src="../../_static/clipboard.min.js"></script>
<script src="../../_static/copybutton.js"></script>

<script>
$(document).ready(function() {
    /* Add a [>>>] button on the top-right corner of code samples to hide
     * the >>> and ... prompts and the output and thus make the code
     * copyable. */
    var div = $('.highlight-python .highlight,' +
                '.highlight-python3 .highlight,' +
                '.highlight-pycon .highlight,' +
		'.highlight-default .highlight')
    var pre = div.find('pre');

    // get the styles from the current theme
    pre.parent().parent().css('position', 'relative');

    // create and add the button to all the code blocks that contain >>>
    div.each(function(index) {
        var jthis = $(this);
        // tracebacks (.gt) contain bare text elements that need to be
        // wrapped in a span to work with .nextUntil() (see later)
        jthis.find('pre:has(.gt)').contents().filter(function() {
            return ((this.nodeType == 3) && (this.data.trim().length > 0));
        }).wrap('<span>');
    });

	/*** Add permalink buttons next to glossary terms ***/
	$('dl.glossary > dt[id]').append(function() {
		return ('<a class="headerlink" href="#' +
			    this.getAttribute('id') +
			    '" title="Permalink to this term">¶</a>');
	});
});

</script>
    
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    
</body>
</html>