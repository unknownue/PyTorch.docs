

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="sklearn.mixture.BayesianGaussianMixture" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://scikit-learn/stable/modules/generated/sklearn.mixture.BayesianGaussianMixture.html" />
<meta property="og:site_name" content="scikit-learn" />
<meta property="og:description" content="Examples using sklearn.mixture.BayesianGaussianMixture: Concentration Prior Type Analysis of Variation Bayesian Gaussian Mixture Gaussian Mixture Model Ellipsoids Gaussian Mixture Model Sine Curve" />
<meta property="og:image" content="https://scikit-learn/stable/_images/sphx_glr_plot_concentration_prior_thumb.png" />
<meta property="og:image:alt" content="" />
<meta name="description" content="Examples using sklearn.mixture.BayesianGaussianMixture: Concentration Prior Type Analysis of Variation Bayesian Gaussian Mixture Gaussian Mixture Model Ellipsoids Gaussian Mixture Model Sine Curve" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <title>sklearn.mixture.BayesianGaussianMixture &mdash; scikit-learn 1.3.2 documentation</title>
  
  <link rel="canonical" href="http://scikit-learn.org/stable/modules/generated/sklearn.mixture.BayesianGaussianMixture.html" />

  
  <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  

  <link rel="stylesheet" href="../../_static/css/vendor/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/plot_directive.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
<script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
<script src="../../_static/js/vendor/jquery-3.6.3.slim.min.js"></script> 
</head>
<body>






<nav id="navbar" class="sk-docs-navbar navbar navbar-expand-md navbar-light bg-light py-0">
  <div class="container-fluid sk-docs-container px-0">
      <a class="navbar-brand py-0" href="../../index.html">
        <img
          class="sk-brand-img"
          src="../../_static/scikit-learn-logo-small.png"
          alt="logo"/>
      </a>
    <button
      id="sk-navbar-toggler"
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="sk-navbar-collapse collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../install.html">Install</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../user_guide.html">User Guide</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../classes.html">API</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../auto_examples/index.html">Examples</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" target="_blank" rel="noopener noreferrer" href="https://blog.scikit-learn.org/">Community</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../getting_started.html" >Getting Started</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../tutorial/index.html" >Tutorial</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../whats_new/v1.3.html" >What's new</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../glossary.html" >Glossary</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://scikit-learn.org/dev/developers/index.html" target="_blank" rel="noopener noreferrer">Development</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../faq.html" >FAQ</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../support.html" >Support</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../related_projects.html" >Related packages</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../roadmap.html" >Roadmap</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../governance.html" >Governance</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../about.html" >About us</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://github.com/scikit-learn/scikit-learn" >GitHub</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://scikit-learn.org/dev/versions.html" >Other Versions and Download</a>
        </li>
        <li class="nav-item dropdown nav-more-item-dropdown">
          <a class="sk-nav-link nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">More</a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdown">
              <a class="sk-nav-dropdown-item dropdown-item" href="../../getting_started.html" >Getting Started</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../tutorial/index.html" >Tutorial</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../whats_new/v1.3.html" >What's new</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../glossary.html" >Glossary</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://scikit-learn.org/dev/developers/index.html" target="_blank" rel="noopener noreferrer">Development</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../faq.html" >FAQ</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../support.html" >Support</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../related_projects.html" >Related packages</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../roadmap.html" >Roadmap</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../governance.html" >Governance</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../about.html" >About us</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://github.com/scikit-learn/scikit-learn" >GitHub</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://scikit-learn.org/dev/versions.html" >Other Versions and Download</a>
          </div>
        </li>
      </ul>
      <div id="searchbox" role="search">
          <div class="searchformwrapper">
          <form class="search" action="../../search.html" method="get">
            <input class="sk-search-text-input" type="text" name="q" aria-labelledby="searchlabel" />
            <input class="sk-search-text-btn" type="submit" value="Go" />
          </form>
          </div>
      </div>
    </div>
  </div>
</nav>
<div class="d-flex" id="sk-doc-wrapper">
    <input type="checkbox" name="sk-toggle-checkbox" id="sk-toggle-checkbox">
    <label id="sk-sidemenu-toggle" class="sk-btn-toggle-toc btn sk-btn-primary" for="sk-toggle-checkbox">Toggle Menu</label>
    <div id="sk-sidebar-wrapper" class="border-right">
      <div class="sk-sidebar-toc-wrapper">
        <div class="btn-group w-100 mb-2" role="group" aria-label="rellinks">
            <a href="sklearn.calibration.CalibrationDisplay.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="sklearn.calibration.CalibrationDisplay">Prev</a><a href="../classes.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="API Reference">Up</a>
            <a href="sklearn.mixture.GaussianMixture.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="sklearn.mixture.GaussianMixture">Next</a>
        </div>
        <div class="alert alert-danger p-1 mb-2" role="alert">
          <p class="text-center mb-0">
          <strong>scikit-learn 1.3.2</strong><br/>
          <a href="http://scikit-learn.org/dev/versions.html">Other versions</a>
          </p>
        </div>
        <div class="alert alert-warning p-1 mb-2" role="alert">
          <p class="text-center mb-0">
            Please <a class="font-weight-bold" href="../../about.html#citing-scikit-learn"><string>cite us</string></a> if you use the software.
          </p>
        </div>
            <div class="sk-sidebar-toc">
              <ul>
<li><a class="reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.mixture</span></code>.BayesianGaussianMixture</a><ul>
<li><a class="reference internal" href="#sklearn.mixture.BayesianGaussianMixture"><code class="docutils literal notranslate"><span class="pre">BayesianGaussianMixture</span></code></a><ul>
<li><a class="reference internal" href="#sklearn.mixture.BayesianGaussianMixture.fit"><code class="docutils literal notranslate"><span class="pre">BayesianGaussianMixture.fit</span></code></a></li>
<li><a class="reference internal" href="#sklearn.mixture.BayesianGaussianMixture.fit_predict"><code class="docutils literal notranslate"><span class="pre">BayesianGaussianMixture.fit_predict</span></code></a></li>
<li><a class="reference internal" href="#sklearn.mixture.BayesianGaussianMixture.get_metadata_routing"><code class="docutils literal notranslate"><span class="pre">BayesianGaussianMixture.get_metadata_routing</span></code></a></li>
<li><a class="reference internal" href="#sklearn.mixture.BayesianGaussianMixture.get_params"><code class="docutils literal notranslate"><span class="pre">BayesianGaussianMixture.get_params</span></code></a></li>
<li><a class="reference internal" href="#sklearn.mixture.BayesianGaussianMixture.predict"><code class="docutils literal notranslate"><span class="pre">BayesianGaussianMixture.predict</span></code></a></li>
<li><a class="reference internal" href="#sklearn.mixture.BayesianGaussianMixture.predict_proba"><code class="docutils literal notranslate"><span class="pre">BayesianGaussianMixture.predict_proba</span></code></a></li>
<li><a class="reference internal" href="#sklearn.mixture.BayesianGaussianMixture.sample"><code class="docutils literal notranslate"><span class="pre">BayesianGaussianMixture.sample</span></code></a></li>
<li><a class="reference internal" href="#sklearn.mixture.BayesianGaussianMixture.score"><code class="docutils literal notranslate"><span class="pre">BayesianGaussianMixture.score</span></code></a></li>
<li><a class="reference internal" href="#sklearn.mixture.BayesianGaussianMixture.score_samples"><code class="docutils literal notranslate"><span class="pre">BayesianGaussianMixture.score_samples</span></code></a></li>
<li><a class="reference internal" href="#sklearn.mixture.BayesianGaussianMixture.set_params"><code class="docutils literal notranslate"><span class="pre">BayesianGaussianMixture.set_params</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#examples-using-sklearn-mixture-bayesiangaussianmixture">Examples using <code class="docutils literal notranslate"><span class="pre">sklearn.mixture.BayesianGaussianMixture</span></code></a></li>
</ul>
</li>
</ul>

            </div>
      </div>
    </div>
    <div id="sk-page-content-wrapper">
      <div class="sk-page-content container-fluid body px-md-3" role="main">
        
  <section id="sklearn-mixture-bayesiangaussianmixture">
<h1><a class="reference internal" href="../classes.html#module-sklearn.mixture" title="sklearn.mixture"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.mixture</span></code></a>.BayesianGaussianMixture<a class="headerlink" href="#sklearn-mixture-bayesiangaussianmixture" title="Link to this heading">¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="sklearn.mixture.BayesianGaussianMixture">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">sklearn.mixture.</span></span><span class="sig-name descname"><span class="pre">BayesianGaussianMixture</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_components</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">covariance_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'full'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg_covar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-06</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'kmeans'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_concentration_prior_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'dirichlet_process'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_concentration_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean_precision_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">degrees_of_freedom_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">covariance_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warm_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose_interval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.mixture.BayesianGaussianMixture" title="Link to this definition">¶</a></dt>
<dd><p>Variational Bayesian estimation of a Gaussian mixture.</p>
<p>This class allows to infer an approximate posterior distribution over the
parameters of a Gaussian mixture distribution. The effective number of
components can be inferred from the data.</p>
<p>This class implements two types of prior for the weights distribution: a
finite mixture model with Dirichlet distribution and an infinite mixture
model with the Dirichlet Process. In practice Dirichlet Process inference
algorithm is approximated and uses a truncated distribution with a fixed
maximum number of components (called the Stick-breaking representation).
The number of components actually used almost always depends on the data.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.18.</span></p>
</div>
<p>Read more in the <a class="reference internal" href="../mixture.html#bgmm"><span class="std std-ref">User Guide</span></a>.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>n_components</strong><span class="classifier">int, default=1</span></dt><dd><p>The number of mixture components. Depending on the data and the value
of the <code class="docutils literal notranslate"><span class="pre">weight_concentration_prior</span></code> the model can decide to not use
all the components by setting some component <code class="docutils literal notranslate"><span class="pre">weights_</span></code> to values very
close to zero. The number of effective components is therefore smaller
than n_components.</p>
</dd>
<dt><strong>covariance_type</strong><span class="classifier">{‘full’, ‘tied’, ‘diag’, ‘spherical’}, default=’full’</span></dt><dd><p>String describing the type of covariance parameters to use.
Must be one of:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="s1">&#39;full&#39;</span> <span class="p">(</span><span class="n">each</span> <span class="n">component</span> <span class="n">has</span> <span class="n">its</span> <span class="n">own</span> <span class="n">general</span> <span class="n">covariance</span> <span class="n">matrix</span><span class="p">),</span>
<span class="s1">&#39;tied&#39;</span> <span class="p">(</span><span class="nb">all</span> <span class="n">components</span> <span class="n">share</span> <span class="n">the</span> <span class="n">same</span> <span class="n">general</span> <span class="n">covariance</span> <span class="n">matrix</span><span class="p">),</span>
<span class="s1">&#39;diag&#39;</span> <span class="p">(</span><span class="n">each</span> <span class="n">component</span> <span class="n">has</span> <span class="n">its</span> <span class="n">own</span> <span class="n">diagonal</span> <span class="n">covariance</span> <span class="n">matrix</span><span class="p">),</span>
<span class="s1">&#39;spherical&#39;</span> <span class="p">(</span><span class="n">each</span> <span class="n">component</span> <span class="n">has</span> <span class="n">its</span> <span class="n">own</span> <span class="n">single</span> <span class="n">variance</span><span class="p">)</span><span class="o">.</span>
</pre></div>
</div>
</dd>
<dt><strong>tol</strong><span class="classifier">float, default=1e-3</span></dt><dd><p>The convergence threshold. EM iterations will stop when the
lower bound average gain on the likelihood (of the training data with
respect to the model) is below this threshold.</p>
</dd>
<dt><strong>reg_covar</strong><span class="classifier">float, default=1e-6</span></dt><dd><p>Non-negative regularization added to the diagonal of covariance.
Allows to assure that the covariance matrices are all positive.</p>
</dd>
<dt><strong>max_iter</strong><span class="classifier">int, default=100</span></dt><dd><p>The number of EM iterations to perform.</p>
</dd>
<dt><strong>n_init</strong><span class="classifier">int, default=1</span></dt><dd><p>The number of initializations to perform. The result with the highest
lower bound value on the likelihood is kept.</p>
</dd>
<dt><strong>init_params</strong><span class="classifier">{‘kmeans’, ‘k-means++’, ‘random’, ‘random_from_data’},     default=’kmeans’</span></dt><dd><p>The method used to initialize the weights, the means and the
covariances.
String must be one of:</p>
<blockquote>
<div><p>‘kmeans’ : responsibilities are initialized using kmeans.
‘k-means++’ : use the k-means++ method to initialize.
‘random’ : responsibilities are initialized randomly.
‘random_from_data’ : initial means are randomly selected data points.</p>
</div></blockquote>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version v1.1: </span><code class="docutils literal notranslate"><span class="pre">init_params</span></code> now accepts ‘random_from_data’ and ‘k-means++’ as
initialization methods.</p>
</div>
</dd>
<dt><strong>weight_concentration_prior_type</strong><span class="classifier">{‘dirichlet_process’, ‘dirichlet_distribution’},             default=’dirichlet_process’</span></dt><dd><p>String describing the type of the weight concentration prior.</p>
</dd>
<dt><strong>weight_concentration_prior</strong><span class="classifier">float or None, default=None</span></dt><dd><p>The dirichlet concentration of each component on the weight
distribution (Dirichlet). This is commonly called gamma in the
literature. The higher concentration puts more mass in
the center and will lead to more components being active, while a lower
concentration parameter will lead to more mass at the edge of the
mixture weights simplex. The value of the parameter must be greater
than 0. If it is None, it’s set to <code class="docutils literal notranslate"><span class="pre">1.</span> <span class="pre">/</span> <span class="pre">n_components</span></code>.</p>
</dd>
<dt><strong>mean_precision_prior</strong><span class="classifier">float or None, default=None</span></dt><dd><p>The precision prior on the mean distribution (Gaussian).
Controls the extent of where means can be placed. Larger
values concentrate the cluster means around <code class="docutils literal notranslate"><span class="pre">mean_prior</span></code>.
The value of the parameter must be greater than 0.
If it is None, it is set to 1.</p>
</dd>
<dt><strong>mean_prior</strong><span class="classifier">array-like, shape (n_features,), default=None</span></dt><dd><p>The prior on the mean distribution (Gaussian).
If it is None, it is set to the mean of X.</p>
</dd>
<dt><strong>degrees_of_freedom_prior</strong><span class="classifier">float or None, default=None</span></dt><dd><p>The prior of the number of degrees of freedom on the covariance
distributions (Wishart). If it is None, it’s set to <code class="docutils literal notranslate"><span class="pre">n_features</span></code>.</p>
</dd>
<dt><strong>covariance_prior</strong><span class="classifier">float or array-like, default=None</span></dt><dd><p>The prior on the covariance distribution (Wishart).
If it is None, the emiprical covariance prior is initialized using the
covariance of X. The shape depends on <code class="docutils literal notranslate"><span class="pre">covariance_type</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span> <span class="k">if</span> <span class="s1">&#39;full&#39;</span><span class="p">,</span>
<span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span> <span class="k">if</span> <span class="s1">&#39;tied&#39;</span><span class="p">,</span>
<span class="p">(</span><span class="n">n_features</span><span class="p">)</span>             <span class="k">if</span> <span class="s1">&#39;diag&#39;</span><span class="p">,</span>
<span class="nb">float</span>                    <span class="k">if</span> <span class="s1">&#39;spherical&#39;</span>
</pre></div>
</div>
</dd>
<dt><strong>random_state</strong><span class="classifier">int, RandomState instance or None, default=None</span></dt><dd><p>Controls the random seed given to the method chosen to initialize the
parameters (see <code class="docutils literal notranslate"><span class="pre">init_params</span></code>).
In addition, it controls the generation of random samples from the
fitted distribution (see the method <code class="docutils literal notranslate"><span class="pre">sample</span></code>).
Pass an int for reproducible output across multiple function calls.
See <a class="reference internal" href="../../glossary.html#term-random_state"><span class="xref std std-term">Glossary</span></a>.</p>
</dd>
<dt><strong>warm_start</strong><span class="classifier">bool, default=False</span></dt><dd><p>If ‘warm_start’ is True, the solution of the last fitting is used as
initialization for the next call of fit(). This can speed up
convergence when fit is called several times on similar problems.
See <a class="reference internal" href="../../glossary.html#term-warm_start"><span class="xref std std-term">the Glossary</span></a>.</p>
</dd>
<dt><strong>verbose</strong><span class="classifier">int, default=0</span></dt><dd><p>Enable verbose output. If 1 then it prints the current
initialization and each iteration step. If greater than 1 then
it prints also the log probability and the time needed
for each step.</p>
</dd>
<dt><strong>verbose_interval</strong><span class="classifier">int, default=10</span></dt><dd><p>Number of iteration done before the next print.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Attributes<span class="colon">:</span></dt>
<dd class="field-even"><dl>
<dt><strong>weights_</strong><span class="classifier">array-like of shape (n_components,)</span></dt><dd><p>The weights of each mixture components.</p>
</dd>
<dt><strong>means_</strong><span class="classifier">array-like of shape (n_components, n_features)</span></dt><dd><p>The mean of each mixture component.</p>
</dd>
<dt><strong>covariances_</strong><span class="classifier">array-like</span></dt><dd><p>The covariance of each mixture component.
The shape depends on <code class="docutils literal notranslate"><span class="pre">covariance_type</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">n_components</span><span class="p">,)</span>                        <span class="k">if</span> <span class="s1">&#39;spherical&#39;</span><span class="p">,</span>
<span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span>               <span class="k">if</span> <span class="s1">&#39;tied&#39;</span><span class="p">,</span>
<span class="p">(</span><span class="n">n_components</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span>             <span class="k">if</span> <span class="s1">&#39;diag&#39;</span><span class="p">,</span>
<span class="p">(</span><span class="n">n_components</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span> <span class="k">if</span> <span class="s1">&#39;full&#39;</span>
</pre></div>
</div>
</dd>
<dt><strong>precisions_</strong><span class="classifier">array-like</span></dt><dd><p>The precision matrices for each component in the mixture. A precision
matrix is the inverse of a covariance matrix. A covariance matrix is
symmetric positive definite so the mixture of Gaussian can be
equivalently parameterized by the precision matrices. Storing the
precision matrices instead of the covariance matrices makes it more
efficient to compute the log-likelihood of new samples at test time.
The shape depends on <code class="docutils literal notranslate"><span class="pre">covariance_type</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">n_components</span><span class="p">,)</span>                        <span class="k">if</span> <span class="s1">&#39;spherical&#39;</span><span class="p">,</span>
<span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span>               <span class="k">if</span> <span class="s1">&#39;tied&#39;</span><span class="p">,</span>
<span class="p">(</span><span class="n">n_components</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span>             <span class="k">if</span> <span class="s1">&#39;diag&#39;</span><span class="p">,</span>
<span class="p">(</span><span class="n">n_components</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span> <span class="k">if</span> <span class="s1">&#39;full&#39;</span>
</pre></div>
</div>
</dd>
<dt><strong>precisions_cholesky_</strong><span class="classifier">array-like</span></dt><dd><p>The cholesky decomposition of the precision matrices of each mixture
component. A precision matrix is the inverse of a covariance matrix.
A covariance matrix is symmetric positive definite so the mixture of
Gaussian can be equivalently parameterized by the precision matrices.
Storing the precision matrices instead of the covariance matrices makes
it more efficient to compute the log-likelihood of new samples at test
time. The shape depends on <code class="docutils literal notranslate"><span class="pre">covariance_type</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">n_components</span><span class="p">,)</span>                        <span class="k">if</span> <span class="s1">&#39;spherical&#39;</span><span class="p">,</span>
<span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span>               <span class="k">if</span> <span class="s1">&#39;tied&#39;</span><span class="p">,</span>
<span class="p">(</span><span class="n">n_components</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span>             <span class="k">if</span> <span class="s1">&#39;diag&#39;</span><span class="p">,</span>
<span class="p">(</span><span class="n">n_components</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span> <span class="k">if</span> <span class="s1">&#39;full&#39;</span>
</pre></div>
</div>
</dd>
<dt><strong>converged_</strong><span class="classifier">bool</span></dt><dd><p>True when convergence was reached in fit(), False otherwise.</p>
</dd>
<dt><strong>n_iter_</strong><span class="classifier">int</span></dt><dd><p>Number of step used by the best fit of inference to reach the
convergence.</p>
</dd>
<dt><strong>lower_bound_</strong><span class="classifier">float</span></dt><dd><p>Lower bound value on the model evidence (of the training data) of the
best fit of inference.</p>
</dd>
<dt><strong>weight_concentration_prior_</strong><span class="classifier">tuple or float</span></dt><dd><p>The dirichlet concentration of each component on the weight
distribution (Dirichlet). The type depends on
<code class="docutils literal notranslate"><span class="pre">weight_concentration_prior_type</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span> <span class="k">if</span> <span class="s1">&#39;dirichlet_process&#39;</span> <span class="p">(</span><span class="n">Beta</span> <span class="n">parameters</span><span class="p">),</span>
<span class="nb">float</span>          <span class="k">if</span> <span class="s1">&#39;dirichlet_distribution&#39;</span> <span class="p">(</span><span class="n">Dirichlet</span> <span class="n">parameters</span><span class="p">)</span><span class="o">.</span>
</pre></div>
</div>
<p>The higher concentration puts more mass in
the center and will lead to more components being active, while a lower
concentration parameter will lead to more mass at the edge of the
simplex.</p>
</dd>
<dt><strong>weight_concentration_</strong><span class="classifier">array-like of shape (n_components,)</span></dt><dd><p>The dirichlet concentration of each component on the weight
distribution (Dirichlet).</p>
</dd>
<dt><strong>mean_precision_prior_</strong><span class="classifier">float</span></dt><dd><p>The precision prior on the mean distribution (Gaussian).
Controls the extent of where means can be placed.
Larger values concentrate the cluster means around <code class="docutils literal notranslate"><span class="pre">mean_prior</span></code>.
If mean_precision_prior is set to None, <code class="docutils literal notranslate"><span class="pre">mean_precision_prior_</span></code> is set
to 1.</p>
</dd>
<dt><strong>mean_precision_</strong><span class="classifier">array-like of shape (n_components,)</span></dt><dd><p>The precision of each components on the mean distribution (Gaussian).</p>
</dd>
<dt><strong>mean_prior_</strong><span class="classifier">array-like of shape (n_features,)</span></dt><dd><p>The prior on the mean distribution (Gaussian).</p>
</dd>
<dt><strong>degrees_of_freedom_prior_</strong><span class="classifier">float</span></dt><dd><p>The prior of the number of degrees of freedom on the covariance
distributions (Wishart).</p>
</dd>
<dt><strong>degrees_of_freedom_</strong><span class="classifier">array-like of shape (n_components,)</span></dt><dd><p>The number of degrees of freedom of each components in the model.</p>
</dd>
<dt><strong>covariance_prior_</strong><span class="classifier">float or array-like</span></dt><dd><p>The prior on the covariance distribution (Wishart).
The shape depends on <code class="docutils literal notranslate"><span class="pre">covariance_type</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span> <span class="k">if</span> <span class="s1">&#39;full&#39;</span><span class="p">,</span>
<span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span> <span class="k">if</span> <span class="s1">&#39;tied&#39;</span><span class="p">,</span>
<span class="p">(</span><span class="n">n_features</span><span class="p">)</span>             <span class="k">if</span> <span class="s1">&#39;diag&#39;</span><span class="p">,</span>
<span class="nb">float</span>                    <span class="k">if</span> <span class="s1">&#39;spherical&#39;</span>
</pre></div>
</div>
</dd>
<dt><strong>n_features_in_</strong><span class="classifier">int</span></dt><dd><p>Number of features seen during <a class="reference internal" href="../../glossary.html#term-fit"><span class="xref std std-term">fit</span></a>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.24.</span></p>
</div>
</dd>
<dt><strong>feature_names_in_</strong><span class="classifier">ndarray of shape (<code class="docutils literal notranslate"><span class="pre">n_features_in_</span></code>,)</span></dt><dd><p>Names of features seen during <a class="reference internal" href="../../glossary.html#term-fit"><span class="xref std std-term">fit</span></a>. Defined only when <code class="docutils literal notranslate"><span class="pre">X</span></code>
has feature names that are all strings.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.0.</span></p>
</div>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="sklearn.mixture.GaussianMixture.html#sklearn.mixture.GaussianMixture" title="sklearn.mixture.GaussianMixture"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GaussianMixture</span></code></a></dt><dd><p>Finite Gaussian mixture fit with EM.</p>
</dd>
</dl>
</div>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r16529824bff2-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://www.springer.com/kr/book/9780387310732">Bishop, Christopher M. (2006). “Pattern recognition and machine
learning”. Vol. 4 No. 4. New York: Springer.</a></p>
</div>
<div class="citation" id="r16529824bff2-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://citeseerx.ist.psu.edu/doc_view/pid/ee844fd96db7041a9681b5a18bff008912052c7e">Hagai Attias. (2000). “A Variational Bayesian Framework for
Graphical Models”. In Advances in Neural Information Processing
Systems 12.</a></p>
</div>
<div class="citation" id="r16529824bff2-3" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://www.cs.princeton.edu/courses/archive/fall11/cos597C/reading/BleiJordan2005.pdf">Blei, David M. and Michael I. Jordan. (2006). “Variational
inference for Dirichlet process mixtures”. Bayesian analysis 1.1</a></p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.mixture</span> <span class="kn">import</span> <span class="n">BayesianGaussianMixture</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bgm</span> <span class="o">=</span> <span class="n">BayesianGaussianMixture</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bgm</span><span class="o">.</span><span class="n">means_</span>
<span class="go">array([[2.49... , 2.29...],</span>
<span class="go">       [8.45..., 4.52... ]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bgm</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span>
<span class="go">array([0, 1])</span>
</pre></div>
</div>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.mixture.BayesianGaussianMixture.fit" title="sklearn.mixture.BayesianGaussianMixture.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>(X[, y])</p></td>
<td><p>Estimate model parameters with the EM algorithm.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.mixture.BayesianGaussianMixture.fit_predict" title="sklearn.mixture.BayesianGaussianMixture.fit_predict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit_predict</span></code></a>(X[, y])</p></td>
<td><p>Estimate model parameters using X and predict the labels for X.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.mixture.BayesianGaussianMixture.get_metadata_routing" title="sklearn.mixture.BayesianGaussianMixture.get_metadata_routing"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_metadata_routing</span></code></a>()</p></td>
<td><p>Get metadata routing of this object.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.mixture.BayesianGaussianMixture.get_params" title="sklearn.mixture.BayesianGaussianMixture.get_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_params</span></code></a>([deep])</p></td>
<td><p>Get parameters for this estimator.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.mixture.BayesianGaussianMixture.predict" title="sklearn.mixture.BayesianGaussianMixture.predict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict</span></code></a>(X)</p></td>
<td><p>Predict the labels for the data samples in X using trained model.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.mixture.BayesianGaussianMixture.predict_proba" title="sklearn.mixture.BayesianGaussianMixture.predict_proba"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict_proba</span></code></a>(X)</p></td>
<td><p>Evaluate the components' density for each sample.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.mixture.BayesianGaussianMixture.sample" title="sklearn.mixture.BayesianGaussianMixture.sample"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sample</span></code></a>([n_samples])</p></td>
<td><p>Generate random samples from the fitted Gaussian distribution.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.mixture.BayesianGaussianMixture.score" title="sklearn.mixture.BayesianGaussianMixture.score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">score</span></code></a>(X[, y])</p></td>
<td><p>Compute the per-sample average log-likelihood of the given data X.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.mixture.BayesianGaussianMixture.score_samples" title="sklearn.mixture.BayesianGaussianMixture.score_samples"><code class="xref py py-obj docutils literal notranslate"><span class="pre">score_samples</span></code></a>(X)</p></td>
<td><p>Compute the log-likelihood of each sample.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.mixture.BayesianGaussianMixture.set_params" title="sklearn.mixture.BayesianGaussianMixture.set_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_params</span></code></a>(**params)</p></td>
<td><p>Set the parameters of this estimator.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.mixture.BayesianGaussianMixture.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.mixture.BayesianGaussianMixture.fit" title="Link to this definition">¶</a></dt>
<dd><p>Estimate model parameters with the EM algorithm.</p>
<p>The method fits the model <code class="docutils literal notranslate"><span class="pre">n_init</span></code> times and sets the parameters with
which the model has the largest likelihood or lower bound. Within each
trial, the method iterates between E-step and M-step for <code class="docutils literal notranslate"><span class="pre">max_iter</span></code>
times until the change of likelihood or lower bound is less than
<code class="docutils literal notranslate"><span class="pre">tol</span></code>, otherwise, a <code class="docutils literal notranslate"><span class="pre">ConvergenceWarning</span></code> is raised.
If <code class="docutils literal notranslate"><span class="pre">warm_start</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, then <code class="docutils literal notranslate"><span class="pre">n_init</span></code> is ignored and a single
initialization is performed upon the first call. Upon consecutive
calls, training starts where it left off.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like of shape (n_samples, n_features)</span></dt><dd><p>List of n_features-dimensional data points. Each row
corresponds to a single data point.</p>
</dd>
<dt><strong>y</strong><span class="classifier">Ignored</span></dt><dd><p>Not used, present for API consistency by convention.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">object</span></dt><dd><p>The fitted mixture.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.mixture.BayesianGaussianMixture.fit_predict">
<span class="sig-name descname"><span class="pre">fit_predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.mixture.BayesianGaussianMixture.fit_predict" title="Link to this definition">¶</a></dt>
<dd><p>Estimate model parameters using X and predict the labels for X.</p>
<p>The method fits the model n_init times and sets the parameters with
which the model has the largest likelihood or lower bound. Within each
trial, the method iterates between E-step and M-step for <code class="docutils literal notranslate"><span class="pre">max_iter</span></code>
times until the change of likelihood or lower bound is less than
<code class="docutils literal notranslate"><span class="pre">tol</span></code>, otherwise, a <a class="reference internal" href="sklearn.exceptions.ConvergenceWarning.html#sklearn.exceptions.ConvergenceWarning" title="sklearn.exceptions.ConvergenceWarning"><code class="xref py py-class docutils literal notranslate"><span class="pre">ConvergenceWarning</span></code></a> is
raised. After fitting, it predicts the most probable label for the
input data points.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.20.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like of shape (n_samples, n_features)</span></dt><dd><p>List of n_features-dimensional data points. Each row
corresponds to a single data point.</p>
</dd>
<dt><strong>y</strong><span class="classifier">Ignored</span></dt><dd><p>Not used, present for API consistency by convention.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>labels</strong><span class="classifier">array, shape (n_samples,)</span></dt><dd><p>Component labels.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.mixture.BayesianGaussianMixture.get_metadata_routing">
<span class="sig-name descname"><span class="pre">get_metadata_routing</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.mixture.BayesianGaussianMixture.get_metadata_routing" title="Link to this definition">¶</a></dt>
<dd><p>Get metadata routing of this object.</p>
<p>Please check <a class="reference internal" href="../../metadata_routing.html#metadata-routing"><span class="std std-ref">User Guide</span></a> on how the routing
mechanism works.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>routing</strong><span class="classifier">MetadataRequest</span></dt><dd><p>A <a class="reference internal" href="sklearn.utils.metadata_routing.MetadataRequest.html#sklearn.utils.metadata_routing.MetadataRequest" title="sklearn.utils.metadata_routing.MetadataRequest"><code class="xref py py-class docutils literal notranslate"><span class="pre">MetadataRequest</span></code></a> encapsulating
routing information.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.mixture.BayesianGaussianMixture.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.mixture.BayesianGaussianMixture.get_params" title="Link to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>deep</strong><span class="classifier">bool, default=True</span></dt><dd><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>params</strong><span class="classifier">dict</span></dt><dd><p>Parameter names mapped to their values.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.mixture.BayesianGaussianMixture.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.mixture.BayesianGaussianMixture.predict" title="Link to this definition">¶</a></dt>
<dd><p>Predict the labels for the data samples in X using trained model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like of shape (n_samples, n_features)</span></dt><dd><p>List of n_features-dimensional data points. Each row
corresponds to a single data point.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>labels</strong><span class="classifier">array, shape (n_samples,)</span></dt><dd><p>Component labels.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.mixture.BayesianGaussianMixture.predict_proba">
<span class="sig-name descname"><span class="pre">predict_proba</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.mixture.BayesianGaussianMixture.predict_proba" title="Link to this definition">¶</a></dt>
<dd><p>Evaluate the components’ density for each sample.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like of shape (n_samples, n_features)</span></dt><dd><p>List of n_features-dimensional data points. Each row
corresponds to a single data point.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>resp</strong><span class="classifier">array, shape (n_samples, n_components)</span></dt><dd><p>Density of each Gaussian component for each sample in X.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.mixture.BayesianGaussianMixture.sample">
<span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.mixture.BayesianGaussianMixture.sample" title="Link to this definition">¶</a></dt>
<dd><p>Generate random samples from the fitted Gaussian distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>n_samples</strong><span class="classifier">int, default=1</span></dt><dd><p>Number of samples to generate.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array, shape (n_samples, n_features)</span></dt><dd><p>Randomly generated sample.</p>
</dd>
<dt><strong>y</strong><span class="classifier">array, shape (nsamples,)</span></dt><dd><p>Component labels.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.mixture.BayesianGaussianMixture.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.mixture.BayesianGaussianMixture.score" title="Link to this definition">¶</a></dt>
<dd><p>Compute the per-sample average log-likelihood of the given data X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like of shape (n_samples, n_dimensions)</span></dt><dd><p>List of n_features-dimensional data points. Each row
corresponds to a single data point.</p>
</dd>
<dt><strong>y</strong><span class="classifier">Ignored</span></dt><dd><p>Not used, present for API consistency by convention.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>log_likelihood</strong><span class="classifier">float</span></dt><dd><p>Log-likelihood of <code class="docutils literal notranslate"><span class="pre">X</span></code> under the Gaussian mixture model.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.mixture.BayesianGaussianMixture.score_samples">
<span class="sig-name descname"><span class="pre">score_samples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.mixture.BayesianGaussianMixture.score_samples" title="Link to this definition">¶</a></dt>
<dd><p>Compute the log-likelihood of each sample.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like of shape (n_samples, n_features)</span></dt><dd><p>List of n_features-dimensional data points. Each row
corresponds to a single data point.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>log_prob</strong><span class="classifier">array, shape (n_samples,)</span></dt><dd><p>Log-likelihood of each sample in <code class="docutils literal notranslate"><span class="pre">X</span></code> under the current model.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.mixture.BayesianGaussianMixture.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.mixture.BayesianGaussianMixture.set_params" title="Link to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as <a class="reference internal" href="sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code></a>). The latter have
parameters of the form <code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s
possible to update each component of a nested object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>**params</strong><span class="classifier">dict</span></dt><dd><p>Estimator parameters.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">estimator instance</span></dt><dd><p>Estimator instance.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<section id="examples-using-sklearn-mixture-bayesiangaussianmixture">
<h2>Examples using <code class="docutils literal notranslate"><span class="pre">sklearn.mixture.BayesianGaussianMixture</span></code><a class="headerlink" href="#examples-using-sklearn-mixture-bayesiangaussianmixture" title="Link to this heading">¶</a></h2>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This example plots the ellipsoids obtained from a toy dataset (mixture of three Gaussians) fitt..."><img alt="" src="../../_images/sphx_glr_plot_concentration_prior_thumb.png" />
<p><a class="reference internal" href="../../auto_examples/mixture/plot_concentration_prior.html#sphx-glr-auto-examples-mixture-plot-concentration-prior-py"><span class="std std-ref">Concentration Prior Type Analysis of Variation Bayesian Gaussian Mixture</span></a></p>
  <div class="sphx-glr-thumbnail-title">Concentration Prior Type Analysis of Variation Bayesian Gaussian Mixture</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Plot the confidence ellipsoids of a mixture of two Gaussians obtained with Expectation Maximisa..."><img alt="" src="../../_images/sphx_glr_plot_gmm_thumb.png" />
<p><a class="reference internal" href="../../auto_examples/mixture/plot_gmm.html#sphx-glr-auto-examples-mixture-plot-gmm-py"><span class="std std-ref">Gaussian Mixture Model Ellipsoids</span></a></p>
  <div class="sphx-glr-thumbnail-title">Gaussian Mixture Model Ellipsoids</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates the behavior of Gaussian mixture models fit on data that was not samp..."><img alt="" src="../../_images/sphx_glr_plot_gmm_sin_thumb.png" />
<p><a class="reference internal" href="../../auto_examples/mixture/plot_gmm_sin.html#sphx-glr-auto-examples-mixture-plot-gmm-sin-py"><span class="std std-ref">Gaussian Mixture Model Sine Curve</span></a></p>
  <div class="sphx-glr-thumbnail-title">Gaussian Mixture Model Sine Curve</div>
</div></div><div class="clearer"></div></section>
</section>


      </div>
    <div class="container">
      <footer class="sk-content-footer">
            &copy; 2007 - 2023, scikit-learn developers (BSD License).
          <a href="../../_sources/modules/generated/sklearn.mixture.BayesianGaussianMixture.rst.txt" rel="nofollow">Show this page source</a>
      </footer>
    </div>
  </div>
</div>
<script src="../../_static/js/vendor/bootstrap.min.js"></script>

<script>
    window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
    ga('create', 'UA-22606712-2', 'auto');
    ga('set', 'anonymizeIp', true);
    ga('send', 'pageview');
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>



<script defer data-domain="scikit-learn.org" src="https://views.scientific-python.org/js/script.js">
</script>


<script src="../../_static/clipboard.min.js"></script>
<script src="../../_static/copybutton.js"></script>

<script>
$(document).ready(function() {
    /* Add a [>>>] button on the top-right corner of code samples to hide
     * the >>> and ... prompts and the output and thus make the code
     * copyable. */
    var div = $('.highlight-python .highlight,' +
                '.highlight-python3 .highlight,' +
                '.highlight-pycon .highlight,' +
		'.highlight-default .highlight')
    var pre = div.find('pre');

    // get the styles from the current theme
    pre.parent().parent().css('position', 'relative');

    // create and add the button to all the code blocks that contain >>>
    div.each(function(index) {
        var jthis = $(this);
        // tracebacks (.gt) contain bare text elements that need to be
        // wrapped in a span to work with .nextUntil() (see later)
        jthis.find('pre:has(.gt)').contents().filter(function() {
            return ((this.nodeType == 3) && (this.data.trim().length > 0));
        }).wrap('<span>');
    });

	/*** Add permalink buttons next to glossary terms ***/
	$('dl.glossary > dt[id]').append(function() {
		return ('<a class="headerlink" href="#' +
			    this.getAttribute('id') +
			    '" title="Permalink to this term">¶</a>');
	});
});

</script>
    
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    
</body>
</html>