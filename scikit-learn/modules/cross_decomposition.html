

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="1.8. Cross decomposition" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://scikit-learn/stable/modules/cross_decomposition.html" />
<meta property="og:site_name" content="scikit-learn" />
<meta property="og:description" content="The cross decomposition module contains supervised estimators for dimensionality reduction and regression, belonging to the “Partial Least Squares” family. Cross decomposition algorithms find the f..." />
<meta property="og:image" content="https://scikit-learn/stable/_images/sphx_glr_plot_compare_cross_decomposition_001.png" />
<meta property="og:image:alt" content="scikit-learn" />
<meta name="description" content="The cross decomposition module contains supervised estimators for dimensionality reduction and regression, belonging to the “Partial Least Squares” family. Cross decomposition algorithms find the f..." />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <title>1.8. Cross decomposition &mdash; scikit-learn 1.3.2 documentation</title>
  
  <link rel="canonical" href="http://scikit-learn.org/stable/modules/cross_decomposition.html" />

  
  <link rel="shortcut icon" href="../_static/favicon.ico"/>
  

  <link rel="stylesheet" href="../_static/css/vendor/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../_static/plot_directive.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
<script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
<script src="../_static/js/vendor/jquery-3.6.3.slim.min.js"></script> 
</head>
<body>






<nav id="navbar" class="sk-docs-navbar navbar navbar-expand-md navbar-light bg-light py-0">
  <div class="container-fluid sk-docs-container px-0">
      <a class="navbar-brand py-0" href="../index.html">
        <img
          class="sk-brand-img"
          src="../_static/scikit-learn-logo-small.png"
          alt="logo"/>
      </a>
    <button
      id="sk-navbar-toggler"
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="sk-navbar-collapse collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../install.html">Install</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../user_guide.html">User Guide</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="classes.html">API</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../auto_examples/index.html">Examples</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" target="_blank" rel="noopener noreferrer" href="https://blog.scikit-learn.org/">Community</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../getting_started.html" >Getting Started</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../tutorial/index.html" >Tutorial</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../whats_new/v1.3.html" >What's new</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../glossary.html" >Glossary</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://scikit-learn.org/dev/developers/index.html" target="_blank" rel="noopener noreferrer">Development</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../faq.html" >FAQ</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../support.html" >Support</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../related_projects.html" >Related packages</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../roadmap.html" >Roadmap</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../governance.html" >Governance</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../about.html" >About us</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://github.com/scikit-learn/scikit-learn" >GitHub</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://scikit-learn.org/dev/versions.html" >Other Versions and Download</a>
        </li>
        <li class="nav-item dropdown nav-more-item-dropdown">
          <a class="sk-nav-link nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">More</a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdown">
              <a class="sk-nav-dropdown-item dropdown-item" href="../getting_started.html" >Getting Started</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../tutorial/index.html" >Tutorial</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../whats_new/v1.3.html" >What's new</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../glossary.html" >Glossary</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://scikit-learn.org/dev/developers/index.html" target="_blank" rel="noopener noreferrer">Development</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../faq.html" >FAQ</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../support.html" >Support</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../related_projects.html" >Related packages</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../roadmap.html" >Roadmap</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../governance.html" >Governance</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../about.html" >About us</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://github.com/scikit-learn/scikit-learn" >GitHub</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://scikit-learn.org/dev/versions.html" >Other Versions and Download</a>
          </div>
        </li>
      </ul>
      <div id="searchbox" role="search">
          <div class="searchformwrapper">
          <form class="search" action="../search.html" method="get">
            <input class="sk-search-text-input" type="text" name="q" aria-labelledby="searchlabel" />
            <input class="sk-search-text-btn" type="submit" value="Go" />
          </form>
          </div>
      </div>
    </div>
  </div>
</nav>
<div class="d-flex" id="sk-doc-wrapper">
    <input type="checkbox" name="sk-toggle-checkbox" id="sk-toggle-checkbox">
    <label id="sk-sidemenu-toggle" class="sk-btn-toggle-toc btn sk-btn-primary" for="sk-toggle-checkbox">Toggle Menu</label>
    <div id="sk-sidebar-wrapper" class="border-right">
      <div class="sk-sidebar-toc-wrapper">
        <div class="btn-group w-100 mb-2" role="group" aria-label="rellinks">
            <a href="gaussian_process.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="1.7. Gaussian Processes">Prev</a><a href="../supervised_learning.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="1. Supervised learning">Up</a>
            <a href="naive_bayes.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="1.9. Naive Bayes">Next</a>
        </div>
        <div class="alert alert-danger p-1 mb-2" role="alert">
          <p class="text-center mb-0">
          <strong>scikit-learn 1.3.2</strong><br/>
          <a href="http://scikit-learn.org/dev/versions.html">Other versions</a>
          </p>
        </div>
        <div class="alert alert-warning p-1 mb-2" role="alert">
          <p class="text-center mb-0">
            Please <a class="font-weight-bold" href="../about.html#citing-scikit-learn"><string>cite us</string></a> if you use the software.
          </p>
        </div>
            <div class="sk-sidebar-toc">
              <ul>
<li><a class="reference internal" href="#">1.8. Cross decomposition</a><ul>
<li><a class="reference internal" href="#plscanonical">1.8.1. PLSCanonical</a><ul>
<li><a class="reference internal" href="#transforming-data">1.8.1.1. Transforming data</a></li>
<li><a class="reference internal" href="#predicting-the-targets-y">1.8.1.2. Predicting the targets Y</a></li>
</ul>
</li>
<li><a class="reference internal" href="#plssvd">1.8.2. PLSSVD</a></li>
<li><a class="reference internal" href="#plsregression">1.8.3. PLSRegression</a></li>
<li><a class="reference internal" href="#canonical-correlation-analysis">1.8.4. Canonical Correlation Analysis</a></li>
</ul>
</li>
</ul>

            </div>
      </div>
    </div>
    <div id="sk-page-content-wrapper">
      <div class="sk-page-content container-fluid body px-md-3" role="main">
        
  <section id="cross-decomposition">
<span id="id1"></span><h1><span class="section-number">1.8. </span>Cross decomposition<a class="headerlink" href="#cross-decomposition" title="Link to this heading">¶</a></h1>
<p>The cross decomposition module contains <strong>supervised</strong> estimators for
dimensionality reduction and regression, belonging to the “Partial Least
Squares” family.</p>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/cross_decomposition/plot_compare_cross_decomposition.html"><img alt="../_images/sphx_glr_plot_compare_cross_decomposition_001.png" src="../_images/sphx_glr_plot_compare_cross_decomposition_001.png" style="width: 900.0px; height: 600.0px;" /></a>
</figure>
<p>Cross decomposition algorithms find the fundamental relations between two
matrices (X and Y). They are latent variable approaches to modeling the
covariance structures in these two spaces. They will try to find the
multidimensional direction in the X space that explains the maximum
multidimensional variance direction in the Y space. In other words, PLS
projects both <code class="docutils literal notranslate"><span class="pre">X</span></code> and <code class="docutils literal notranslate"><span class="pre">Y</span></code> into a lower-dimensional subspace such that the
covariance between <code class="docutils literal notranslate"><span class="pre">transformed(X)</span></code> and <code class="docutils literal notranslate"><span class="pre">transformed(Y)</span></code> is maximal.</p>
<p>PLS draws similarities with <a class="reference external" href="https://en.wikipedia.org/wiki/Principal_component_regression">Principal Component Regression</a> (PCR), where
the samples are first projected into a lower-dimensional subspace, and the
targets <code class="docutils literal notranslate"><span class="pre">y</span></code> are predicted using <code class="docutils literal notranslate"><span class="pre">transformed(X)</span></code>. One issue with PCR is that
the dimensionality reduction is unsupervised, and may lose some important
variables: PCR would keep the features with the most variance, but it’s
possible that features with a small variances are relevant from predicting
the target. In a way, PLS allows for the same kind of dimensionality
reduction, but by taking into account the targets <code class="docutils literal notranslate"><span class="pre">y</span></code>. An illustration of
this fact is given in the following example:
* <a class="reference internal" href="../auto_examples/cross_decomposition/plot_pcr_vs_pls.html#sphx-glr-auto-examples-cross-decomposition-plot-pcr-vs-pls-py"><span class="std std-ref">Principal Component Regression vs Partial Least Squares Regression</span></a>.</p>
<p>Apart from CCA, the PLS estimators are particularly suited when the matrix of
predictors has more variables than observations, and when there is
multicollinearity among the features. By contrast, standard linear regression
would fail in these cases unless it is regularized.</p>
<p>Classes included in this module are <a class="reference internal" href="generated/sklearn.cross_decomposition.PLSRegression.html#sklearn.cross_decomposition.PLSRegression" title="sklearn.cross_decomposition.PLSRegression"><code class="xref py py-class docutils literal notranslate"><span class="pre">PLSRegression</span></code></a>,
<a class="reference internal" href="generated/sklearn.cross_decomposition.PLSCanonical.html#sklearn.cross_decomposition.PLSCanonical" title="sklearn.cross_decomposition.PLSCanonical"><code class="xref py py-class docutils literal notranslate"><span class="pre">PLSCanonical</span></code></a>, <a class="reference internal" href="generated/sklearn.cross_decomposition.CCA.html#sklearn.cross_decomposition.CCA" title="sklearn.cross_decomposition.CCA"><code class="xref py py-class docutils literal notranslate"><span class="pre">CCA</span></code></a> and <a class="reference internal" href="generated/sklearn.cross_decomposition.PLSSVD.html#sklearn.cross_decomposition.PLSSVD" title="sklearn.cross_decomposition.PLSSVD"><code class="xref py py-class docutils literal notranslate"><span class="pre">PLSSVD</span></code></a></p>
<section id="plscanonical">
<h2><span class="section-number">1.8.1. </span>PLSCanonical<a class="headerlink" href="#plscanonical" title="Link to this heading">¶</a></h2>
<p>We here describe the algorithm used in <a class="reference internal" href="generated/sklearn.cross_decomposition.PLSCanonical.html#sklearn.cross_decomposition.PLSCanonical" title="sklearn.cross_decomposition.PLSCanonical"><code class="xref py py-class docutils literal notranslate"><span class="pre">PLSCanonical</span></code></a>. The other
estimators use variants of this algorithm, and are detailed below.
We recommend section <a class="footnote-reference brackets" href="#id6" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a> for more details and comparisons between these
algorithms. In <a class="footnote-reference brackets" href="#id6" id="id3" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>, <a class="reference internal" href="generated/sklearn.cross_decomposition.PLSCanonical.html#sklearn.cross_decomposition.PLSCanonical" title="sklearn.cross_decomposition.PLSCanonical"><code class="xref py py-class docutils literal notranslate"><span class="pre">PLSCanonical</span></code></a> corresponds to “PLSW2A”.</p>
<p>Given two centered matrices <span class="math notranslate nohighlight">\(X \in \mathbb{R}^{n \times d}\)</span> and
<span class="math notranslate nohighlight">\(Y \in \mathbb{R}^{n \times t}\)</span>, and a number of components <span class="math notranslate nohighlight">\(K\)</span>,
<a class="reference internal" href="generated/sklearn.cross_decomposition.PLSCanonical.html#sklearn.cross_decomposition.PLSCanonical" title="sklearn.cross_decomposition.PLSCanonical"><code class="xref py py-class docutils literal notranslate"><span class="pre">PLSCanonical</span></code></a> proceeds as follows:</p>
<p>Set <span class="math notranslate nohighlight">\(X_1\)</span> to <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y_1\)</span> to <span class="math notranslate nohighlight">\(Y\)</span>. Then, for each
<span class="math notranslate nohighlight">\(k \in [1, K]\)</span>:</p>
<ul class="simple">
<li><p>a) compute <span class="math notranslate nohighlight">\(u_k \in \mathbb{R}^d\)</span> and <span class="math notranslate nohighlight">\(v_k \in \mathbb{R}^t\)</span>,
the first left and right singular vectors of the cross-covariance matrix
<span class="math notranslate nohighlight">\(C = X_k^T Y_k\)</span>.
<span class="math notranslate nohighlight">\(u_k\)</span> and <span class="math notranslate nohighlight">\(v_k\)</span> are called the <em>weights</em>.
By definition, <span class="math notranslate nohighlight">\(u_k\)</span> and <span class="math notranslate nohighlight">\(v_k\)</span> are
chosen so that they maximize the covariance between the projected
<span class="math notranslate nohighlight">\(X_k\)</span> and the projected target, that is <span class="math notranslate nohighlight">\(\text{Cov}(X_k u_k,
Y_k v_k)\)</span>.</p></li>
<li><p>b) Project <span class="math notranslate nohighlight">\(X_k\)</span> and <span class="math notranslate nohighlight">\(Y_k\)</span> on the singular vectors to obtain
<em>scores</em>: <span class="math notranslate nohighlight">\(\xi_k = X_k u_k\)</span> and <span class="math notranslate nohighlight">\(\omega_k = Y_k v_k\)</span></p></li>
<li><p>c) Regress <span class="math notranslate nohighlight">\(X_k\)</span> on <span class="math notranslate nohighlight">\(\xi_k\)</span>, i.e. find a vector <span class="math notranslate nohighlight">\(\gamma_k
\in \mathbb{R}^d\)</span> such that the rank-1 matrix <span class="math notranslate nohighlight">\(\xi_k \gamma_k^T\)</span>
is as close as possible to <span class="math notranslate nohighlight">\(X_k\)</span>. Do the same on <span class="math notranslate nohighlight">\(Y_k\)</span> with
<span class="math notranslate nohighlight">\(\omega_k\)</span> to obtain <span class="math notranslate nohighlight">\(\delta_k\)</span>. The vectors
<span class="math notranslate nohighlight">\(\gamma_k\)</span> and <span class="math notranslate nohighlight">\(\delta_k\)</span> are called the <em>loadings</em>.</p></li>
<li><p>d) <em>deflate</em> <span class="math notranslate nohighlight">\(X_k\)</span> and <span class="math notranslate nohighlight">\(Y_k\)</span>, i.e. subtract the rank-1
approximations: <span class="math notranslate nohighlight">\(X_{k+1} = X_k - \xi_k \gamma_k^T\)</span>, and
<span class="math notranslate nohighlight">\(Y_{k + 1} = Y_k - \omega_k \delta_k^T\)</span>.</p></li>
</ul>
<p>At the end, we have approximated <span class="math notranslate nohighlight">\(X\)</span> as a sum of rank-1 matrices:
<span class="math notranslate nohighlight">\(X = \Xi \Gamma^T\)</span> where <span class="math notranslate nohighlight">\(\Xi \in \mathbb{R}^{n \times K}\)</span>
contains the scores in its columns, and <span class="math notranslate nohighlight">\(\Gamma^T \in \mathbb{R}^{K
\times d}\)</span> contains the loadings in its rows. Similarly for <span class="math notranslate nohighlight">\(Y\)</span>, we
have <span class="math notranslate nohighlight">\(Y = \Omega \Delta^T\)</span>.</p>
<p>Note that the scores matrices <span class="math notranslate nohighlight">\(\Xi\)</span> and <span class="math notranslate nohighlight">\(\Omega\)</span> correspond to
the projections of the training data <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>, respectively.</p>
<p>Step <em>a)</em> may be performed in two ways: either by computing the whole SVD of
<span class="math notranslate nohighlight">\(C\)</span> and only retain the singular vectors with the biggest singular
values, or by directly computing the singular vectors using the power method (cf section 11.3 in <a class="footnote-reference brackets" href="#id6" id="id4" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>),
which corresponds to the <code class="docutils literal notranslate"><span class="pre">'nipals'</span></code> option of the <code class="docutils literal notranslate"><span class="pre">algorithm</span></code> parameter.</p>
<section id="transforming-data">
<h3><span class="section-number">1.8.1.1. </span>Transforming data<a class="headerlink" href="#transforming-data" title="Link to this heading">¶</a></h3>
<p>To transform <span class="math notranslate nohighlight">\(X\)</span> into <span class="math notranslate nohighlight">\(\bar{X}\)</span>, we need to find a projection
matrix <span class="math notranslate nohighlight">\(P\)</span> such that <span class="math notranslate nohighlight">\(\bar{X} = XP\)</span>. We know that for the
training data, <span class="math notranslate nohighlight">\(\Xi = XP\)</span>, and <span class="math notranslate nohighlight">\(X = \Xi \Gamma^T\)</span>. Setting
<span class="math notranslate nohighlight">\(P = U(\Gamma^T U)^{-1}\)</span> where <span class="math notranslate nohighlight">\(U\)</span> is the matrix with the
<span class="math notranslate nohighlight">\(u_k\)</span> in the columns, we have <span class="math notranslate nohighlight">\(XP = X U(\Gamma^T U)^{-1} = \Xi
(\Gamma^T U) (\Gamma^T U)^{-1} = \Xi\)</span> as desired. The rotation matrix
<span class="math notranslate nohighlight">\(P\)</span> can be accessed from the <code class="docutils literal notranslate"><span class="pre">x_rotations_</span></code> attribute.</p>
<p>Similarly, <span class="math notranslate nohighlight">\(Y\)</span> can be transformed using the rotation matrix
<span class="math notranslate nohighlight">\(V(\Delta^T V)^{-1}\)</span>, accessed via the <code class="docutils literal notranslate"><span class="pre">y_rotations_</span></code> attribute.</p>
</section>
<section id="predicting-the-targets-y">
<h3><span class="section-number">1.8.1.2. </span>Predicting the targets Y<a class="headerlink" href="#predicting-the-targets-y" title="Link to this heading">¶</a></h3>
<p>To predict the targets of some data <span class="math notranslate nohighlight">\(X\)</span>, we are looking for a
coefficient matrix <span class="math notranslate nohighlight">\(\beta \in R^{d \times t}\)</span> such that <span class="math notranslate nohighlight">\(Y =
X\beta\)</span>.</p>
<p>The idea is to try to predict the transformed targets <span class="math notranslate nohighlight">\(\Omega\)</span> as a
function of the transformed samples <span class="math notranslate nohighlight">\(\Xi\)</span>, by computing <span class="math notranslate nohighlight">\(\alpha
\in \mathbb{R}\)</span> such that <span class="math notranslate nohighlight">\(\Omega = \alpha \Xi\)</span>.</p>
<p>Then, we have <span class="math notranslate nohighlight">\(Y = \Omega \Delta^T = \alpha \Xi \Delta^T\)</span>, and since
<span class="math notranslate nohighlight">\(\Xi\)</span> is the transformed training data we have that <span class="math notranslate nohighlight">\(Y = X \alpha
P \Delta^T\)</span>, and as a result the coefficient matrix <span class="math notranslate nohighlight">\(\beta = \alpha P
\Delta^T\)</span>.</p>
<p><span class="math notranslate nohighlight">\(\beta\)</span> can be accessed through the <code class="docutils literal notranslate"><span class="pre">coef_</span></code> attribute.</p>
</section>
</section>
<section id="plssvd">
<h2><span class="section-number">1.8.2. </span>PLSSVD<a class="headerlink" href="#plssvd" title="Link to this heading">¶</a></h2>
<p><a class="reference internal" href="generated/sklearn.cross_decomposition.PLSSVD.html#sklearn.cross_decomposition.PLSSVD" title="sklearn.cross_decomposition.PLSSVD"><code class="xref py py-class docutils literal notranslate"><span class="pre">PLSSVD</span></code></a> is a simplified version of <a class="reference internal" href="generated/sklearn.cross_decomposition.PLSCanonical.html#sklearn.cross_decomposition.PLSCanonical" title="sklearn.cross_decomposition.PLSCanonical"><code class="xref py py-class docutils literal notranslate"><span class="pre">PLSCanonical</span></code></a>
described earlier: instead of iteratively deflating the matrices <span class="math notranslate nohighlight">\(X_k\)</span>
and <span class="math notranslate nohighlight">\(Y_k\)</span>, <a class="reference internal" href="generated/sklearn.cross_decomposition.PLSSVD.html#sklearn.cross_decomposition.PLSSVD" title="sklearn.cross_decomposition.PLSSVD"><code class="xref py py-class docutils literal notranslate"><span class="pre">PLSSVD</span></code></a> computes the SVD of <span class="math notranslate nohighlight">\(C = X^TY\)</span>
only <em>once</em>, and stores the <code class="docutils literal notranslate"><span class="pre">n_components</span></code> singular vectors corresponding to
the biggest singular values in the matrices <code class="docutils literal notranslate"><span class="pre">U</span></code> and <code class="docutils literal notranslate"><span class="pre">V</span></code>, corresponding to the
<code class="docutils literal notranslate"><span class="pre">x_weights_</span></code> and <code class="docutils literal notranslate"><span class="pre">y_weights_</span></code> attributes. Here, the transformed data is
simply <code class="docutils literal notranslate"><span class="pre">transformed(X)</span> <span class="pre">=</span> <span class="pre">XU</span></code> and <code class="docutils literal notranslate"><span class="pre">transformed(Y)</span> <span class="pre">=</span> <span class="pre">YV</span></code>.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">n_components</span> <span class="pre">==</span> <span class="pre">1</span></code>, <a class="reference internal" href="generated/sklearn.cross_decomposition.PLSSVD.html#sklearn.cross_decomposition.PLSSVD" title="sklearn.cross_decomposition.PLSSVD"><code class="xref py py-class docutils literal notranslate"><span class="pre">PLSSVD</span></code></a> and <a class="reference internal" href="generated/sklearn.cross_decomposition.PLSCanonical.html#sklearn.cross_decomposition.PLSCanonical" title="sklearn.cross_decomposition.PLSCanonical"><code class="xref py py-class docutils literal notranslate"><span class="pre">PLSCanonical</span></code></a> are
strictly equivalent.</p>
</section>
<section id="plsregression">
<h2><span class="section-number">1.8.3. </span>PLSRegression<a class="headerlink" href="#plsregression" title="Link to this heading">¶</a></h2>
<p>The <a class="reference internal" href="generated/sklearn.cross_decomposition.PLSRegression.html#sklearn.cross_decomposition.PLSRegression" title="sklearn.cross_decomposition.PLSRegression"><code class="xref py py-class docutils literal notranslate"><span class="pre">PLSRegression</span></code></a> estimator is similar to
<a class="reference internal" href="generated/sklearn.cross_decomposition.PLSCanonical.html#sklearn.cross_decomposition.PLSCanonical" title="sklearn.cross_decomposition.PLSCanonical"><code class="xref py py-class docutils literal notranslate"><span class="pre">PLSCanonical</span></code></a> with <code class="docutils literal notranslate"><span class="pre">algorithm='nipals'</span></code>, with 2 significant
differences:</p>
<ul class="simple">
<li><p>at step a) in the power method to compute <span class="math notranslate nohighlight">\(u_k\)</span> and <span class="math notranslate nohighlight">\(v_k\)</span>,
<span class="math notranslate nohighlight">\(v_k\)</span> is never normalized.</p></li>
<li><p>at step c), the targets <span class="math notranslate nohighlight">\(Y_k\)</span> are approximated using the projection
of <span class="math notranslate nohighlight">\(X_k\)</span> (i.e. <span class="math notranslate nohighlight">\(\xi_k\)</span>) instead of the projection of
<span class="math notranslate nohighlight">\(Y_k\)</span> (i.e. <span class="math notranslate nohighlight">\(\omega_k\)</span>). In other words, the loadings
computation is different. As a result, the deflation in step d) will also
be affected.</p></li>
</ul>
<p>These two modifications affect the output of <code class="docutils literal notranslate"><span class="pre">predict</span></code> and <code class="docutils literal notranslate"><span class="pre">transform</span></code>,
which are not the same as for <a class="reference internal" href="generated/sklearn.cross_decomposition.PLSCanonical.html#sklearn.cross_decomposition.PLSCanonical" title="sklearn.cross_decomposition.PLSCanonical"><code class="xref py py-class docutils literal notranslate"><span class="pre">PLSCanonical</span></code></a>. Also, while the number
of components is limited by <code class="docutils literal notranslate"><span class="pre">min(n_samples,</span> <span class="pre">n_features,</span> <span class="pre">n_targets)</span></code> in
<a class="reference internal" href="generated/sklearn.cross_decomposition.PLSCanonical.html#sklearn.cross_decomposition.PLSCanonical" title="sklearn.cross_decomposition.PLSCanonical"><code class="xref py py-class docutils literal notranslate"><span class="pre">PLSCanonical</span></code></a>, here the limit is the rank of <span class="math notranslate nohighlight">\(X^TX\)</span>, i.e.
<code class="docutils literal notranslate"><span class="pre">min(n_samples,</span> <span class="pre">n_features)</span></code>.</p>
<p><a class="reference internal" href="generated/sklearn.cross_decomposition.PLSRegression.html#sklearn.cross_decomposition.PLSRegression" title="sklearn.cross_decomposition.PLSRegression"><code class="xref py py-class docutils literal notranslate"><span class="pre">PLSRegression</span></code></a> is also known as PLS1 (single targets) and PLS2
(multiple targets). Much like <a class="reference internal" href="generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso" title="sklearn.linear_model.Lasso"><code class="xref py py-class docutils literal notranslate"><span class="pre">Lasso</span></code></a>,
<a class="reference internal" href="generated/sklearn.cross_decomposition.PLSRegression.html#sklearn.cross_decomposition.PLSRegression" title="sklearn.cross_decomposition.PLSRegression"><code class="xref py py-class docutils literal notranslate"><span class="pre">PLSRegression</span></code></a> is a form of regularized linear regression where the
number of components controls the strength of the regularization.</p>
</section>
<section id="canonical-correlation-analysis">
<h2><span class="section-number">1.8.4. </span>Canonical Correlation Analysis<a class="headerlink" href="#canonical-correlation-analysis" title="Link to this heading">¶</a></h2>
<p>Canonical Correlation Analysis was developed prior and independently to PLS.
But it turns out that <a class="reference internal" href="generated/sklearn.cross_decomposition.CCA.html#sklearn.cross_decomposition.CCA" title="sklearn.cross_decomposition.CCA"><code class="xref py py-class docutils literal notranslate"><span class="pre">CCA</span></code></a> is a special case of PLS, and corresponds
to PLS in “Mode B” in the literature.</p>
<p><a class="reference internal" href="generated/sklearn.cross_decomposition.CCA.html#sklearn.cross_decomposition.CCA" title="sklearn.cross_decomposition.CCA"><code class="xref py py-class docutils literal notranslate"><span class="pre">CCA</span></code></a> differs from <a class="reference internal" href="generated/sklearn.cross_decomposition.PLSCanonical.html#sklearn.cross_decomposition.PLSCanonical" title="sklearn.cross_decomposition.PLSCanonical"><code class="xref py py-class docutils literal notranslate"><span class="pre">PLSCanonical</span></code></a> in the way the weights
<span class="math notranslate nohighlight">\(u_k\)</span> and <span class="math notranslate nohighlight">\(v_k\)</span> are computed in the power method of step a).
Details can be found in section 10 of <a class="footnote-reference brackets" href="#id6" id="id5" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>.</p>
<p>Since <a class="reference internal" href="generated/sklearn.cross_decomposition.CCA.html#sklearn.cross_decomposition.CCA" title="sklearn.cross_decomposition.CCA"><code class="xref py py-class docutils literal notranslate"><span class="pre">CCA</span></code></a> involves the inversion of <span class="math notranslate nohighlight">\(X_k^TX_k\)</span> and
<span class="math notranslate nohighlight">\(Y_k^TY_k\)</span>, this estimator can be unstable if the number of features or
targets is greater than the number of samples.</p>
<aside class="topic">
<p class="topic-title">Reference:</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id6" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id2">1</a>,<a role="doc-backlink" href="#id3">2</a>,<a role="doc-backlink" href="#id4">3</a>,<a role="doc-backlink" href="#id5">4</a>)</span>
<p><a class="reference external" href="https://stat.uw.edu/sites/default/files/files/reports/2000/tr371.pdf">A survey of Partial Least Squares (PLS) methods, with emphasis on
the two-block case</a>
JA Wegelin</p>
</aside>
</aside>
</aside>
<aside class="topic">
<p class="topic-title">Examples:</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/cross_decomposition/plot_compare_cross_decomposition.html#sphx-glr-auto-examples-cross-decomposition-plot-compare-cross-decomposition-py"><span class="std std-ref">Compare cross decomposition methods</span></a></p></li>
<li><p><a class="reference internal" href="../auto_examples/cross_decomposition/plot_pcr_vs_pls.html#sphx-glr-auto-examples-cross-decomposition-plot-pcr-vs-pls-py"><span class="std std-ref">Principal Component Regression vs Partial Least Squares Regression</span></a></p></li>
</ul>
</aside>
</section>
</section>


      </div>
    <div class="container">
      <footer class="sk-content-footer">
            &copy; 2007 - 2023, scikit-learn developers (BSD License).
          <a href="../_sources/modules/cross_decomposition.rst.txt" rel="nofollow">Show this page source</a>
      </footer>
    </div>
  </div>
</div>
<script src="../_static/js/vendor/bootstrap.min.js"></script>

<script>
    window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
    ga('create', 'UA-22606712-2', 'auto');
    ga('set', 'anonymizeIp', true);
    ga('send', 'pageview');
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>



<script defer data-domain="scikit-learn.org" src="https://views.scientific-python.org/js/script.js">
</script>


<script src="../_static/clipboard.min.js"></script>
<script src="../_static/copybutton.js"></script>

<script>
$(document).ready(function() {
    /* Add a [>>>] button on the top-right corner of code samples to hide
     * the >>> and ... prompts and the output and thus make the code
     * copyable. */
    var div = $('.highlight-python .highlight,' +
                '.highlight-python3 .highlight,' +
                '.highlight-pycon .highlight,' +
		'.highlight-default .highlight')
    var pre = div.find('pre');

    // get the styles from the current theme
    pre.parent().parent().css('position', 'relative');

    // create and add the button to all the code blocks that contain >>>
    div.each(function(index) {
        var jthis = $(this);
        // tracebacks (.gt) contain bare text elements that need to be
        // wrapped in a span to work with .nextUntil() (see later)
        jthis.find('pre:has(.gt)').contents().filter(function() {
            return ((this.nodeType == 3) && (this.data.trim().length > 0));
        }).wrap('<span>');
    });

	/*** Add permalink buttons next to glossary terms ***/
	$('dl.glossary > dt[id]').append(function() {
		return ('<a class="headerlink" href="#' +
			    this.getAttribute('id') +
			    '" title="Permalink to this term">¶</a>');
	});
});

</script>
    
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    
</body>
</html>