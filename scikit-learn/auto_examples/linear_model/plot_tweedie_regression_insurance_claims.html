

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="Description" content="scikit-learn: machine learning in Python">

  
  <title>Tweedie regression on insurance claims &mdash; scikit-learn 0.23.2 documentation</title>
  
  <link rel="canonical" href="http://scikit-learn.org/stable/auto_examples/linear_model/plot_tweedie_regression_insurance_claims.html" />

  
  <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  

  <link rel="stylesheet" href="../../_static/css/vendor/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
<script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
<script src="../../_static/jquery.js"></script> 
</head>
<body>
<nav id="navbar" class="sk-docs-navbar navbar navbar-expand-md navbar-light bg-light py-0">
  <div class="container-fluid sk-docs-container px-0">
      <a class="navbar-brand py-0" href="../../index.html">
        <img
          class="sk-brand-img"
          src="../../_static/scikit-learn-logo-small.png"
          alt="logo"/>
      </a>
    <button
      id="sk-navbar-toggler"
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="sk-navbar-collapse collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../install.html">Install</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../user_guide.html">User Guide</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../modules/classes.html">API</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../index.html">Examples</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../getting_started.html">Getting Started</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../tutorial/index.html">Tutorial</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../whats_new/v0.23.html">What's new</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../glossary.html">Glossary</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../developers/index.html">Development</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../faq.html">FAQ</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../related_projects.html">Related packages</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../roadmap.html">Roadmap</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../about.html">About us</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://github.com/scikit-learn/scikit-learn">GitHub</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://scikit-learn.org/dev/versions.html">Other Versions</a>
        </li>
        <li class="nav-item dropdown nav-more-item-dropdown">
          <a class="sk-nav-link nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">More</a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdown">
              <a class="sk-nav-dropdown-item dropdown-item" href="../../getting_started.html">Getting Started</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../tutorial/index.html">Tutorial</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../whats_new/v0.23.html">What's new</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../glossary.html">Glossary</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../developers/index.html">Development</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../faq.html">FAQ</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../related_projects.html">Related packages</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../roadmap.html">Roadmap</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../about.html">About us</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://github.com/scikit-learn/scikit-learn">GitHub</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://scikit-learn.org/dev/versions.html">Other Versions</a>
          </div>
        </li>
      </ul>
      <div id="searchbox" role="search">
          <div class="searchformwrapper">
          <form class="search" action="../../search.html" method="get">
            <input class="sk-search-text-input" type="text" name="q" aria-labelledby="searchlabel" />
            <input class="sk-search-text-btn" type="submit" value="Go" />
          </form>
          </div>
      </div>
    </div>
  </div>
</nav>
<div class="d-flex" id="sk-doc-wrapper">
    <input type="checkbox" name="sk-toggle-checkbox" id="sk-toggle-checkbox">
    <label id="sk-sidemenu-toggle" class="sk-btn-toggle-toc btn sk-btn-primary" for="sk-toggle-checkbox">Toggle Menu</label>
    <div id="sk-sidebar-wrapper" class="border-right">
      <div class="sk-sidebar-toc-wrapper">
        <div class="sk-sidebar-toc-logo">
          <a href="../../index.html">
            <img
              class="sk-brand-img"
              src="../../_static/scikit-learn-logo-small.png"
              alt="logo"/>
          </a>
        </div>
        <div class="btn-group w-100 mb-2" role="group" aria-label="rellinks">
            <a href="plot_poisson_regression_non_normal_loss.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="Poisson regression and non-normal loss">Prev</a><a href="../index.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="Examples">Up</a>
            <a href="../inspection/plot_permutation_importance_multicollinear.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="Permutation Importance with Multicollinear or Correlated Features">Next</a>
        </div>
        <div class="alert alert-danger p-1 mb-2" role="alert">
          <p class="text-center mb-0">
          <strong>scikit-learn 0.23.2</strong><br/>
          <a href="http://scikit-learn.org/dev/versions.html">Other versions</a>
          </p>
        </div>
        <div class="alert alert-warning p-1 mb-2" role="alert">
          <p class="text-center mb-0">
            Please <a class="font-weight-bold" href="../../about.html#citing-scikit-learn"><string>cite us</string></a> if you use the software.
          </p>
        </div>
          <div class="sk-sidebar-toc">
            <ul>
<li><a class="reference internal" href="#">Tweedie regression on insurance claims</a><ul>
<li><a class="reference internal" href="#loading-datasets-basic-feature-extraction-and-target-definitions">Loading datasets, basic feature extraction and target definitions</a></li>
<li><a class="reference internal" href="#frequency-model-poisson-distribution">Frequency model – Poisson distribution</a></li>
<li><a class="reference internal" href="#severity-model-gamma-distribution">Severity Model -  Gamma distribution</a></li>
<li><a class="reference internal" href="#pure-premium-modeling-via-a-product-model-vs-single-tweedieregressor">Pure Premium Modeling via a Product Model vs single TweedieRegressor</a></li>
</ul>
</li>
</ul>

          </div>
      </div>
    </div>
    <div id="sk-page-content-wrapper">
      <div class="sk-page-content container-fluid body px-md-3" role="main">
        
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-linear-model-plot-tweedie-regression-insurance-claims-py"><span class="std std-ref">here</span></a>     to download the full example code or to run this example in your browser via Binder</p>
</div>
<div class="sphx-glr-example-title section" id="tweedie-regression-on-insurance-claims">
<span id="sphx-glr-auto-examples-linear-model-plot-tweedie-regression-insurance-claims-py"></span><h1>Tweedie regression on insurance claims<a class="headerlink" href="#tweedie-regression-on-insurance-claims" title="Permalink to this headline">¶</a></h1>
<p>This example illustrates the use of Poisson, Gamma and Tweedie regression on
the <a class="reference external" href="https://www.openml.org/d/41214">French Motor Third-Party Liability Claims dataset</a>, and is inspired by an R tutorial <a class="footnote-reference brackets" href="#id2" id="id1">1</a>.</p>
<p>In this dataset, each sample corresponds to an insurance policy, i.e. a
contract within an insurance company and an individual (policyholder).
Available features include driver age, vehicle age, vehicle power, etc.</p>
<p>A few definitions: a <em>claim</em> is the request made by a policyholder to the
insurer to compensate for a loss covered by the insurance. The <em>claim amount</em>
is the amount of money that the insurer must pay. The <em>exposure</em> is the
duration of the insurance coverage of a given policy, in years.</p>
<p>Here our goal goal is to predict the expected
value, i.e. the mean, of the total claim amount per exposure unit also
referred to as the pure premium.</p>
<p>There are several possibilities to do that, two of which are:</p>
<ol class="arabic simple">
<li><p>Model the number of claims with a Poisson distribution, and the average
claim amount per claim, also known as severity, as a Gamma distribution
and multiply the predictions of both in order to get the total claim
amount.</p></li>
<li><p>Model the total claim amount per exposure directly, typically with a Tweedie
distribution of Tweedie power <span class="math notranslate nohighlight">\(p \in (1, 2)\)</span>.</p></li>
</ol>
<p>In this example we will illustrate both approaches. We start by defining a few
helper functions for loading the data and visualizing results.</p>
<dl class="footnote brackets">
<dt class="label" id="id2"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>A. Noll, R. Salzmann and M.V. Wuthrich, Case Study: French Motor
Third-Party Liability Claims (November 8, 2018). <a class="reference external" href="http://dx.doi.org/10.2139/ssrn.3164764">doi:10.2139/ssrn.3164764</a></p>
</dd>
</dl>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>

<span class="c1"># Authors: Christian Lorentzen &lt;lorentzen.ch@gmail.com&gt;</span>
<span class="c1">#          Roman Yurchak &lt;rth.yurchak@gmail.com&gt;</span>
<span class="c1">#          Olivier Grisel &lt;olivier.grisel@ensta.org&gt;</span>
<span class="c1"># License: BSD 3 clause</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_openml</span>
<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">PoissonRegressor</span><span class="p">,</span> <span class="n">GammaRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">TweedieRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_tweedie_deviance</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">FunctionTransformer</span><span class="p">,</span> <span class="n">OneHotEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">KBinsDiscretizer</span>

<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">auc</span>


<span class="k">def</span> <span class="nf">load_mtpl2</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">100000</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Fetch the French Motor Third-Party Liability Claims dataset.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_samples: int, default=100000</span>
<span class="sd">      number of samples to select (for faster run time). Full dataset has</span>
<span class="sd">      678013 samples.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># freMTPL2freq dataset from https://www.openml.org/d/41214</span>
    <span class="n">df_freq</span> <span class="o">=</span> <span class="n">fetch_openml</span><span class="p">(</span><span class="n">data_id</span><span class="o">=</span><span class="mi">41214</span><span class="p">,</span> <span class="n">as_frame</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="s1">&#39;data&#39;</span><span class="p">]</span>
    <span class="n">df_freq</span><span class="p">[</span><span class="s1">&#39;IDpol&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_freq</span><span class="p">[</span><span class="s1">&#39;IDpol&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>
    <span class="n">df_freq</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;IDpol&#39;</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># freMTPL2sev dataset from https://www.openml.org/d/41215</span>
    <span class="n">df_sev</span> <span class="o">=</span> <span class="n">fetch_openml</span><span class="p">(</span><span class="n">data_id</span><span class="o">=</span><span class="mi">41215</span><span class="p">,</span> <span class="n">as_frame</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="s1">&#39;data&#39;</span><span class="p">]</span>

    <span class="c1"># sum ClaimAmount over identical IDs</span>
    <span class="n">df_sev</span> <span class="o">=</span> <span class="n">df_sev</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;IDpol&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

    <span class="n">df</span> <span class="o">=</span> <span class="n">df_freq</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df_sev</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">)</span>
    <span class="n">df</span><span class="p">[</span><span class="s2">&quot;ClaimAmount&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># unquote string fields</span>
    <span class="k">for</span> <span class="n">column_name</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">dtypes</span><span class="o">.</span><span class="n">values</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">object</span><span class="p">]:</span>
        <span class="n">df</span><span class="p">[</span><span class="n">column_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">column_name</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="s2">&quot;&#39;&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">n_samples</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">plot_obs_pred</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">feature</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">observed</span><span class="p">,</span> <span class="n">predicted</span><span class="p">,</span> <span class="n">y_label</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                  <span class="n">title</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">fill_legend</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Plot observed and predicted - aggregated per feature level.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    df : DataFrame</span>
<span class="sd">        input data</span>
<span class="sd">    feature: str</span>
<span class="sd">        a column name of df for the feature to be plotted</span>
<span class="sd">    weight : str</span>
<span class="sd">        column name of df with the values of weights or exposure</span>
<span class="sd">    observed : str</span>
<span class="sd">        a column name of df with the observed target</span>
<span class="sd">    predicted : DataFrame</span>
<span class="sd">        a dataframe, with the same index as df, with the predicted target</span>
<span class="sd">    fill_legend : bool, default=False</span>
<span class="sd">        whether to show fill_between legend</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># aggregate observed and predicted variables by feature level</span>
    <span class="n">df_</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="n">feature</span><span class="p">,</span> <span class="n">weight</span><span class="p">]]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">df_</span><span class="p">[</span><span class="s2">&quot;observed&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">observed</span><span class="p">]</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="n">weight</span><span class="p">]</span>
    <span class="n">df_</span><span class="p">[</span><span class="s2">&quot;predicted&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">predicted</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="n">weight</span><span class="p">]</span>
    <span class="n">df_</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">df_</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="n">feature</span><span class="p">])[[</span><span class="n">weight</span><span class="p">,</span> <span class="s2">&quot;observed&quot;</span><span class="p">,</span> <span class="s2">&quot;predicted&quot;</span><span class="p">]]</span>
        <span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">observed</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;observed&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="n">x</span><span class="p">[</span><span class="n">weight</span><span class="p">])</span>
        <span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">predicted</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;predicted&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="n">x</span><span class="p">[</span><span class="n">weight</span><span class="p">])</span>
    <span class="p">)</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">df_</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s2">&quot;observed&quot;</span><span class="p">,</span> <span class="s2">&quot;predicted&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">y_max</span> <span class="o">=</span> <span class="n">df_</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s2">&quot;observed&quot;</span><span class="p">,</span> <span class="s2">&quot;predicted&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">*</span> <span class="mf">0.8</span>
    <span class="n">p2</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span>
        <span class="n">df_</span><span class="o">.</span><span class="n">index</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="n">y_max</span> <span class="o">*</span> <span class="n">df_</span><span class="p">[</span><span class="n">weight</span><span class="p">]</span> <span class="o">/</span> <span class="n">df_</span><span class="p">[</span><span class="n">weight</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span>
        <span class="n">color</span><span class="o">=</span><span class="s2">&quot;g&quot;</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">fill_legend</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="n">p2</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> distribution&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">feature</span><span class="p">)])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
        <span class="n">ylabel</span><span class="o">=</span><span class="n">y_label</span> <span class="k">if</span> <span class="n">y_label</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">title</span><span class="o">=</span><span class="n">title</span> <span class="k">if</span> <span class="n">title</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="s2">&quot;Train: Observed vs Predicted&quot;</span><span class="p">,</span>
    <span class="p">)</span>


<span class="k">def</span> <span class="nf">score_estimator</span><span class="p">(</span>
    <span class="n">estimator</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">df_train</span><span class="p">,</span> <span class="n">df_test</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span>
    <span class="n">tweedie_powers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Evaluate an estimator on train and test sets with different metrics&quot;&quot;&quot;</span>

    <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span><span class="s2">&quot;D² explained&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>   <span class="c1"># Use default scorer if it exists</span>
        <span class="p">(</span><span class="s2">&quot;mean abs. error&quot;</span><span class="p">,</span> <span class="n">mean_absolute_error</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">&quot;mean squared error&quot;</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">),</span>
    <span class="p">]</span>
    <span class="k">if</span> <span class="n">tweedie_powers</span><span class="p">:</span>
        <span class="n">metrics</span> <span class="o">+=</span> <span class="p">[(</span>
            <span class="s2">&quot;mean Tweedie dev p=</span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">power</span><span class="p">),</span>
            <span class="n">partial</span><span class="p">(</span><span class="n">mean_tweedie_deviance</span><span class="p">,</span> <span class="n">power</span><span class="o">=</span><span class="n">power</span><span class="p">)</span>
        <span class="p">)</span> <span class="k">for</span> <span class="n">power</span> <span class="ow">in</span> <span class="n">tweedie_powers</span><span class="p">]</span>

    <span class="n">res</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">subset_label</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">df</span> <span class="ow">in</span> <span class="p">[</span>
        <span class="p">(</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">df_train</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">&quot;test&quot;</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">df_test</span><span class="p">),</span>
    <span class="p">]:</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">_weights</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">target</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="n">weights</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">score_label</span><span class="p">,</span> <span class="n">metric</span> <span class="ow">in</span> <span class="n">metrics</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">estimator</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="c1"># Score the model consisting of the product of frequency and</span>
                <span class="c1"># severity models.</span>
                <span class="n">est_freq</span><span class="p">,</span> <span class="n">est_sev</span> <span class="o">=</span> <span class="n">estimator</span>
                <span class="n">y_pred</span> <span class="o">=</span> <span class="n">est_freq</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="n">est_sev</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">y_pred</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">metric</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="s2">&quot;score&quot;</span><span class="p">):</span>
                    <span class="k">continue</span>
                <span class="n">score</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">_weights</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">score</span> <span class="o">=</span> <span class="n">metric</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">_weights</span><span class="p">)</span>

            <span class="n">res</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="p">{</span><span class="s2">&quot;subset&quot;</span><span class="p">:</span> <span class="n">subset_label</span><span class="p">,</span> <span class="s2">&quot;metric&quot;</span><span class="p">:</span> <span class="n">score_label</span><span class="p">,</span> <span class="s2">&quot;score&quot;</span><span class="p">:</span> <span class="n">score</span><span class="p">}</span>
            <span class="p">)</span>

    <span class="n">res</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
        <span class="o">.</span><span class="n">set_index</span><span class="p">([</span><span class="s2">&quot;metric&quot;</span><span class="p">,</span> <span class="s2">&quot;subset&quot;</span><span class="p">])</span>
        <span class="o">.</span><span class="n">score</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
        <span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">]]</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span>
</pre></div>
</div>
<div class="section" id="loading-datasets-basic-feature-extraction-and-target-definitions">
<h2>Loading datasets, basic feature extraction and target definitions<a class="headerlink" href="#loading-datasets-basic-feature-extraction-and-target-definitions" title="Permalink to this headline">¶</a></h2>
<p>We construct the freMTPL2 dataset by joining the freMTPL2freq table,
containing the number of claims (<code class="docutils literal notranslate"><span class="pre">ClaimNb</span></code>), with the freMTPL2sev table,
containing the claim amount (<code class="docutils literal notranslate"><span class="pre">ClaimAmount</span></code>) for the same policy ids
(<code class="docutils literal notranslate"><span class="pre">IDpol</span></code>).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">load_mtpl2</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">60000</span><span class="p">)</span>

<span class="c1"># Note: filter out claims with zero amount, as the severity model</span>
<span class="c1"># requires strictly positive target values.</span>
<span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;ClaimAmount&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;ClaimNb&quot;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">),</span> <span class="s2">&quot;ClaimNb&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># Correct for unreasonable observations (that might be data error)</span>
<span class="c1"># and a few exceptionally large claim amounts</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;ClaimNb&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;ClaimNb&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">upper</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;Exposure&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;Exposure&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">upper</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;ClaimAmount&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;ClaimAmount&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">upper</span><span class="o">=</span><span class="mi">200000</span><span class="p">)</span>

<span class="n">log_scale_transformer</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">func</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">),</span>
    <span class="n">StandardScaler</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">column_trans</span> <span class="o">=</span> <span class="n">ColumnTransformer</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">(</span><span class="s2">&quot;binned_numeric&quot;</span><span class="p">,</span> <span class="n">KBinsDiscretizer</span><span class="p">(</span><span class="n">n_bins</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span>
            <span class="p">[</span><span class="s2">&quot;VehAge&quot;</span><span class="p">,</span> <span class="s2">&quot;DrivAge&quot;</span><span class="p">]),</span>
        <span class="p">(</span><span class="s2">&quot;onehot_categorical&quot;</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">(),</span>
            <span class="p">[</span><span class="s2">&quot;VehBrand&quot;</span><span class="p">,</span> <span class="s2">&quot;VehPower&quot;</span><span class="p">,</span> <span class="s2">&quot;VehGas&quot;</span><span class="p">,</span> <span class="s2">&quot;Region&quot;</span><span class="p">,</span> <span class="s2">&quot;Area&quot;</span><span class="p">]),</span>
        <span class="p">(</span><span class="s2">&quot;passthrough_numeric&quot;</span><span class="p">,</span> <span class="s2">&quot;passthrough&quot;</span><span class="p">,</span>
            <span class="p">[</span><span class="s2">&quot;BonusMalus&quot;</span><span class="p">]),</span>
        <span class="p">(</span><span class="s2">&quot;log_scaled_numeric&quot;</span><span class="p">,</span> <span class="n">log_scale_transformer</span><span class="p">,</span>
            <span class="p">[</span><span class="s2">&quot;Density&quot;</span><span class="p">]),</span>
    <span class="p">],</span>
    <span class="n">remainder</span><span class="o">=</span><span class="s2">&quot;drop&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">column_trans</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="c1"># Insurances companies are interested in modeling the Pure Premium, that is</span>
<span class="c1"># the expected total claim amount per unit of exposure for each policyholder</span>
<span class="c1"># in their portfolio:</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;PurePremium&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;ClaimAmount&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;Exposure&quot;</span><span class="p">]</span>

<span class="c1"># This can be indirectly approximated by a 2-step modeling: the product of the</span>
<span class="c1"># Frequency times the average claim amount per claim:</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;Frequency&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;ClaimNb&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;Exposure&quot;</span><span class="p">]</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;AvgClaimAmount&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;ClaimAmount&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">fmax</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;ClaimNb&quot;</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>

<span class="k">with</span> <span class="n">pd</span><span class="o">.</span><span class="n">option_context</span><span class="p">(</span><span class="s2">&quot;display.max_columns&quot;</span><span class="p">,</span> <span class="mi">15</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">ClaimAmount</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.8/dist-packages/sklearn/datasets/_openml.py:754: UserWarning: Version 1 of dataset freMTPL2freq is inactive, meaning that issues have been found in the dataset. Try using a newer version from this URL: https://www.openml.org/data/v1/download/20649148/freMTPL2freq.arff
  warn(&quot;Version {} of dataset {} is inactive, meaning that issues have &quot;
/usr/local/lib/python3.8/dist-packages/sklearn/datasets/_openml.py:754: UserWarning: Version 1 of dataset freMTPL2sev is inactive, meaning that issues have been found in the dataset. Try using a newer version from this URL: https://www.openml.org/data/v1/download/20649149/freMTPL2sev.arff
  warn(&quot;Version {} of dataset {} is inactive, meaning that issues have &quot;
/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_discretization.py:200: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(&#39;Bins whose width are too small (i.e., &lt;= &#39;
       ClaimNb  Exposure Area  VehPower  VehAge  DrivAge  BonusMalus VehBrand  \
IDpol
139        1.0      0.75    F       7.0     1.0     61.0        50.0      B12
190        1.0      0.14    B      12.0     5.0     50.0        60.0      B12
414        1.0      0.14    E       4.0     0.0     36.0        85.0      B12
424        2.0      0.62    F      10.0     0.0     51.0       100.0      B12
463        1.0      0.31    A       5.0     0.0     45.0        50.0      B12

        VehGas  Density Region  ClaimAmount   PurePremium  Frequency  \
IDpol
139    Regular  27000.0    R11       303.00    404.000000   1.333333
190     Diesel     56.0    R25      1981.84  14156.000000   7.142857
414    Regular   4792.0    R11      1456.55  10403.928571   7.142857
424    Regular  27000.0    R11     10834.00  17474.193548   3.225806
463    Regular     12.0    R73      3986.67  12860.225806   3.225806

       AvgClaimAmount
IDpol
139            303.00
190           1981.84
414           1456.55
424           5417.00
463           3986.67
</pre></div>
</div>
</div>
<div class="section" id="frequency-model-poisson-distribution">
<h2>Frequency model – Poisson distribution<a class="headerlink" href="#frequency-model-poisson-distribution" title="Permalink to this headline">¶</a></h2>
<p>The number of claims (<code class="docutils literal notranslate"><span class="pre">ClaimNb</span></code>) is a positive integer (0 included).
Thus, this target can be modelled by a Poisson distribution.
It is then assumed to be the number of discrete events occuring with a
constant rate in a given time interval (<code class="docutils literal notranslate"><span class="pre">Exposure</span></code>, in units of years).
Here we model the frequency <code class="docutils literal notranslate"><span class="pre">y</span> <span class="pre">=</span> <span class="pre">ClaimNb</span> <span class="pre">/</span> <span class="pre">Exposure</span></code>, which is still a
(scaled) Poisson distribution, and use <code class="docutils literal notranslate"><span class="pre">Exposure</span></code> as <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">df_train</span><span class="p">,</span> <span class="n">df_test</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># The parameters of the model are estimated by minimizing the Poisson deviance</span>
<span class="c1"># on the training set via a quasi-Newton solver: l-BFGS. Some of the features</span>
<span class="c1"># are collinear, we use a weak penalization to avoid numerical issues.</span>
<span class="n">glm_freq</span> <span class="o">=</span> <span class="n">PoissonRegressor</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">400</span><span class="p">)</span>
<span class="n">glm_freq</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">df_train</span><span class="p">[</span><span class="s2">&quot;Frequency&quot;</span><span class="p">],</span>
             <span class="n">sample_weight</span><span class="o">=</span><span class="n">df_train</span><span class="p">[</span><span class="s2">&quot;Exposure&quot;</span><span class="p">])</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">score_estimator</span><span class="p">(</span>
    <span class="n">glm_freq</span><span class="p">,</span>
    <span class="n">X_train</span><span class="p">,</span>
    <span class="n">X_test</span><span class="p">,</span>
    <span class="n">df_train</span><span class="p">,</span>
    <span class="n">df_test</span><span class="p">,</span>
    <span class="n">target</span><span class="o">=</span><span class="s2">&quot;Frequency&quot;</span><span class="p">,</span>
    <span class="n">weights</span><span class="o">=</span><span class="s2">&quot;Exposure&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Evaluation of PoissonRegressor on target Frequency&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Evaluation of PoissonRegressor on target Frequency
subset               train    test
metric
D² explained        0.0590  0.0579
mean abs. error     0.1706  0.1661
mean squared error  0.3041  0.3043
</pre></div>
</div>
<p>We can visually compare observed and predicted values, aggregated by the
drivers age (<code class="docutils literal notranslate"><span class="pre">DrivAge</span></code>), vehicle age (<code class="docutils literal notranslate"><span class="pre">VehAge</span></code>) and the insurance
bonus/malus (<code class="docutils literal notranslate"><span class="pre">BonusMalus</span></code>).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">fig</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="n">plot_obs_pred</span><span class="p">(</span>
    <span class="n">df</span><span class="o">=</span><span class="n">df_train</span><span class="p">,</span>
    <span class="n">feature</span><span class="o">=</span><span class="s2">&quot;DrivAge&quot;</span><span class="p">,</span>
    <span class="n">weight</span><span class="o">=</span><span class="s2">&quot;Exposure&quot;</span><span class="p">,</span>
    <span class="n">observed</span><span class="o">=</span><span class="s2">&quot;Frequency&quot;</span><span class="p">,</span>
    <span class="n">predicted</span><span class="o">=</span><span class="n">glm_freq</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span>
    <span class="n">y_label</span><span class="o">=</span><span class="s2">&quot;Claim Frequency&quot;</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;train data&quot;</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="p">)</span>

<span class="n">plot_obs_pred</span><span class="p">(</span>
    <span class="n">df</span><span class="o">=</span><span class="n">df_test</span><span class="p">,</span>
    <span class="n">feature</span><span class="o">=</span><span class="s2">&quot;DrivAge&quot;</span><span class="p">,</span>
    <span class="n">weight</span><span class="o">=</span><span class="s2">&quot;Exposure&quot;</span><span class="p">,</span>
    <span class="n">observed</span><span class="o">=</span><span class="s2">&quot;Frequency&quot;</span><span class="p">,</span>
    <span class="n">predicted</span><span class="o">=</span><span class="n">glm_freq</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span>
    <span class="n">y_label</span><span class="o">=</span><span class="s2">&quot;Claim Frequency&quot;</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;test data&quot;</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="n">fill_legend</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>

<span class="n">plot_obs_pred</span><span class="p">(</span>
    <span class="n">df</span><span class="o">=</span><span class="n">df_test</span><span class="p">,</span>
    <span class="n">feature</span><span class="o">=</span><span class="s2">&quot;VehAge&quot;</span><span class="p">,</span>
    <span class="n">weight</span><span class="o">=</span><span class="s2">&quot;Exposure&quot;</span><span class="p">,</span>
    <span class="n">observed</span><span class="o">=</span><span class="s2">&quot;Frequency&quot;</span><span class="p">,</span>
    <span class="n">predicted</span><span class="o">=</span><span class="n">glm_freq</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span>
    <span class="n">y_label</span><span class="o">=</span><span class="s2">&quot;Claim Frequency&quot;</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;test data&quot;</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="n">fill_legend</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>

<span class="n">plot_obs_pred</span><span class="p">(</span>
    <span class="n">df</span><span class="o">=</span><span class="n">df_test</span><span class="p">,</span>
    <span class="n">feature</span><span class="o">=</span><span class="s2">&quot;BonusMalus&quot;</span><span class="p">,</span>
    <span class="n">weight</span><span class="o">=</span><span class="s2">&quot;Exposure&quot;</span><span class="p">,</span>
    <span class="n">observed</span><span class="o">=</span><span class="s2">&quot;Frequency&quot;</span><span class="p">,</span>
    <span class="n">predicted</span><span class="o">=</span><span class="n">glm_freq</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span>
    <span class="n">y_label</span><span class="o">=</span><span class="s2">&quot;Claim Frequency&quot;</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;test data&quot;</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="n">fill_legend</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</pre></div>
</div>
<img alt="train data, test data, test data, test data" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_tweedie_regression_insurance_claims_001.png" />
<p>According to the observed data, the frequency of accidents is higher for
drivers younger than 30 years old, and is positively correlated with the
<code class="docutils literal notranslate"><span class="pre">BonusMalus</span></code> variable. Our model is able to mostly correctly model this
behaviour.</p>
</div>
<div class="section" id="severity-model-gamma-distribution">
<h2>Severity Model -  Gamma distribution<a class="headerlink" href="#severity-model-gamma-distribution" title="Permalink to this headline">¶</a></h2>
<p>The mean claim amount or severity (<code class="docutils literal notranslate"><span class="pre">AvgClaimAmount</span></code>) can be empirically
shown to follow approximately a Gamma distribution. We fit a GLM model for
the severity with the same features as the frequency model.</p>
<p>Note:</p>
<ul class="simple">
<li><p>We filter out <code class="docutils literal notranslate"><span class="pre">ClaimAmount</span> <span class="pre">==</span> <span class="pre">0</span></code> as the Gamma distribution has support
on <span class="math notranslate nohighlight">\((0, \infty)\)</span>, not <span class="math notranslate nohighlight">\([0, \infty)\)</span>.</p></li>
<li><p>We use <code class="docutils literal notranslate"><span class="pre">ClaimNb</span></code> as <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code> to account for policies that contain
more than one claim.</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mask_train</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[</span><span class="s2">&quot;ClaimAmount&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span>
<span class="n">mask_test</span> <span class="o">=</span> <span class="n">df_test</span><span class="p">[</span><span class="s2">&quot;ClaimAmount&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span>

<span class="n">glm_sev</span> <span class="o">=</span> <span class="n">GammaRegressor</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">10.</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>

<span class="n">glm_sev</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">X_train</span><span class="p">[</span><span class="n">mask_train</span><span class="o">.</span><span class="n">values</span><span class="p">],</span>
    <span class="n">df_train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">mask_train</span><span class="p">,</span> <span class="s2">&quot;AvgClaimAmount&quot;</span><span class="p">],</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="n">df_train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">mask_train</span><span class="p">,</span> <span class="s2">&quot;ClaimNb&quot;</span><span class="p">],</span>
<span class="p">)</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">score_estimator</span><span class="p">(</span>
    <span class="n">glm_sev</span><span class="p">,</span>
    <span class="n">X_train</span><span class="p">[</span><span class="n">mask_train</span><span class="o">.</span><span class="n">values</span><span class="p">],</span>
    <span class="n">X_test</span><span class="p">[</span><span class="n">mask_test</span><span class="o">.</span><span class="n">values</span><span class="p">],</span>
    <span class="n">df_train</span><span class="p">[</span><span class="n">mask_train</span><span class="p">],</span>
    <span class="n">df_test</span><span class="p">[</span><span class="n">mask_test</span><span class="p">],</span>
    <span class="n">target</span><span class="o">=</span><span class="s2">&quot;AvgClaimAmount&quot;</span><span class="p">,</span>
    <span class="n">weights</span><span class="o">=</span><span class="s2">&quot;ClaimNb&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Evaluation of GammaRegressor on target AvgClaimAmount&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Evaluation of GammaRegressor on target AvgClaimAmount
subset                     train          test
metric
D² explained        4.300000e-03 -1.380000e-02
mean abs. error     1.699197e+03  2.027923e+03
mean squared error  4.548147e+07  6.094863e+07
</pre></div>
</div>
<p>Here, the scores for the test data call for caution as they are
significantly worse than for the training data indicating an overfit despite
the strong regularization.</p>
<p>Note that the resulting model is the average claim amount per claim. As
such, it is conditional on having at least one claim, and cannot be used to
predict the average claim amount per policy in general.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean AvgClaim Amount per policy:              </span><span class="si">%.2f</span><span class="s2"> &quot;</span>
      <span class="o">%</span> <span class="n">df_train</span><span class="p">[</span><span class="s2">&quot;AvgClaimAmount&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean AvgClaim Amount | NbClaim &gt; 0:           </span><span class="si">%.2f</span><span class="s2">&quot;</span>
      <span class="o">%</span> <span class="n">df_train</span><span class="p">[</span><span class="s2">&quot;AvgClaimAmount&quot;</span><span class="p">][</span><span class="n">df_train</span><span class="p">[</span><span class="s2">&quot;AvgClaimAmount&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Predicted Mean AvgClaim Amount | NbClaim &gt; 0: </span><span class="si">%.2f</span><span class="s2">&quot;</span>
      <span class="o">%</span> <span class="n">glm_sev</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Mean AvgClaim Amount per policy:              97.89
Mean AvgClaim Amount | NbClaim &gt; 0:           1899.60
Predicted Mean AvgClaim Amount | NbClaim &gt; 0: 1884.40
</pre></div>
</div>
<p>We can visually compare observed and predicted values, aggregated for
the drivers age (<code class="docutils literal notranslate"><span class="pre">DrivAge</span></code>).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">plot_obs_pred</span><span class="p">(</span>
    <span class="n">df</span><span class="o">=</span><span class="n">df_train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">mask_train</span><span class="p">],</span>
    <span class="n">feature</span><span class="o">=</span><span class="s2">&quot;DrivAge&quot;</span><span class="p">,</span>
    <span class="n">weight</span><span class="o">=</span><span class="s2">&quot;Exposure&quot;</span><span class="p">,</span>
    <span class="n">observed</span><span class="o">=</span><span class="s2">&quot;AvgClaimAmount&quot;</span><span class="p">,</span>
    <span class="n">predicted</span><span class="o">=</span><span class="n">glm_sev</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">mask_train</span><span class="o">.</span><span class="n">values</span><span class="p">]),</span>
    <span class="n">y_label</span><span class="o">=</span><span class="s2">&quot;Average Claim Severity&quot;</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;train data&quot;</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
<span class="p">)</span>

<span class="n">plot_obs_pred</span><span class="p">(</span>
    <span class="n">df</span><span class="o">=</span><span class="n">df_test</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">mask_test</span><span class="p">],</span>
    <span class="n">feature</span><span class="o">=</span><span class="s2">&quot;DrivAge&quot;</span><span class="p">,</span>
    <span class="n">weight</span><span class="o">=</span><span class="s2">&quot;Exposure&quot;</span><span class="p">,</span>
    <span class="n">observed</span><span class="o">=</span><span class="s2">&quot;AvgClaimAmount&quot;</span><span class="p">,</span>
    <span class="n">predicted</span><span class="o">=</span><span class="n">glm_sev</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">mask_test</span><span class="o">.</span><span class="n">values</span><span class="p">]),</span>
    <span class="n">y_label</span><span class="o">=</span><span class="s2">&quot;Average Claim Severity&quot;</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;test data&quot;</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
    <span class="n">fill_legend</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
<img alt="train data, test data" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_tweedie_regression_insurance_claims_002.png" />
<p>Overall, the drivers age (<code class="docutils literal notranslate"><span class="pre">DrivAge</span></code>) has a weak impact on the claim
severity, both in observed and predicted data.</p>
</div>
<div class="section" id="pure-premium-modeling-via-a-product-model-vs-single-tweedieregressor">
<h2>Pure Premium Modeling via a Product Model vs single TweedieRegressor<a class="headerlink" href="#pure-premium-modeling-via-a-product-model-vs-single-tweedieregressor" title="Permalink to this headline">¶</a></h2>
<p>As mentioned in the introduction, the total claim amount per unit of
exposure can be modeled as the product of the prediction of the
frequency model by the prediction of the severity model.</p>
<p>Alternatively, one can directly model the total loss with a unique
Compound Poisson Gamma generalized linear model (with a log link function).
This model is a special case of the Tweedie GLM with a “power” parameter
<span class="math notranslate nohighlight">\(p \in (1, 2)\)</span>. Here, we fix apriori the <code class="docutils literal notranslate"><span class="pre">power</span></code> parameter of the
Tweedie model to some arbitrary value (1.9) in the valid range. Ideally one
would select this value via grid-search by minimizing the negative
log-likelihood of the Tweedie model, but unfortunately the current
implementation does not allow for this (yet).</p>
<p>We will compare the performance of both approaches.
To quantify the performance of both models, one can compute
the mean deviance of the train and test data assuming a Compound
Poisson-Gamma distribution of the total claim amount. This is equivalent to
a Tweedie distribution with a <code class="docutils literal notranslate"><span class="pre">power</span></code> parameter between 1 and 2.</p>
<p>The <a class="reference internal" href="../../modules/generated/sklearn.metrics.mean_tweedie_deviance.html#sklearn.metrics.mean_tweedie_deviance" title="sklearn.metrics.mean_tweedie_deviance"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.mean_tweedie_deviance</span></code></a> depends on a <code class="docutils literal notranslate"><span class="pre">power</span></code>
parameter. As we do not know the true value of the <code class="docutils literal notranslate"><span class="pre">power</span></code> parameter, we here
compute the mean deviances for a grid of possible values, and compare the
models side by side, i.e. we compare them at identical values of <code class="docutils literal notranslate"><span class="pre">power</span></code>.
Ideally, we hope that one model will be consistently better than the other,
regardless of <code class="docutils literal notranslate"><span class="pre">power</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">glm_pure_premium</span> <span class="o">=</span> <span class="n">TweedieRegressor</span><span class="p">(</span><span class="n">power</span><span class="o">=</span><span class="mf">1.9</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=.</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
<span class="n">glm_pure_premium</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">df_train</span><span class="p">[</span><span class="s2">&quot;PurePremium&quot;</span><span class="p">],</span>
                     <span class="n">sample_weight</span><span class="o">=</span><span class="n">df_train</span><span class="p">[</span><span class="s2">&quot;Exposure&quot;</span><span class="p">])</span>

<span class="n">tweedie_powers</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">1.7</span><span class="p">,</span> <span class="mf">1.8</span><span class="p">,</span> <span class="mf">1.9</span><span class="p">,</span> <span class="mf">1.99</span><span class="p">,</span> <span class="mf">1.999</span><span class="p">,</span> <span class="mf">1.9999</span><span class="p">]</span>

<span class="n">scores_product_model</span> <span class="o">=</span> <span class="n">score_estimator</span><span class="p">(</span>
    <span class="p">(</span><span class="n">glm_freq</span><span class="p">,</span> <span class="n">glm_sev</span><span class="p">),</span>
    <span class="n">X_train</span><span class="p">,</span>
    <span class="n">X_test</span><span class="p">,</span>
    <span class="n">df_train</span><span class="p">,</span>
    <span class="n">df_test</span><span class="p">,</span>
    <span class="n">target</span><span class="o">=</span><span class="s2">&quot;PurePremium&quot;</span><span class="p">,</span>
    <span class="n">weights</span><span class="o">=</span><span class="s2">&quot;Exposure&quot;</span><span class="p">,</span>
    <span class="n">tweedie_powers</span><span class="o">=</span><span class="n">tweedie_powers</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">scores_glm_pure_premium</span> <span class="o">=</span> <span class="n">score_estimator</span><span class="p">(</span>
    <span class="n">glm_pure_premium</span><span class="p">,</span>
    <span class="n">X_train</span><span class="p">,</span>
    <span class="n">X_test</span><span class="p">,</span>
    <span class="n">df_train</span><span class="p">,</span>
    <span class="n">df_test</span><span class="p">,</span>
    <span class="n">target</span><span class="o">=</span><span class="s2">&quot;PurePremium&quot;</span><span class="p">,</span>
    <span class="n">weights</span><span class="o">=</span><span class="s2">&quot;Exposure&quot;</span><span class="p">,</span>
    <span class="n">tweedie_powers</span><span class="o">=</span><span class="n">tweedie_powers</span>
<span class="p">)</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">scores_product_model</span><span class="p">,</span> <span class="n">scores_glm_pure_premium</span><span class="p">],</span>
                   <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">sort</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                   <span class="n">keys</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;Product Model&#39;</span><span class="p">,</span> <span class="s1">&#39;TweedieRegressor&#39;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Evaluation of the Product Model and the Tweedie Regressor &quot;</span>
      <span class="s2">&quot;on target PurePremium&quot;</span><span class="p">)</span>
<span class="k">with</span> <span class="n">pd</span><span class="o">.</span><span class="n">option_context</span><span class="p">(</span><span class="s1">&#39;display.expand_frame_repr&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Evaluation of the Product Model and the Tweedie Regressor on target PurePremium
                          Product Model               TweedieRegressor
subset                            train          test            train          test
D² explained                        NaN           NaN     2.550000e-02  2.480000e-02
mean Tweedie dev p=1.5000  8.217800e+01  8.639750e+01     7.960780e+01  8.618780e+01
mean Tweedie dev p=1.7000  3.833700e+01  3.920270e+01     3.737390e+01  3.917480e+01
mean Tweedie dev p=1.8000  3.106890e+01  3.148660e+01     3.047890e+01  3.148140e+01
mean Tweedie dev p=1.9000  3.396240e+01  3.420550e+01     3.360060e+01  3.420830e+01
mean Tweedie dev p=1.9900  1.989243e+02  1.996416e+02     1.986911e+02  1.996462e+02
mean Tweedie dev p=1.9990  1.886429e+03  1.892748e+03     1.886206e+03  1.892753e+03
mean Tweedie dev p=1.9999  1.876452e+04  1.882692e+04     1.876430e+04  1.882692e+04
mean abs. error            3.246831e+02  3.469773e+02     3.202432e+02  3.397005e+02
mean squared error         1.469183e+08  3.325903e+07     1.469327e+08  3.325470e+07
</pre></div>
</div>
<p>In this example, both modeling approaches yield comparable performance
metrics. For implementation reasons, the percentage of explained variance
<span class="math notranslate nohighlight">\(D^2\)</span> is not available for the product model.</p>
<p>We can additionally validate these models by comparing observed and
predicted total claim amount over the test and train subsets. We see that,
on average, both model tend to underestimate the total claim (but this
behavior depends on the amount of regularization).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">res</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">subset_label</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">df</span> <span class="ow">in</span> <span class="p">[</span>
    <span class="p">(</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">df_train</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;test&quot;</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">df_test</span><span class="p">),</span>
<span class="p">]:</span>
    <span class="n">exposure</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;Exposure&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
    <span class="n">res</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s2">&quot;subset&quot;</span><span class="p">:</span> <span class="n">subset_label</span><span class="p">,</span>
            <span class="s2">&quot;observed&quot;</span><span class="p">:</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;ClaimAmount&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span>
            <span class="s2">&quot;predicted, frequency*severity model&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
                <span class="n">exposure</span> <span class="o">*</span> <span class="n">glm_freq</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="n">glm_sev</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="p">),</span>
            <span class="s2">&quot;predicted, tweedie, power=</span><span class="si">%.2f</span><span class="s2">&quot;</span>
            <span class="o">%</span> <span class="n">glm_pure_premium</span><span class="o">.</span><span class="n">power</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
                <span class="n">exposure</span> <span class="o">*</span> <span class="n">glm_pure_premium</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)),</span>
        <span class="p">}</span>
    <span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">res</span><span class="p">)</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s2">&quot;subset&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>subset                                      train          test
observed                             4.577616e+06  1.725665e+06
predicted, frequency*severity model  4.565330e+06  1.495512e+06
predicted, tweedie, power=1.90       4.451462e+06  1.431938e+06
</pre></div>
</div>
<p>Finally, we can compare the two models using a plot of cumulated claims: for
each model, the policyholders are ranked from safest to riskiest and the
fraction of observed total cumulated claims is plotted on the y axis. This
plot is often called the ordered Lorenz curve of the model.</p>
<p>The Gini coefficient (based on the area under the curve) can be used as a
model selection metric to quantify the ability of the model to rank
policyholders. Note that this metric does not reflect the ability of the
models to make accurate predictions in terms of absolute value of total
claim amounts but only in terms of relative amounts as a ranking metric.</p>
<p>Both models are able to rank policyholders by risky-ness significantly
better than chance although they are also both far from perfect due to the
natural difficulty of the prediction problem from few features.</p>
<p>Note that the Gini index only characterize the ranking performance of the
model but not its calibration: any monotonic transformation of the
predictions leaves the Gini index of the model unchanged.</p>
<p>Finally one should highlight that the Compound Poisson Gamma model that
is directly fit on the pure premium is operationally simpler to develop and
maintain as it consists in a single scikit-learn estimator instead of a
pair of models, each with its own set of hyperparameters.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">lorenz_curve</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">exposure</span><span class="p">):</span>
    <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y_true</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
    <span class="n">exposure</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">exposure</span><span class="p">)</span>

    <span class="c1"># order samples by increasing predicted risk:</span>
    <span class="n">ranking</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
    <span class="n">ranked_exposure</span> <span class="o">=</span> <span class="n">exposure</span><span class="p">[</span><span class="n">ranking</span><span class="p">]</span>
    <span class="n">ranked_pure_premium</span> <span class="o">=</span> <span class="n">y_true</span><span class="p">[</span><span class="n">ranking</span><span class="p">]</span>
    <span class="n">cumulated_claim_amount</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">ranked_pure_premium</span> <span class="o">*</span> <span class="n">ranked_exposure</span><span class="p">)</span>
    <span class="n">cumulated_claim_amount</span> <span class="o">/=</span> <span class="n">cumulated_claim_amount</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">cumulated_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">cumulated_claim_amount</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">cumulated_samples</span><span class="p">,</span> <span class="n">cumulated_claim_amount</span>


<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="n">y_pred_product</span> <span class="o">=</span> <span class="n">glm_freq</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span> <span class="o">*</span> <span class="n">glm_sev</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_pred_total</span> <span class="o">=</span> <span class="n">glm_pure_premium</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">y_pred</span> <span class="ow">in</span> <span class="p">[(</span><span class="s2">&quot;Frequency * Severity model&quot;</span><span class="p">,</span> <span class="n">y_pred_product</span><span class="p">),</span>
                      <span class="p">(</span><span class="s2">&quot;Compound Poisson Gamma&quot;</span><span class="p">,</span> <span class="n">y_pred_total</span><span class="p">)]:</span>
    <span class="n">ordered_samples</span><span class="p">,</span> <span class="n">cum_claims</span> <span class="o">=</span> <span class="n">lorenz_curve</span><span class="p">(</span>
        <span class="n">df_test</span><span class="p">[</span><span class="s2">&quot;PurePremium&quot;</span><span class="p">],</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">df_test</span><span class="p">[</span><span class="s2">&quot;Exposure&quot;</span><span class="p">])</span>
    <span class="n">gini</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">auc</span><span class="p">(</span><span class="n">ordered_samples</span><span class="p">,</span> <span class="n">cum_claims</span><span class="p">)</span>
    <span class="n">label</span> <span class="o">+=</span> <span class="s2">&quot; (Gini index: </span><span class="si">{:.3f}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gini</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ordered_samples</span><span class="p">,</span> <span class="n">cum_claims</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;-&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>

<span class="c1"># Oracle model: y_pred == y_test</span>
<span class="n">ordered_samples</span><span class="p">,</span> <span class="n">cum_claims</span> <span class="o">=</span> <span class="n">lorenz_curve</span><span class="p">(</span>
    <span class="n">df_test</span><span class="p">[</span><span class="s2">&quot;PurePremium&quot;</span><span class="p">],</span> <span class="n">df_test</span><span class="p">[</span><span class="s2">&quot;PurePremium&quot;</span><span class="p">],</span> <span class="n">df_test</span><span class="p">[</span><span class="s2">&quot;Exposure&quot;</span><span class="p">])</span>
<span class="n">gini</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">auc</span><span class="p">(</span><span class="n">ordered_samples</span><span class="p">,</span> <span class="n">cum_claims</span><span class="p">)</span>
<span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;Oracle (Gini index: </span><span class="si">{:.3f}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gini</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ordered_samples</span><span class="p">,</span> <span class="n">cum_claims</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;-.&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>

<span class="c1"># Random baseline</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Random baseline&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Lorenz Curves&quot;</span><span class="p">,</span>
    <span class="n">xlabel</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;Fraction of policyholders</span><span class="se">\n</span><span class="s1">&#39;</span>
            <span class="s1">&#39;(ordered by model from safest to riskiest)&#39;</span><span class="p">),</span>
    <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Fraction of total claim amount&#39;</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;upper left&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>
</div>
<img alt="Lorenz Curves" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_tweedie_regression_insurance_claims_003.png" />
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[]
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  18.481 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-linear-model-plot-tweedie-regression-insurance-claims-py">
<div class="binder-badge docutils container">
<a class="reference external image-reference" href="https://mybinder.org/v2/gh/scikit-learn/scikit-learn/0.23.X?urlpath=lab/tree/notebooks/auto_examples/linear_model/plot_tweedie_regression_insurance_claims.ipynb"><img alt="Launch binder" src="../../_images/binder_badge_logo14.svg" width="150px" /></a>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/86c888008757148890daaf43d664fa71/plot_tweedie_regression_insurance_claims.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_tweedie_regression_insurance_claims.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/a97bf662e52d471b04e1ab480c0ad7f2/plot_tweedie_regression_insurance_claims.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_tweedie_regression_insurance_claims.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


      </div>
    <div class="container">
      <footer class="sk-content-footer">
            &copy; 2007 - 2020, scikit-learn developers (BSD License).
          <a href="../../_sources/auto_examples/linear_model/plot_tweedie_regression_insurance_claims.rst.txt" rel="nofollow">Show this page source</a>
      </footer>
    </div>
  </div>
</div>
<script src="../../_static/js/vendor/bootstrap.min.js"></script>

<script>
    window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
    ga('create', 'UA-22606712-2', 'auto');
    ga('set', 'anonymizeIp', true);
    ga('send', 'pageview');
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


<script>
$(document).ready(function() {
    /* Add a [>>>] button on the top-right corner of code samples to hide
     * the >>> and ... prompts and the output and thus make the code
     * copyable. */
    var div = $('.highlight-python .highlight,' +
                '.highlight-python3 .highlight,' +
                '.highlight-pycon .highlight,' +
		'.highlight-default .highlight')
    var pre = div.find('pre');

    // get the styles from the current theme
    pre.parent().parent().css('position', 'relative');
    var hide_text = 'Hide prompts and outputs';
    var show_text = 'Show prompts and outputs';

    // create and add the button to all the code blocks that contain >>>
    div.each(function(index) {
        var jthis = $(this);
        if (jthis.find('.gp').length > 0) {
            var button = $('<span class="copybutton">&gt;&gt;&gt;</span>');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
            jthis.prepend(button);
        }
        // tracebacks (.gt) contain bare text elements that need to be
        // wrapped in a span to work with .nextUntil() (see later)
        jthis.find('pre:has(.gt)').contents().filter(function() {
            return ((this.nodeType == 3) && (this.data.trim().length > 0));
        }).wrap('<span>');
    });

    // define the behavior of the button when it's clicked
    $('.copybutton').click(function(e){
        e.preventDefault();
        var button = $(this);
        if (button.data('hidden') === 'false') {
            // hide the code output
            button.parent().find('.go, .gp, .gt').hide();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'hidden');
            button.css('text-decoration', 'line-through');
            button.attr('title', show_text);
            button.data('hidden', 'true');
        } else {
            // show the code output
            button.parent().find('.go, .gp, .gt').show();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'visible');
            button.css('text-decoration', 'none');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
        }
    });

	/*** Add permalink buttons next to glossary terms ***/
	$('dl.glossary > dt[id]').append(function() {
		return ('<a class="headerlink" href="#' +
			    this.getAttribute('id') +
			    '" title="Permalink to this term">¶</a>');
	});
  /*** Hide navbar when scrolling down ***/
  // Returns true when headerlink target matches hash in url
  (function() {
    hashTargetOnTop = function() {
        var hash = window.location.hash;
        if ( hash.length < 2 ) { return false; }

        var target = document.getElementById( hash.slice(1) );
        if ( target === null ) { return false; }

        var top = target.getBoundingClientRect().top;
        return (top < 2) && (top > -2);
    };

    // Hide navbar on load if hash target is on top
    var navBar = document.getElementById("navbar");
    var navBarToggler = document.getElementById("sk-navbar-toggler");
    var navBarHeightHidden = "-" + navBar.getBoundingClientRect().height + "px";
    var $window = $(window);

    hideNavBar = function() {
        navBar.style.top = navBarHeightHidden;
    };

    showNavBar = function() {
        navBar.style.top = "0";
    }

    if (hashTargetOnTop()) {
        hideNavBar()
    }

    var prevScrollpos = window.pageYOffset;
    hideOnScroll = function(lastScrollTop) {
        if (($window.width() < 768) && (navBarToggler.getAttribute("aria-expanded") === 'true')) {
            return;
        }
        if (lastScrollTop > 2 && (prevScrollpos <= lastScrollTop) || hashTargetOnTop()){
            hideNavBar()
        } else {
            showNavBar()
        }
        prevScrollpos = lastScrollTop;
    };

    /*** high performance scroll event listener***/
    var raf = window.requestAnimationFrame ||
        window.webkitRequestAnimationFrame ||
        window.mozRequestAnimationFrame ||
        window.msRequestAnimationFrame ||
        window.oRequestAnimationFrame;
    var lastScrollTop = $window.scrollTop();

    if (raf) {
        loop();
    }

    function loop() {
        var scrollTop = $window.scrollTop();
        if (lastScrollTop === scrollTop) {
            raf(loop);
            return;
        } else {
            lastScrollTop = scrollTop;
            hideOnScroll(lastScrollTop);
            raf(loop);
        }
    }
  })();
});

</script>
    
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    
</body>
</html>