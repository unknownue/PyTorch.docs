

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Model Complexity Influence" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://scikit-learn/stable/auto_examples/applications/plot_model_complexity_influence.html" />
<meta property="og:site_name" content="scikit-learn" />
<meta property="og:description" content="Demonstrate how model complexity influences both prediction accuracy and computational performance. We will be using two datasets:,- Diabetes dataset for regression. This dataset consists of 10 mea..." />
<meta property="og:image" content="https://scikit-learn.org/stable/_static/scikit-learn-logo-small.png" />
<meta property="og:image:alt" content="scikit-learn" />
<meta name="description" content="Demonstrate how model complexity influences both prediction accuracy and computational performance. We will be using two datasets:,- Diabetes dataset for regression. This dataset consists of 10 mea..." />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <title>Model Complexity Influence &mdash; scikit-learn 1.3.2 documentation</title>
  
  <link rel="canonical" href="http://scikit-learn.org/stable/auto_examples/applications/plot_model_complexity_influence.html" />

  
  <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  

  <link rel="stylesheet" href="../../_static/css/vendor/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/plot_directive.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
<script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
<script src="../../_static/js/vendor/jquery-3.6.3.slim.min.js"></script> 
</head>
<body>






<nav id="navbar" class="sk-docs-navbar navbar navbar-expand-md navbar-light bg-light py-0">
  <div class="container-fluid sk-docs-container px-0">
      <a class="navbar-brand py-0" href="../../index.html">
        <img
          class="sk-brand-img"
          src="../../_static/scikit-learn-logo-small.png"
          alt="logo"/>
      </a>
    <button
      id="sk-navbar-toggler"
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="sk-navbar-collapse collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../install.html">Install</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../user_guide.html">User Guide</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../modules/classes.html">API</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../index.html">Examples</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" target="_blank" rel="noopener noreferrer" href="https://blog.scikit-learn.org/">Community</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../getting_started.html" >Getting Started</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../tutorial/index.html" >Tutorial</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../whats_new/v1.3.html" >What's new</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../glossary.html" >Glossary</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://scikit-learn.org/dev/developers/index.html" target="_blank" rel="noopener noreferrer">Development</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../faq.html" >FAQ</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../support.html" >Support</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../related_projects.html" >Related packages</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../roadmap.html" >Roadmap</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../governance.html" >Governance</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../about.html" >About us</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://github.com/scikit-learn/scikit-learn" >GitHub</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://scikit-learn.org/dev/versions.html" >Other Versions and Download</a>
        </li>
        <li class="nav-item dropdown nav-more-item-dropdown">
          <a class="sk-nav-link nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">More</a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdown">
              <a class="sk-nav-dropdown-item dropdown-item" href="../../getting_started.html" >Getting Started</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../tutorial/index.html" >Tutorial</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../whats_new/v1.3.html" >What's new</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../glossary.html" >Glossary</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://scikit-learn.org/dev/developers/index.html" target="_blank" rel="noopener noreferrer">Development</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../faq.html" >FAQ</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../support.html" >Support</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../related_projects.html" >Related packages</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../roadmap.html" >Roadmap</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../governance.html" >Governance</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../about.html" >About us</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://github.com/scikit-learn/scikit-learn" >GitHub</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://scikit-learn.org/dev/versions.html" >Other Versions and Download</a>
          </div>
        </li>
      </ul>
      <div id="searchbox" role="search">
          <div class="searchformwrapper">
          <form class="search" action="../../search.html" method="get">
            <input class="sk-search-text-input" type="text" name="q" aria-labelledby="searchlabel" />
            <input class="sk-search-text-btn" type="submit" value="Go" />
          </form>
          </div>
      </div>
    </div>
  </div>
</nav>
<div class="d-flex" id="sk-doc-wrapper">
    <input type="checkbox" name="sk-toggle-checkbox" id="sk-toggle-checkbox">
    <label id="sk-sidemenu-toggle" class="sk-btn-toggle-toc btn sk-btn-primary" for="sk-toggle-checkbox">Toggle Menu</label>
    <div id="sk-sidebar-wrapper" class="border-right">
      <div class="sk-sidebar-toc-wrapper">
        <div class="btn-group w-100 mb-2" role="group" aria-label="rellinks">
            <a href="svm_gui.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="Libsvm GUI">Prev</a><a href="index.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="Examples based on real world datasets">Up</a>
            <a href="plot_out_of_core_classification.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="Out-of-core classification of text documents">Next</a>
        </div>
        <div class="alert alert-danger p-1 mb-2" role="alert">
          <p class="text-center mb-0">
          <strong>scikit-learn 1.3.2</strong><br/>
          <a href="http://scikit-learn.org/dev/versions.html">Other versions</a>
          </p>
        </div>
        <div class="alert alert-warning p-1 mb-2" role="alert">
          <p class="text-center mb-0">
            Please <a class="font-weight-bold" href="../../about.html#citing-scikit-learn"><string>cite us</string></a> if you use the software.
          </p>
        </div>
            <div class="sk-sidebar-toc">
              <ul>
<li><a class="reference internal" href="#">Model Complexity Influence</a><ul>
<li><a class="reference internal" href="#load-the-data">Load the data</a></li>
<li><a class="reference internal" href="#benchmark-influence">Benchmark influence</a></li>
<li><a class="reference internal" href="#choose-parameters">Choose parameters</a></li>
<li><a class="reference internal" href="#run-the-code-and-plot-the-results">Run the code and plot the results</a></li>
<li><a class="reference internal" href="#conclusion">Conclusion</a></li>
</ul>
</li>
</ul>

            </div>
      </div>
    </div>
    <div id="sk-page-content-wrapper">
      <div class="sk-page-content container-fluid body px-md-3" role="main">
        
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-examples-applications-plot-model-complexity-influence-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code or to run this example in your browser via Binder</p>
</div>
<section class="sphx-glr-example-title" id="model-complexity-influence">
<span id="sphx-glr-auto-examples-applications-plot-model-complexity-influence-py"></span><h1>Model Complexity Influence<a class="headerlink" href="#model-complexity-influence" title="Link to this heading">¶</a></h1>
<p>Demonstrate how model complexity influences both prediction accuracy and
computational performance.</p>
<dl class="simple">
<dt>We will be using two datasets:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="../../datasets/toy_dataset.html#diabetes-dataset"><span class="std std-ref">Diabetes dataset</span></a> for regression.
This dataset consists of 10 measurements taken from diabetes patients.
The task is to predict disease progression;</p></li>
<li><p><a class="reference internal" href="../../datasets/real_world.html#newsgroups-dataset"><span class="std std-ref">The 20 newsgroups text dataset</span></a> for classification. This dataset consists of
newsgroup posts. The task is to predict on which topic (out of 20 topics)
the post is written about.</p></li>
</ul>
</dd>
<dt>We will model the complexity influence on three different estimators:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="../../modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier" title="sklearn.linear_model.SGDClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">SGDClassifier</span></code></a> (for classification data)
which implements stochastic gradient descent learning;</p></li>
<li><p><a class="reference internal" href="../../modules/generated/sklearn.svm.NuSVR.html#sklearn.svm.NuSVR" title="sklearn.svm.NuSVR"><code class="xref py py-class docutils literal notranslate"><span class="pre">NuSVR</span></code></a> (for regression data) which implements
Nu support vector regression;</p></li>
<li><p><a class="reference internal" href="../../modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor" title="sklearn.ensemble.GradientBoostingRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingRegressor</span></code></a> builds an additive
model in a forward stage-wise fashion. Notice that
<a class="reference internal" href="../../modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#sklearn.ensemble.HistGradientBoostingRegressor" title="sklearn.ensemble.HistGradientBoostingRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">HistGradientBoostingRegressor</span></code></a> is much faster
than <a class="reference internal" href="../../modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor" title="sklearn.ensemble.GradientBoostingRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingRegressor</span></code></a> starting with
intermediate datasets (<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">&gt;=</span> <span class="pre">10_000</span></code>), which is not the case for
this example.</p></li>
</ul>
</dd>
</dl>
<p>We make the model complexity vary through the choice of relevant model
parameters in each of our selected models. Next, we will measure the influence
on both computational performance (latency) and predictive power (MSE or
Hamming Loss).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Authors: Eustache Diemert &lt;eustache@diemert.fr&gt;</span>
<span class="c1">#          Maria Telenczuk &lt;https://github.com/maikia&gt;</span>
<span class="c1">#          Guillaume Lemaitre &lt;g.lemaitre58@gmail.com&gt;</span>
<span class="c1"># License: BSD 3 clause</span>

<span class="kn">import</span> <span class="nn">time</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="../../modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor" title="sklearn.ensemble.GradientBoostingRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">GradientBoostingRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <a href="../../modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier" title="sklearn.linear_model.SGDClassifier" class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">SGDClassifier</span></a>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <a href="../../modules/generated/sklearn.metrics.hamming_loss.html#sklearn.metrics.hamming_loss" title="sklearn.metrics.hamming_loss" class="sphx-glr-backref-module-sklearn-metrics sphx-glr-backref-type-py-function"><span class="n">hamming_loss</span></a><span class="p">,</span> <a href="../../modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error" title="sklearn.metrics.mean_squared_error" class="sphx-glr-backref-module-sklearn-metrics sphx-glr-backref-type-py-function"><span class="n">mean_squared_error</span></a>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <a href="../../modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split" title="sklearn.model_selection.train_test_split" class="sphx-glr-backref-module-sklearn-model_selection sphx-glr-backref-type-py-function"><span class="n">train_test_split</span></a>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <a href="../../modules/generated/sklearn.svm.NuSVR.html#sklearn.svm.NuSVR" title="sklearn.svm.NuSVR" class="sphx-glr-backref-module-sklearn-svm sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">NuSVR</span></a>

<span class="c1"># Initialize random generator</span>
<a href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.seed.html#numpy.random.seed" title="numpy.random.seed" class="sphx-glr-backref-module-numpy-random sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span></a><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<section id="load-the-data">
<h2>Load the data<a class="headerlink" href="#load-the-data" title="Link to this heading">¶</a></h2>
<p>First we load both datasets.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We are using
<a class="reference internal" href="../../modules/generated/sklearn.datasets.fetch_20newsgroups_vectorized.html#sklearn.datasets.fetch_20newsgroups_vectorized" title="sklearn.datasets.fetch_20newsgroups_vectorized"><code class="xref py py-func docutils literal notranslate"><span class="pre">fetch_20newsgroups_vectorized</span></code></a> to download 20
newsgroups dataset. It returns ready-to-use features.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">X</span></code> of the 20 newsgroups dataset is a sparse matrix while <code class="docutils literal notranslate"><span class="pre">X</span></code>
of diabetes dataset is a numpy array.</p>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate_data</span><span class="p">(</span><span class="n">case</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate regression/classification data.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">case</span> <span class="o">==</span> <span class="s2">&quot;regression&quot;</span><span class="p">:</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <a href="../../modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes" title="sklearn.datasets.load_diabetes" class="sphx-glr-backref-module-sklearn-datasets sphx-glr-backref-type-py-function"><span class="n">datasets</span><span class="o">.</span><span class="n">load_diabetes</span></a><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">train_size</span> <span class="o">=</span> <span class="mf">0.8</span>
    <span class="k">elif</span> <span class="n">case</span> <span class="o">==</span> <span class="s2">&quot;classification&quot;</span><span class="p">:</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <a href="../../modules/generated/sklearn.datasets.fetch_20newsgroups_vectorized.html#sklearn.datasets.fetch_20newsgroups_vectorized" title="sklearn.datasets.fetch_20newsgroups_vectorized" class="sphx-glr-backref-module-sklearn-datasets sphx-glr-backref-type-py-function"><span class="n">datasets</span><span class="o">.</span><span class="n">fetch_20newsgroups_vectorized</span></a><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">,</span> <span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">train_size</span> <span class="o">=</span> <span class="mf">0.4</span>  <span class="c1"># to make the example run faster</span>

    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <a href="../../modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split" title="sklearn.model_selection.train_test_split" class="sphx-glr-backref-module-sklearn-model_selection sphx-glr-backref-type-py-function"><span class="n">train_test_split</span></a><span class="p">(</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="n">train_size</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span>
    <span class="p">)</span>

    <span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;X_train&quot;</span><span class="p">:</span> <span class="n">X_train</span><span class="p">,</span> <span class="s2">&quot;X_test&quot;</span><span class="p">:</span> <span class="n">X_test</span><span class="p">,</span> <span class="s2">&quot;y_train&quot;</span><span class="p">:</span> <span class="n">y_train</span><span class="p">,</span> <span class="s2">&quot;y_test&quot;</span><span class="p">:</span> <span class="n">y_test</span><span class="p">}</span>
    <span class="k">return</span> <span class="n">data</span>


<span class="n">regression_data</span> <span class="o">=</span> <span class="n">generate_data</span><span class="p">(</span><span class="s2">&quot;regression&quot;</span><span class="p">)</span>
<span class="n">classification_data</span> <span class="o">=</span> <span class="n">generate_data</span><span class="p">(</span><span class="s2">&quot;classification&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="benchmark-influence">
<h2>Benchmark influence<a class="headerlink" href="#benchmark-influence" title="Link to this heading">¶</a></h2>
<p>Next, we can calculate the influence of the parameters on the given
estimator. In each round, we will set the estimator with the new value of
<code class="docutils literal notranslate"><span class="pre">changing_param</span></code> and we will be collecting the prediction times, prediction
performance and complexities to see how those changes affect the estimator.
We will calculate the complexity using <code class="docutils literal notranslate"><span class="pre">complexity_computer</span></code> passed as a
parameter.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">benchmark_influence</span><span class="p">(</span><span class="n">conf</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Benchmark influence of `changing_param` on both MSE and latency.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">prediction_times</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">prediction_powers</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">complexities</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">param_value</span> <span class="ow">in</span> <span class="n">conf</span><span class="p">[</span><span class="s2">&quot;changing_param_values&quot;</span><span class="p">]:</span>
        <span class="n">conf</span><span class="p">[</span><span class="s2">&quot;tuned_params&quot;</span><span class="p">][</span><span class="n">conf</span><span class="p">[</span><span class="s2">&quot;changing_param&quot;</span><span class="p">]]</span> <span class="o">=</span> <span class="n">param_value</span>
        <span class="n">estimator</span> <span class="o">=</span> <span class="n">conf</span><span class="p">[</span><span class="s2">&quot;estimator&quot;</span><span class="p">](</span><span class="o">**</span><span class="n">conf</span><span class="p">[</span><span class="s2">&quot;tuned_params&quot;</span><span class="p">])</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Benchmarking </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">estimator</span><span class="p">)</span>
        <span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">conf</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">][</span><span class="s2">&quot;X_train&quot;</span><span class="p">],</span> <span class="n">conf</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">][</span><span class="s2">&quot;y_train&quot;</span><span class="p">])</span>
        <span class="n">conf</span><span class="p">[</span><span class="s2">&quot;postfit_hook&quot;</span><span class="p">](</span><span class="n">estimator</span><span class="p">)</span>
        <span class="n">complexity</span> <span class="o">=</span> <span class="n">conf</span><span class="p">[</span><span class="s2">&quot;complexity_computer&quot;</span><span class="p">](</span><span class="n">estimator</span><span class="p">)</span>
        <span class="n">complexities</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">complexity</span><span class="p">)</span>
        <span class="n">start_time</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/time.html#time.time" title="time.time" class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"><span class="n">time</span><span class="o">.</span><span class="n">time</span></a><span class="p">()</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">conf</span><span class="p">[</span><span class="s2">&quot;n_samples&quot;</span><span class="p">]):</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">conf</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">][</span><span class="s2">&quot;X_test&quot;</span><span class="p">])</span>
        <span class="n">elapsed_time</span> <span class="o">=</span> <span class="p">(</span><a href="https://docs.python.org/3/library/time.html#time.time" title="time.time" class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"><span class="n">time</span><span class="o">.</span><span class="n">time</span></a><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">conf</span><span class="p">[</span><span class="s2">&quot;n_samples&quot;</span><span class="p">])</span>
        <span class="n">prediction_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">elapsed_time</span><span class="p">)</span>
        <span class="n">pred_score</span> <span class="o">=</span> <span class="n">conf</span><span class="p">[</span><span class="s2">&quot;prediction_performance_computer&quot;</span><span class="p">](</span>
            <span class="n">conf</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">][</span><span class="s2">&quot;y_test&quot;</span><span class="p">],</span> <span class="n">y_pred</span>
        <span class="p">)</span>
        <span class="n">prediction_powers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred_score</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="s2">&quot;Complexity: </span><span class="si">%d</span><span class="s2"> | </span><span class="si">%s</span><span class="s2">: </span><span class="si">%.4f</span><span class="s2"> | Pred. Time: </span><span class="si">%f</span><span class="s2">s</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="o">%</span> <span class="p">(</span>
                <span class="n">complexity</span><span class="p">,</span>
                <span class="n">conf</span><span class="p">[</span><span class="s2">&quot;prediction_performance_label&quot;</span><span class="p">],</span>
                <span class="n">pred_score</span><span class="p">,</span>
                <span class="n">elapsed_time</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">prediction_powers</span><span class="p">,</span> <span class="n">prediction_times</span><span class="p">,</span> <span class="n">complexities</span>
</pre></div>
</div>
</section>
<section id="choose-parameters">
<h2>Choose parameters<a class="headerlink" href="#choose-parameters" title="Link to this heading">¶</a></h2>
<p>We choose the parameters for each of our estimators by making
a dictionary with all the necessary values.
<code class="docutils literal notranslate"><span class="pre">changing_param</span></code> is the name of the parameter which will vary in each
estimator.
Complexity will be defined by the <code class="docutils literal notranslate"><span class="pre">complexity_label</span></code> and calculated using
<code class="docutils literal notranslate"><span class="pre">complexity_computer</span></code>.
Also note that depending on the estimator type we are passing
different data.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_count_nonzero_coefficients</span><span class="p">(</span><span class="n">estimator</span><span class="p">):</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
    <span class="k">return</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.count_nonzero.html#numpy.count_nonzero" title="numpy.count_nonzero" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span></a><span class="p">(</span><span class="n">a</span><span class="p">)</span>


<span class="n">configurations</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>
        <span class="s2">&quot;estimator&quot;</span><span class="p">:</span> <a href="../../modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier" title="sklearn.linear_model.SGDClassifier" class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">SGDClassifier</span></a><span class="p">,</span>
        <span class="s2">&quot;tuned_params&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;penalty&quot;</span><span class="p">:</span> <span class="s2">&quot;elasticnet&quot;</span><span class="p">,</span>
            <span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span>
            <span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="s2">&quot;modified_huber&quot;</span><span class="p">,</span>
            <span class="s2">&quot;fit_intercept&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
            <span class="s2">&quot;tol&quot;</span><span class="p">:</span> <span class="mf">1e-1</span><span class="p">,</span>
            <span class="s2">&quot;n_iter_no_change&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="s2">&quot;changing_param&quot;</span><span class="p">:</span> <span class="s2">&quot;l1_ratio&quot;</span><span class="p">,</span>
        <span class="s2">&quot;changing_param_values&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">],</span>
        <span class="s2">&quot;complexity_label&quot;</span><span class="p">:</span> <span class="s2">&quot;non_zero coefficients&quot;</span><span class="p">,</span>
        <span class="s2">&quot;complexity_computer&quot;</span><span class="p">:</span> <span class="n">_count_nonzero_coefficients</span><span class="p">,</span>
        <span class="s2">&quot;prediction_performance_computer&quot;</span><span class="p">:</span> <a href="../../modules/generated/sklearn.metrics.hamming_loss.html#sklearn.metrics.hamming_loss" title="sklearn.metrics.hamming_loss" class="sphx-glr-backref-module-sklearn-metrics sphx-glr-backref-type-py-function"><span class="n">hamming_loss</span></a><span class="p">,</span>
        <span class="s2">&quot;prediction_performance_label&quot;</span><span class="p">:</span> <span class="s2">&quot;Hamming Loss (Misclassification Ratio)&quot;</span><span class="p">,</span>
        <span class="s2">&quot;postfit_hook&quot;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">sparsify</span><span class="p">(),</span>
        <span class="s2">&quot;data&quot;</span><span class="p">:</span> <span class="n">classification_data</span><span class="p">,</span>
        <span class="s2">&quot;n_samples&quot;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="s2">&quot;estimator&quot;</span><span class="p">:</span> <a href="../../modules/generated/sklearn.svm.NuSVR.html#sklearn.svm.NuSVR" title="sklearn.svm.NuSVR" class="sphx-glr-backref-module-sklearn-svm sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">NuSVR</span></a><span class="p">,</span>
        <span class="s2">&quot;tuned_params&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;C&quot;</span><span class="p">:</span> <span class="mf">1e3</span><span class="p">,</span> <span class="s2">&quot;gamma&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="o">**-</span><span class="mi">15</span><span class="p">},</span>
        <span class="s2">&quot;changing_param&quot;</span><span class="p">:</span> <span class="s2">&quot;nu&quot;</span><span class="p">,</span>
        <span class="s2">&quot;changing_param_values&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span>
        <span class="s2">&quot;complexity_label&quot;</span><span class="p">:</span> <span class="s2">&quot;n_support_vectors&quot;</span><span class="p">,</span>
        <span class="s2">&quot;complexity_computer&quot;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">support_vectors_</span><span class="p">),</span>
        <span class="s2">&quot;data&quot;</span><span class="p">:</span> <span class="n">regression_data</span><span class="p">,</span>
        <span class="s2">&quot;postfit_hook&quot;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span>
        <span class="s2">&quot;prediction_performance_computer&quot;</span><span class="p">:</span> <a href="../../modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error" title="sklearn.metrics.mean_squared_error" class="sphx-glr-backref-module-sklearn-metrics sphx-glr-backref-type-py-function"><span class="n">mean_squared_error</span></a><span class="p">,</span>
        <span class="s2">&quot;prediction_performance_label&quot;</span><span class="p">:</span> <span class="s2">&quot;MSE&quot;</span><span class="p">,</span>
        <span class="s2">&quot;n_samples&quot;</span><span class="p">:</span> <span class="mi">15</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="s2">&quot;estimator&quot;</span><span class="p">:</span> <a href="../../modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor" title="sklearn.ensemble.GradientBoostingRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">GradientBoostingRegressor</span></a><span class="p">,</span>
        <span class="s2">&quot;tuned_params&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="s2">&quot;squared_error&quot;</span><span class="p">,</span>
            <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="mf">0.05</span><span class="p">,</span>
            <span class="s2">&quot;max_depth&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="s2">&quot;changing_param&quot;</span><span class="p">:</span> <span class="s2">&quot;n_estimators&quot;</span><span class="p">,</span>
        <span class="s2">&quot;changing_param_values&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">75</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
        <span class="s2">&quot;complexity_label&quot;</span><span class="p">:</span> <span class="s2">&quot;n_trees&quot;</span><span class="p">,</span>
        <span class="s2">&quot;complexity_computer&quot;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span>
        <span class="s2">&quot;data&quot;</span><span class="p">:</span> <span class="n">regression_data</span><span class="p">,</span>
        <span class="s2">&quot;postfit_hook&quot;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span>
        <span class="s2">&quot;prediction_performance_computer&quot;</span><span class="p">:</span> <a href="../../modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error" title="sklearn.metrics.mean_squared_error" class="sphx-glr-backref-module-sklearn-metrics sphx-glr-backref-type-py-function"><span class="n">mean_squared_error</span></a><span class="p">,</span>
        <span class="s2">&quot;prediction_performance_label&quot;</span><span class="p">:</span> <span class="s2">&quot;MSE&quot;</span><span class="p">,</span>
        <span class="s2">&quot;n_samples&quot;</span><span class="p">:</span> <span class="mi">15</span><span class="p">,</span>
    <span class="p">},</span>
<span class="p">]</span>
</pre></div>
</div>
</section>
<section id="run-the-code-and-plot-the-results">
<h2>Run the code and plot the results<a class="headerlink" href="#run-the-code-and-plot-the-results" title="Link to this heading">¶</a></h2>
<p>We defined all the functions required to run our benchmark. Now, we will loop
over the different configurations that we defined previously. Subsequently,
we can analyze the plots obtained from the benchmark:
Relaxing the <code class="docutils literal notranslate"><span class="pre">L1</span></code> penalty in the SGD classifier reduces the prediction error
but leads to an increase in the training time.
We can draw a similar analysis regarding the training time which increases
with the number of support vectors with a Nu-SVR. However, we observed that
there is an optimal number of support vectors which reduces the prediction
error. Indeed, too few support vectors lead to an under-fitted model while
too many support vectors lead to an over-fitted model.
The exact same conclusion can be drawn for the gradient-boosting model. The
only the difference with the Nu-SVR is that having too many trees in the
ensemble is not as detrimental.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_influence</span><span class="p">(</span><span class="n">conf</span><span class="p">,</span> <span class="n">mse_values</span><span class="p">,</span> <span class="n">prediction_times</span><span class="p">,</span> <span class="n">complexities</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Plot influence of model complexity on both accuracy and latency.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">fig</span> <span class="o">=</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.figure.html#matplotlib.pyplot.figure" title="matplotlib.pyplot.figure" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span></a><span class="p">()</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">right</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>

    <span class="c1"># first axes (prediction error)</span>
    <span class="n">ax1</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
    <span class="n">line1</span> <span class="o">=</span> <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">complexities</span><span class="p">,</span> <span class="n">mse_values</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;tab:blue&quot;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s2">&quot;-&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Model Complexity (</span><span class="si">%s</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="n">conf</span><span class="p">[</span><span class="s2">&quot;complexity_label&quot;</span><span class="p">])</span>
    <span class="n">y1_label</span> <span class="o">=</span> <span class="n">conf</span><span class="p">[</span><span class="s2">&quot;prediction_performance_label&quot;</span><span class="p">]</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">y1_label</span><span class="p">)</span>

    <span class="n">ax1</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s2">&quot;left&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_color</span><span class="p">(</span><span class="n">line1</span><span class="o">.</span><span class="n">get_color</span><span class="p">())</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">label</span><span class="o">.</span><span class="n">set_color</span><span class="p">(</span><span class="n">line1</span><span class="o">.</span><span class="n">get_color</span><span class="p">())</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="n">line1</span><span class="o">.</span><span class="n">get_color</span><span class="p">())</span>

    <span class="c1"># second axes (latency)</span>
    <span class="n">ax2</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="n">ax1</span><span class="p">,</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">line2</span> <span class="o">=</span> <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">complexities</span><span class="p">,</span> <span class="n">prediction_times</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;tab:orange&quot;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s2">&quot;-&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">tick_right</span><span class="p">()</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_label_position</span><span class="p">(</span><span class="s2">&quot;right&quot;</span><span class="p">)</span>
    <span class="n">y2_label</span> <span class="o">=</span> <span class="s2">&quot;Time (s)&quot;</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">y2_label</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s2">&quot;right&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_color</span><span class="p">(</span><span class="n">line2</span><span class="o">.</span><span class="n">get_color</span><span class="p">())</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">label</span><span class="o">.</span><span class="n">set_color</span><span class="p">(</span><span class="n">line2</span><span class="o">.</span><span class="n">get_color</span><span class="p">())</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="n">line2</span><span class="o">.</span><span class="n">get_color</span><span class="p">())</span>

    <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.legend.html#matplotlib.pyplot.legend" title="matplotlib.pyplot.legend" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">legend</span></a><span class="p">(</span>
        <span class="p">(</span><span class="n">line1</span><span class="p">,</span> <span class="n">line2</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;prediction error&quot;</span><span class="p">,</span> <span class="s2">&quot;prediction latency&quot;</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;upper center&quot;</span>
    <span class="p">)</span>

    <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.title.html#matplotlib.pyplot.title" title="matplotlib.pyplot.title" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">title</span></a><span class="p">(</span>
        <span class="s2">&quot;Influence of varying &#39;</span><span class="si">%s</span><span class="s2">&#39; on </span><span class="si">%s</span><span class="s2">&quot;</span>
        <span class="o">%</span> <span class="p">(</span><span class="n">conf</span><span class="p">[</span><span class="s2">&quot;changing_param&quot;</span><span class="p">],</span> <span class="n">conf</span><span class="p">[</span><span class="s2">&quot;estimator&quot;</span><span class="p">]</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
    <span class="p">)</span>


<span class="k">for</span> <span class="n">conf</span> <span class="ow">in</span> <span class="n">configurations</span><span class="p">:</span>
    <span class="n">prediction_performances</span><span class="p">,</span> <span class="n">prediction_times</span><span class="p">,</span> <span class="n">complexities</span> <span class="o">=</span> <span class="n">benchmark_influence</span><span class="p">(</span><span class="n">conf</span><span class="p">)</span>
    <span class="n">plot_influence</span><span class="p">(</span><span class="n">conf</span><span class="p">,</span> <span class="n">prediction_performances</span><span class="p">,</span> <span class="n">prediction_times</span><span class="p">,</span> <span class="n">complexities</span><span class="p">)</span>
<a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.show.html#matplotlib.pyplot.show" title="matplotlib.pyplot.show" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">show</span></a><span class="p">()</span>
</pre></div>
</div>
<ul class="sphx-glr-horizontal">
<li><img src="../../_images/sphx_glr_plot_model_complexity_influence_001.png" srcset="../../_images/sphx_glr_plot_model_complexity_influence_001.png" alt="Influence of varying 'l1_ratio' on SGDClassifier" class = "sphx-glr-multi-img"/></li>
<li><img src="../../_images/sphx_glr_plot_model_complexity_influence_002.png" srcset="../../_images/sphx_glr_plot_model_complexity_influence_002.png" alt="Influence of varying 'nu' on NuSVR" class = "sphx-glr-multi-img"/></li>
<li><img src="../../_images/sphx_glr_plot_model_complexity_influence_003.png" srcset="../../_images/sphx_glr_plot_model_complexity_influence_003.png" alt="Influence of varying 'n_estimators' on GradientBoostingRegressor" class = "sphx-glr-multi-img"/></li>
</ul>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Benchmarking SGDClassifier(alpha=0.001, l1_ratio=0.25, loss=&#39;modified_huber&#39;,
              n_iter_no_change=2, penalty=&#39;elasticnet&#39;, tol=0.1)
Complexity: 4948 | Hamming Loss (Misclassification Ratio): 0.2675 | Pred. Time: 0.054108s

Benchmarking SGDClassifier(alpha=0.001, l1_ratio=0.5, loss=&#39;modified_huber&#39;,
              n_iter_no_change=2, penalty=&#39;elasticnet&#39;, tol=0.1)
Complexity: 1847 | Hamming Loss (Misclassification Ratio): 0.3264 | Pred. Time: 0.038893s

Benchmarking SGDClassifier(alpha=0.001, l1_ratio=0.75, loss=&#39;modified_huber&#39;,
              n_iter_no_change=2, penalty=&#39;elasticnet&#39;, tol=0.1)
Complexity: 997 | Hamming Loss (Misclassification Ratio): 0.3383 | Pred. Time: 0.030957s

Benchmarking SGDClassifier(alpha=0.001, l1_ratio=0.9, loss=&#39;modified_huber&#39;,
              n_iter_no_change=2, penalty=&#39;elasticnet&#39;, tol=0.1)
Complexity: 802 | Hamming Loss (Misclassification Ratio): 0.3582 | Pred. Time: 0.028343s

Benchmarking NuSVR(C=1000.0, gamma=3.0517578125e-05, nu=0.05)
Complexity: 18 | MSE: 5558.7313 | Pred. Time: 0.000127s

Benchmarking NuSVR(C=1000.0, gamma=3.0517578125e-05, nu=0.1)
Complexity: 36 | MSE: 5289.8022 | Pred. Time: 0.000182s

Benchmarking NuSVR(C=1000.0, gamma=3.0517578125e-05, nu=0.2)
Complexity: 72 | MSE: 5193.8353 | Pred. Time: 0.000303s

Benchmarking NuSVR(C=1000.0, gamma=3.0517578125e-05, nu=0.35)
Complexity: 124 | MSE: 5131.3279 | Pred. Time: 0.000471s

Benchmarking NuSVR(C=1000.0, gamma=3.0517578125e-05)
Complexity: 178 | MSE: 5149.0779 | Pred. Time: 0.000638s

Benchmarking GradientBoostingRegressor(learning_rate=0.05, max_depth=2, n_estimators=10)
Complexity: 10 | MSE: 4066.4812 | Pred. Time: 0.000115s

Benchmarking GradientBoostingRegressor(learning_rate=0.05, max_depth=2, n_estimators=25)
Complexity: 25 | MSE: 3551.1723 | Pred. Time: 0.000123s

Benchmarking GradientBoostingRegressor(learning_rate=0.05, max_depth=2, n_estimators=50)
Complexity: 50 | MSE: 3445.2171 | Pred. Time: 0.000142s

Benchmarking GradientBoostingRegressor(learning_rate=0.05, max_depth=2, n_estimators=75)
Complexity: 75 | MSE: 3433.0358 | Pred. Time: 0.000161s

Benchmarking GradientBoostingRegressor(learning_rate=0.05, max_depth=2)
Complexity: 100 | MSE: 3456.0602 | Pred. Time: 0.000180s
</pre></div>
</div>
</section>
<section id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading">¶</a></h2>
<p>As a conclusion, we can deduce the following insights:</p>
<ul class="simple">
<li><p>a model which is more complex (or expressive) will require a larger
training time;</p></li>
<li><p>a more complex model does not guarantee to reduce the prediction error.</p></li>
</ul>
<p>These aspects are related to model generalization and avoiding model
under-fitting or over-fitting.</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 12.435 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-applications-plot-model-complexity-influence-py">
<div class="binder-badge docutils container">
<a class="reference external image-reference" href="https://mybinder.org/v2/gh/scikit-learn/scikit-learn/1.3.X?urlpath=lab/tree/notebooks/auto_examples/applications/plot_model_complexity_influence.ipynb"><img alt="Launch binder" src="../../_images/binder_badge_logo.svg" width="150px" /></a>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/ddd79923ba48c7f71fb17697baa1a22b/plot_model_complexity_influence.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_model_complexity_influence.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/3ed102fa8211c8d36f2331f0c5e1dcef/plot_model_complexity_influence.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_model_complexity_influence.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


      </div>
    <div class="container">
      <footer class="sk-content-footer">
            &copy; 2007 - 2023, scikit-learn developers (BSD License).
          <a href="../../_sources/auto_examples/applications/plot_model_complexity_influence.rst.txt" rel="nofollow">Show this page source</a>
      </footer>
    </div>
  </div>
</div>
<script src="../../_static/js/vendor/bootstrap.min.js"></script>

<script>
    window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
    ga('create', 'UA-22606712-2', 'auto');
    ga('set', 'anonymizeIp', true);
    ga('send', 'pageview');
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>



<script defer data-domain="scikit-learn.org" src="https://views.scientific-python.org/js/script.js">
</script>


<script src="../../_static/clipboard.min.js"></script>
<script src="../../_static/copybutton.js"></script>

<script>
$(document).ready(function() {
    /* Add a [>>>] button on the top-right corner of code samples to hide
     * the >>> and ... prompts and the output and thus make the code
     * copyable. */
    var div = $('.highlight-python .highlight,' +
                '.highlight-python3 .highlight,' +
                '.highlight-pycon .highlight,' +
		'.highlight-default .highlight')
    var pre = div.find('pre');

    // get the styles from the current theme
    pre.parent().parent().css('position', 'relative');

    // create and add the button to all the code blocks that contain >>>
    div.each(function(index) {
        var jthis = $(this);
        // tracebacks (.gt) contain bare text elements that need to be
        // wrapped in a span to work with .nextUntil() (see later)
        jthis.find('pre:has(.gt)').contents().filter(function() {
            return ((this.nodeType == 3) && (this.data.trim().length > 0));
        }).wrap('<span>');
    });

	/*** Add permalink buttons next to glossary terms ***/
	$('dl.glossary > dt[id]').append(function() {
		return ('<a class="headerlink" href="#' +
			    this.getAttribute('id') +
			    '" title="Permalink to this term">¶</a>');
	});
});

</script>
    
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    
</body>
</html>