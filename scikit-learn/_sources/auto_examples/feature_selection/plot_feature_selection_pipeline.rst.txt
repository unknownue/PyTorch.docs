
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/feature_selection/plot_feature_selection_pipeline.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_feature_selection_plot_feature_selection_pipeline.py>`
        to download the full example code or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_feature_selection_plot_feature_selection_pipeline.py:


==================
Pipeline ANOVA SVM
==================

This example shows how a feature selection can be easily integrated within
a machine learning pipeline.

We also show that you can easily inspect part of the pipeline.

.. GENERATED FROM PYTHON SOURCE LINES 14-16

We will start by generating a binary classification dataset. Subsequently, we
will divide the dataset into two subsets.

.. GENERATED FROM PYTHON SOURCE LINES 16-30

.. code-block:: default


    from sklearn.datasets import make_classification
    from sklearn.model_selection import train_test_split

    X, y = make_classification(
        n_features=20,
        n_informative=3,
        n_redundant=0,
        n_classes=2,
        n_clusters_per_class=2,
        random_state=42,
    )
    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)








.. GENERATED FROM PYTHON SOURCE LINES 31-43

A common mistake done with feature selection is to search a subset of
discriminative features on the full dataset, instead of only using the
training set. The usage of scikit-learn :func:`~sklearn.pipeline.Pipeline`
prevents to make such mistake.

Here, we will demonstrate how to build a pipeline where the first step will
be the feature selection.

When calling `fit` on the training data, a subset of feature will be selected
and the index of these selected features will be stored. The feature selector
will subsequently reduce the number of features, and pass this subset to the
classifier which will be trained.

.. GENERATED FROM PYTHON SOURCE LINES 43-53

.. code-block:: default


    from sklearn.feature_selection import SelectKBest, f_classif
    from sklearn.pipeline import make_pipeline
    from sklearn.svm import LinearSVC

    anova_filter = SelectKBest(f_classif, k=3)
    clf = LinearSVC(dual="auto")
    anova_svm = make_pipeline(anova_filter, clf)
    anova_svm.fit(X_train, y_train)






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <style>#sk-container-id-27 {color: black;}#sk-container-id-27 pre{padding: 0;}#sk-container-id-27 div.sk-toggleable {background-color: white;}#sk-container-id-27 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-27 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-27 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-27 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-27 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-27 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-27 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-27 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-27 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-27 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-27 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-27 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-27 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-27 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-27 div.sk-item {position: relative;z-index: 1;}#sk-container-id-27 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-27 div.sk-item::before, #sk-container-id-27 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-27 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-27 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-27 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-27 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-27 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-27 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-27 div.sk-label-container {text-align: center;}#sk-container-id-27 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-27 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-27" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>Pipeline(steps=[(&#x27;selectkbest&#x27;, SelectKBest(k=3)),
                    (&#x27;linearsvc&#x27;, LinearSVC(dual=&#x27;auto&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-110" type="checkbox" ><label for="sk-estimator-id-110" class="sk-toggleable__label sk-toggleable__label-arrow">Pipeline</label><div class="sk-toggleable__content"><pre>Pipeline(steps=[(&#x27;selectkbest&#x27;, SelectKBest(k=3)),
                    (&#x27;linearsvc&#x27;, LinearSVC(dual=&#x27;auto&#x27;))])</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-111" type="checkbox" ><label for="sk-estimator-id-111" class="sk-toggleable__label sk-toggleable__label-arrow">SelectKBest</label><div class="sk-toggleable__content"><pre>SelectKBest(k=3)</pre></div></div></div><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-112" type="checkbox" ><label for="sk-estimator-id-112" class="sk-toggleable__label sk-toggleable__label-arrow">LinearSVC</label><div class="sk-toggleable__content"><pre>LinearSVC(dual=&#x27;auto&#x27;)</pre></div></div></div></div></div></div></div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 54-60

Once the training is complete, we can predict on new unseen samples. In this
case, the feature selector will only select the most discriminative features
based on the information stored during training. Then, the data will be
passed to the classifier which will make the prediction.

Here, we show the final metrics via a classification report.

.. GENERATED FROM PYTHON SOURCE LINES 60-66

.. code-block:: default


    from sklearn.metrics import classification_report

    y_pred = anova_svm.predict(X_test)
    print(classification_report(y_test, y_pred))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

                  precision    recall  f1-score   support

               0       0.92      0.80      0.86        15
               1       0.75      0.90      0.82        10

        accuracy                           0.84        25
       macro avg       0.84      0.85      0.84        25
    weighted avg       0.85      0.84      0.84        25





.. GENERATED FROM PYTHON SOURCE LINES 67-70

Be aware that you can inspect a step in the pipeline. For instance, we might
be interested about the parameters of the classifier. Since we selected
three features, we expect to have three coefficients.

.. GENERATED FROM PYTHON SOURCE LINES 70-73

.. code-block:: default


    anova_svm[-1].coef_





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    array([[0.75788833, 0.27161955, 0.26113448]])



.. GENERATED FROM PYTHON SOURCE LINES 74-78

However, we do not know which features were selected from the original
dataset. We could proceed by several manners. Here, we will invert the
transformation of these coefficients to get information about the original
space.

.. GENERATED FROM PYTHON SOURCE LINES 78-81

.. code-block:: default


    anova_svm[:-1].inverse_transform(anova_svm[-1].coef_)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    array([[0.        , 0.        , 0.75788833, 0.        , 0.        ,
            0.        , 0.        , 0.        , 0.        , 0.27161955,
            0.        , 0.        , 0.        , 0.        , 0.        ,
            0.        , 0.        , 0.        , 0.        , 0.26113448]])



.. GENERATED FROM PYTHON SOURCE LINES 82-84

We can see that the features with non-zero coefficients are the selected
features by the first step.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 0.009 seconds)


.. _sphx_glr_download_auto_examples_feature_selection_plot_feature_selection_pipeline.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: binder-badge

      .. image:: images/binder_badge_logo.svg
        :target: https://mybinder.org/v2/gh/scikit-learn/scikit-learn/1.3.X?urlpath=lab/tree/notebooks/auto_examples/feature_selection/plot_feature_selection_pipeline.ipynb
        :alt: Launch binder
        :width: 150 px



    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_feature_selection_pipeline.py <plot_feature_selection_pipeline.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_feature_selection_pipeline.ipynb <plot_feature_selection_pipeline.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
