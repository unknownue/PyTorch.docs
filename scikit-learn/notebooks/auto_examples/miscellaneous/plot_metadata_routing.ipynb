{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Metadata Routing\n\n.. currentmodule:: sklearn\n\nThis document shows how you can use the `metadata routing mechanism\n<metadata_routing>` in scikit-learn to route metadata through meta-estimators\nto the estimators consuming them. To better understand the rest of the\ndocument, we need to introduce two concepts: routers and consumers. A router is\nan object, in most cases a meta-estimator, which forwards given data and\nmetadata to other objects and estimators. A consumer, on the other hand, is an\nobject which accepts and uses a certain given metadata. For instance, an\nestimator taking into account ``sample_weight`` in its :term:`fit` method is a\nconsumer of ``sample_weight``. It is possible for an object to be both a router\nand a consumer. For instance, a meta-estimator may take into account\n``sample_weight`` in certain calculations, but it may also route it to the\nunderlying estimator.\n\nFirst a few imports and some random data for the rest of the script.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import warnings\nfrom pprint import pprint\n\nimport numpy as np\n\nfrom sklearn import set_config\nfrom sklearn.base import (\n    BaseEstimator,\n    ClassifierMixin,\n    MetaEstimatorMixin,\n    RegressorMixin,\n    TransformerMixin,\n    clone,\n)\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.utils import metadata_routing\nfrom sklearn.utils.metadata_routing import (\n    MetadataRouter,\n    MethodMapping,\n    get_routing_for_object,\n    process_routing,\n)\nfrom sklearn.utils.validation import check_is_fitted\n\nn_samples, n_features = 100, 4\nrng = np.random.RandomState(42)\nX = rng.rand(n_samples, n_features)\ny = rng.randint(0, 2, size=n_samples)\nmy_groups = rng.randint(0, 10, size=n_samples)\nmy_weights = rng.rand(n_samples)\nmy_other_weights = rng.rand(n_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This feature is only available if explicitly enabled:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "set_config(enable_metadata_routing=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This utility function is a dummy to check if a metadata is passed.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def check_metadata(obj, **kwargs):\n    for key, value in kwargs.items():\n        if value is not None:\n            print(\n                f\"Received {key} of length = {len(value)} in {obj.__class__.__name__}.\"\n            )\n        else:\n            print(f\"{key} is None in {obj.__class__.__name__}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A utility function to nicely print the routing information of an object\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def print_routing(obj):\n    pprint(obj.get_metadata_routing()._serialize())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Estimators\nHere we demonstrate how an estimator can expose the required API to support\nmetadata routing as a consumer. Imagine a simple classifier accepting\n``sample_weight`` as a metadata on its ``fit`` and ``groups`` in its\n``predict`` method:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class ExampleClassifier(ClassifierMixin, BaseEstimator):\n    def fit(self, X, y, sample_weight=None):\n        check_metadata(self, sample_weight=sample_weight)\n        # all classifiers need to expose a classes_ attribute once they're fit.\n        self.classes_ = np.array([0, 1])\n        return self\n\n    def predict(self, X, groups=None):\n        check_metadata(self, groups=groups)\n        # return a constant value of 1, not a very smart classifier!\n        return np.ones(len(X))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The above estimator now has all it needs to consume metadata. This is\naccomplished by some magic done in :class:`~base.BaseEstimator`. There are\nnow three methods exposed by the above class: ``set_fit_request``,\n``set_predict_request``, and ``get_metadata_routing``. There is also a\n``set_score_request`` for ``sample_weight`` which is present since\n:class:`~base.ClassifierMixin` implements a ``score`` method accepting\n``sample_weight``. The same applies to regressors which inherit from\n:class:`~base.RegressorMixin`.\n\nBy default, no metadata is requested, which we can see as:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print_routing(ExampleClassifier())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The above output means that ``sample_weight`` and ``groups`` are not\nrequested, but if a router is given those metadata, it should raise an error,\nsince the user has not explicitly set whether they are required or not. The\nsame is true for ``sample_weight`` in the ``score`` method, which is\ninherited from :class:`~base.ClassifierMixin`. In order to explicitly set\nrequest values for those metadata, we can use these methods:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "est = (\n    ExampleClassifier()\n    .set_fit_request(sample_weight=False)\n    .set_predict_request(groups=True)\n    .set_score_request(sample_weight=False)\n)\nprint_routing(est)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. note ::\n    Please note that as long as the above estimator is not used in another\n    meta-estimator, the user does not need to set any requests for the\n    metadata and the set values are ignored, since a consumer does not\n    validate or route given metadata. A simple usage of the above estimator\n    would work as expected.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "est = ExampleClassifier()\nest.fit(X, y, sample_weight=my_weights)\nest.predict(X[:3, :], groups=my_groups)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's have a meta-estimator, which doesn't do much other than routing the\nmetadata.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class MetaClassifier(MetaEstimatorMixin, ClassifierMixin, BaseEstimator):\n    def __init__(self, estimator):\n        self.estimator = estimator\n\n    def get_metadata_routing(self):\n        # This method defines the routing for this meta-estimator.\n        # In order to do so, a `MetadataRouter` instance is created, and the\n        # right routing is added to it. More explanations follow.\n        router = MetadataRouter(owner=self.__class__.__name__).add(\n            estimator=self.estimator, method_mapping=\"one-to-one\"\n        )\n        return router\n\n    def fit(self, X, y, **fit_params):\n        # meta-estimators are responsible for validating the given metadata.\n        # `get_routing_for_object` is a safe way to construct a\n        # `MetadataRouter` or a `MetadataRequest` from the given object.\n        request_router = get_routing_for_object(self)\n        request_router.validate_metadata(params=fit_params, method=\"fit\")\n        # we can use provided utility methods to map the given metadata to what\n        # is required by the underlying estimator. Here `method` refers to the\n        # parent's method, i.e. `fit` in this example.\n        routed_params = request_router.route_params(params=fit_params, caller=\"fit\")\n\n        # the output has a key for each object's method which is used here,\n        # i.e. parent's `fit` method, containing the metadata which should be\n        # routed to them, based on the information provided in\n        # `get_metadata_routing`.\n        self.estimator_ = clone(self.estimator).fit(X, y, **routed_params.estimator.fit)\n        self.classes_ = self.estimator_.classes_\n        return self\n\n    def predict(self, X, **predict_params):\n        check_is_fitted(self)\n        # same as in `fit`, we validate the given metadata\n        request_router = get_routing_for_object(self)\n        request_router.validate_metadata(params=predict_params, method=\"predict\")\n        # and then prepare the input to the underlying `predict` method.\n        routed_params = request_router.route_params(\n            params=predict_params, caller=\"predict\"\n        )\n        return self.estimator_.predict(X, **routed_params.estimator.predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's break down different parts of the above code.\n\nFirst, the :meth:`~utils.metadata_routing.get_routing_for_object` takes an\nestimator (``self``) and returns a\n:class:`~utils.metadata_routing.MetadataRouter` or a\n:class:`~utils.metadata_routing.MetadataRequest` based on the output of the\nestimator's ``get_metadata_routing`` method.\n\nThen in each method, we use the ``route_params`` method to construct a\ndictionary of the form ``{\"object_name\": {\"method_name\": {\"metadata\":\nvalue}}}`` to pass to the underlying estimator's method. The ``object_name``\n(``estimator`` in the above ``routed_params.estimator.fit`` example) is the\nsame as the one added in the ``get_metadata_routing``. ``validate_metadata``\nmakes sure all given metadata are requested to avoid silent bugs. Now, we\nillustrate the different behaviors and notably the type of errors raised:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "est = MetaClassifier(estimator=ExampleClassifier().set_fit_request(sample_weight=True))\nest.fit(X, y, sample_weight=my_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that the above example checks that ``sample_weight`` is correctly passed\nto ``ExampleClassifier``, or else it would print that ``sample_weight`` is\n``None``:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "est.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we pass an unknown metadata, an error is raised:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "try:\n    est.fit(X, y, test=my_weights)\nexcept TypeError as e:\n    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And if we pass a metadata which is not explicitly requested:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "try:\n    est.fit(X, y, sample_weight=my_weights).predict(X, groups=my_groups)\nexcept ValueError as e:\n    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Also, if we explicitly set it as not requested, but it is provided:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "est = MetaClassifier(\n    estimator=ExampleClassifier()\n    .set_fit_request(sample_weight=True)\n    .set_predict_request(groups=False)\n)\ntry:\n    est.fit(X, y, sample_weight=my_weights).predict(X[:3, :], groups=my_groups)\nexcept TypeError as e:\n    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Another concept to introduce is **aliased metadata**. This is when an estimator\nrequests a metadata with a different name than the default value. For\ninstance, in a setting where there are two estimators in a pipeline, one\ncould request ``sample_weight1`` and the other ``sample_weight2``. Note that\nthis doesn't change what the estimator expects, it only tells the\nmeta-estimator how to map the provided metadata to what's required. Here's an\nexample, where we pass ``aliased_sample_weight`` to the meta-estimator, but\nthe meta-estimator understands that ``aliased_sample_weight`` is an alias for\n``sample_weight``, and passes it as ``sample_weight`` to the underlying\nestimator:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "est = MetaClassifier(\n    estimator=ExampleClassifier().set_fit_request(sample_weight=\"aliased_sample_weight\")\n)\nest.fit(X, y, aliased_sample_weight=my_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And passing ``sample_weight`` here will fail since it is requested with an\nalias and ``sample_weight`` with that name is not requested:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "try:\n    est.fit(X, y, sample_weight=my_weights)\nexcept TypeError as e:\n    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This leads us to the ``get_metadata_routing``. The way routing works in\nscikit-learn is that consumers request what they need, and routers pass that\nalong. Additionally, a router exposes what it requires itself so that it can\nbe used inside another router, e.g. a pipeline inside a grid search object.\nThe output of the ``get_metadata_routing`` which is a dictionary\nrepresentation of a :class:`~utils.metadata_routing.MetadataRouter`, includes\nthe complete tree of requested metadata by all nested objects and their\ncorresponding method routings, i.e. which method of a sub-estimator is used\nin which method of a meta-estimator:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print_routing(est)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you can see, the only metadata requested for method ``fit`` is\n``\"sample_weight\"`` with ``\"aliased_sample_weight\"`` as the alias. The\n``~utils.metadata_routing.MetadataRouter`` class enables us to easily create\nthe routing object which would create the output we need for our\n``get_metadata_routing``. In the above implementation,\n``mapping=\"one-to-one\"`` means there is a one to one mapping between\nsub-estimator's methods and meta-estimator's ones, i.e. ``fit`` used in\n``fit`` and so on. In order to understand how aliases work in\nmeta-estimators, imagine our meta-estimator inside another one:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "meta_est = MetaClassifier(estimator=est).fit(X, y, aliased_sample_weight=my_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the above example, this is how each ``fit`` method will call the\nsub-estimator's ``fit``::\n\n    meta_est.fit(X, y, aliased_sample_weight=my_weights):\n        ...  # this estimator (est), expects aliased_sample_weight as seen above\n        self.estimator_.fit(X, y, aliased_sample_weight=aliased_sample_weight):\n            ...  # now est passes aliased_sample_weight's value as sample_weight,\n                 # which is expected by the sub-estimator\n            self.estimator_.fit(X, y, sample_weight=aliased_sample_weight)\n   ...\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Router and Consumer\nTo show how a slightly more complex case would work, consider a case\nwhere a meta-estimator uses some metadata, but it also routes them to an\nunderlying estimator. In this case, this meta-estimator is a consumer and a\nrouter at the same time. This is how we can implement one, and it is very\nsimilar to what we had before, with a few tweaks.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class RouterConsumerClassifier(MetaEstimatorMixin, ClassifierMixin, BaseEstimator):\n    def __init__(self, estimator):\n        self.estimator = estimator\n\n    def get_metadata_routing(self):\n        router = (\n            MetadataRouter(owner=self.__class__.__name__)\n            .add_self_request(self)\n            .add(estimator=self.estimator, method_mapping=\"one-to-one\")\n        )\n        return router\n\n    def fit(self, X, y, sample_weight, **fit_params):\n        if self.estimator is None:\n            raise ValueError(\"estimator cannot be None!\")\n\n        check_metadata(self, sample_weight=sample_weight)\n\n        if sample_weight is not None:\n            fit_params[\"sample_weight\"] = sample_weight\n\n        # meta-estimators are responsible for validating the given metadata\n        request_router = get_routing_for_object(self)\n        request_router.validate_metadata(params=fit_params, method=\"fit\")\n        # we can use provided utility methods to map the given metadata to what\n        # is required by the underlying estimator\n        params = request_router.route_params(params=fit_params, caller=\"fit\")\n        self.estimator_ = clone(self.estimator).fit(X, y, **params.estimator.fit)\n        self.classes_ = self.estimator_.classes_\n        return self\n\n    def predict(self, X, **predict_params):\n        check_is_fitted(self)\n        # same as in ``fit``, we validate the given metadata\n        request_router = get_routing_for_object(self)\n        request_router.validate_metadata(params=predict_params, method=\"predict\")\n        # and then prepare the input to the underlying ``predict`` method.\n        params = request_router.route_params(params=predict_params, caller=\"predict\")\n        return self.estimator_.predict(X, **params.estimator.predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The key parts where the above estimator differs from our previous\nmeta-estimator is accepting ``sample_weight`` explicitly in ``fit`` and\nincluding it in ``fit_params``. Making ``sample_weight`` an explicit argument\nmakes sure ``set_fit_request(sample_weight=...)`` is present for this class.\nIn a sense, this means the estimator is both a consumer, as well as a router\nof ``sample_weight``.\n\nIn ``get_metadata_routing``, we add ``self`` to the routing using\n``add_self_request`` to indicate this estimator is consuming\n``sample_weight`` as well as being a router; which also adds a\n``$self_request`` key to the routing info as illustrated below. Now let's\nlook at some examples:\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- No metadata requested\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "est = RouterConsumerClassifier(estimator=ExampleClassifier())\nprint_routing(est)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- ``sample_weight`` requested by underlying estimator\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "est = RouterConsumerClassifier(\n    estimator=ExampleClassifier().set_fit_request(sample_weight=True)\n)\nprint_routing(est)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- ``sample_weight`` requested by meta-estimator\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "est = RouterConsumerClassifier(estimator=ExampleClassifier()).set_fit_request(\n    sample_weight=True\n)\nprint_routing(est)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note the difference in the requested metadata representations above.\n\n- We can also alias the metadata to pass different values to them:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "est = RouterConsumerClassifier(\n    estimator=ExampleClassifier().set_fit_request(sample_weight=\"clf_sample_weight\"),\n).set_fit_request(sample_weight=\"meta_clf_sample_weight\")\nprint_routing(est)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "However, ``fit`` of the meta-estimator only needs the alias for the\nsub-estimator, since it doesn't validate and route its own required metadata:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "est.fit(X, y, sample_weight=my_weights, clf_sample_weight=my_other_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Alias only on the sub-estimator. This is useful if we don't want the\n  meta-estimator to use the metadata, and we only want the metadata to be used\n  by the sub-estimator.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "est = RouterConsumerClassifier(\n    estimator=ExampleClassifier().set_fit_request(sample_weight=\"aliased_sample_weight\")\n).set_fit_request(sample_weight=True)\nprint_routing(est)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simple Pipeline\nA slightly more complicated use-case is a meta-estimator which does something\nsimilar to the :class:`~pipeline.Pipeline`. Here is a meta-estimator, which\naccepts a transformer and a classifier, and applies the transformer before\nrunning the classifier.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class SimplePipeline(ClassifierMixin, BaseEstimator):\n    _required_parameters = [\"estimator\"]\n\n    def __init__(self, transformer, classifier):\n        self.transformer = transformer\n        self.classifier = classifier\n\n    def get_metadata_routing(self):\n        router = (\n            MetadataRouter(owner=self.__class__.__name__)\n            .add(\n                transformer=self.transformer,\n                method_mapping=MethodMapping()\n                .add(callee=\"fit\", caller=\"fit\")\n                .add(callee=\"transform\", caller=\"fit\")\n                .add(callee=\"transform\", caller=\"predict\"),\n            )\n            .add(classifier=self.classifier, method_mapping=\"one-to-one\")\n        )\n        return router\n\n    def fit(self, X, y, **fit_params):\n        params = process_routing(self, \"fit\", fit_params)\n\n        self.transformer_ = clone(self.transformer).fit(X, y, **params.transformer.fit)\n        X_transformed = self.transformer_.transform(X, **params.transformer.transform)\n\n        self.classifier_ = clone(self.classifier).fit(\n            X_transformed, y, **params.classifier.fit\n        )\n        return self\n\n    def predict(self, X, **predict_params):\n        params = process_routing(self, \"predict\", predict_params)\n\n        X_transformed = self.transformer_.transform(X, **params.transformer.transform)\n        return self.classifier_.predict(X_transformed, **params.classifier.predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note the usage of :class:`~utils.metadata_routing.MethodMapping` to declare\nwhich methods of the child estimator (callee) are used in which methods of\nthe meta estimator (caller). As you can see, we use the transformer's\n``transform`` and ``fit`` methods in ``fit``, and its ``transform`` method in\n``predict``, and that's what you see implemented in the routing structure of\nthe pipeline class.\n\nAnother difference in the above example with the previous ones is the usage\nof :func:`~utils.metadata_routing.process_routing`, which processes the input\nparameters, does the required validation, and returns the `params` which we\nhad created in previous examples. This reduces the boilerplate code a\ndeveloper needs to write in each meta-estimator's method. Developers are\nstrongly recommended to use this function unless there is a good reason\nagainst it.\n\nIn order to test the above pipeline, let's add an example transformer.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class ExampleTransformer(TransformerMixin, BaseEstimator):\n    def fit(self, X, y, sample_weight=None):\n        check_metadata(self, sample_weight=sample_weight)\n        return self\n\n    def transform(self, X, groups=None):\n        check_metadata(self, groups=groups)\n        return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can test our pipeline, and see if metadata is correctly passed around.\nThis example uses our simple pipeline, and our transformer, and our\nconsumer+router estimator which uses our simple classifier.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "est = SimplePipeline(\n    transformer=ExampleTransformer()\n    # we transformer's fit to receive sample_weight\n    .set_fit_request(sample_weight=True)\n    # we want transformer's transform to receive groups\n    .set_transform_request(groups=True),\n    classifier=RouterConsumerClassifier(\n        estimator=ExampleClassifier()\n        # we want this sub-estimator to receive sample_weight in fit\n        .set_fit_request(sample_weight=True)\n        # but not groups in predict\n        .set_predict_request(groups=False),\n    ).set_fit_request(\n        # and we want the meta-estimator to receive sample_weight as well\n        sample_weight=True\n    ),\n)\nest.fit(X, y, sample_weight=my_weights, groups=my_groups).predict(\n    X[:3], groups=my_groups\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deprecation / Default Value Change\nIn this section we show how one should handle the case where a router becomes\nalso a consumer, especially when it consumes the same metadata as its\nsub-estimator, or a consumer starts consuming a metadata which it wasn't in\nan older release. In this case, a warning should be raised for a while, to\nlet users know the behavior is changed from previous versions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class MetaRegressor(MetaEstimatorMixin, RegressorMixin, BaseEstimator):\n    def __init__(self, estimator):\n        self.estimator = estimator\n\n    def fit(self, X, y, **fit_params):\n        params = process_routing(self, \"fit\", fit_params)\n        self.estimator_ = clone(self.estimator).fit(X, y, **params.estimator.fit)\n\n    def get_metadata_routing(self):\n        router = MetadataRouter(owner=self.__class__.__name__).add(\n            estimator=self.estimator, method_mapping=\"one-to-one\"\n        )\n        return router"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As explained above, this is now a valid usage:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "reg = MetaRegressor(estimator=LinearRegression().set_fit_request(sample_weight=True))\nreg.fit(X, y, sample_weight=my_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now imagine we further develop ``MetaRegressor`` and it now also *consumes*\n``sample_weight``:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class WeightedMetaRegressor(MetaEstimatorMixin, RegressorMixin, BaseEstimator):\n    __metadata_request__fit = {\"sample_weight\": metadata_routing.WARN}\n\n    def __init__(self, estimator):\n        self.estimator = estimator\n\n    def fit(self, X, y, sample_weight=None, **fit_params):\n        params = process_routing(self, \"fit\", fit_params, sample_weight=sample_weight)\n        check_metadata(self, sample_weight=sample_weight)\n        self.estimator_ = clone(self.estimator).fit(X, y, **params.estimator.fit)\n\n    def get_metadata_routing(self):\n        router = (\n            MetadataRouter(owner=self.__class__.__name__)\n            .add_self_request(self)\n            .add(estimator=self.estimator, method_mapping=\"one-to-one\")\n        )\n        return router"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The above implementation is almost no different than ``MetaRegressor``, and\nbecause of the default request value defined in ``__metadata_request__fit``\nthere is a warning raised.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "with warnings.catch_warnings(record=True) as record:\n    WeightedMetaRegressor(\n        estimator=LinearRegression().set_fit_request(sample_weight=False)\n    ).fit(X, y, sample_weight=my_weights)\nfor w in record:\n    print(w.message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When an estimator supports a metadata which wasn't supported before, the\nfollowing pattern can be used to warn the users about it.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class ExampleRegressor(RegressorMixin, BaseEstimator):\n    __metadata_request__fit = {\"sample_weight\": metadata_routing.WARN}\n\n    def fit(self, X, y, sample_weight=None):\n        check_metadata(self, sample_weight=sample_weight)\n        return self\n\n    def predict(self, X):\n        return np.zeros(shape=(len(X)))\n\n\nwith warnings.catch_warnings(record=True) as record:\n    MetaRegressor(estimator=ExampleRegressor()).fit(X, y, sample_weight=my_weights)\nfor w in record:\n    print(w.message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Third Party Development and scikit-learn Dependency\n\nAs seen above, information is communicated between classes using\n:class:`~utils.metadata_routing.MetadataRequest` and\n:class:`~utils.metadata_routing.MetadataRouter`. It is strongly not advised,\nbut possible to vendor the tools related to metadata-routing if you strictly\nwant to have a scikit-learn compatible estimator, without depending on the\nscikit-learn package. If the following conditions are met, you do NOT need to\nmodify your code at all:\n\n- your estimator inherits from :class:`~base.BaseEstimator`\n- the parameters consumed by your estimator's methods, e.g. ``fit``, are\n  explicitly defined in the method's signature, as opposed to being\n  ``*args`` or ``*kwargs``.\n- you do not route any metadata to the underlying objects, i.e. you're not a\n  *router*.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}