

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="Description" content="scikit-learn: machine learning in Python">

  
  <title>Glossary of Common Terms and API Elements &mdash; scikit-learn 0.23.2 documentation</title>
  
  <link rel="canonical" href="http://scikit-learn.org/stable/glossary.html" />

  
  <link rel="shortcut icon" href="_static/favicon.ico"/>
  

  <link rel="stylesheet" href="_static/css/vendor/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="_static/gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="_static/gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
<script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
<script src="_static/jquery.js"></script> 
</head>
<body>
<nav id="navbar" class="sk-docs-navbar navbar navbar-expand-md navbar-light bg-light py-0">
  <div class="container-fluid sk-docs-container px-0">
      <a class="navbar-brand py-0" href="index.html">
        <img
          class="sk-brand-img"
          src="_static/scikit-learn-logo-small.png"
          alt="logo"/>
      </a>
    <button
      id="sk-navbar-toggler"
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="sk-navbar-collapse collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="install.html">Install</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="user_guide.html">User Guide</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="modules/classes.html">API</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="auto_examples/index.html">Examples</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="getting_started.html">Getting Started</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="tutorial/index.html">Tutorial</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="whats_new/v0.23.html">What's new</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="#">Glossary</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="developers/index.html">Development</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="faq.html">FAQ</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="related_projects.html">Related packages</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="roadmap.html">Roadmap</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="about.html">About us</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://github.com/scikit-learn/scikit-learn">GitHub</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://scikit-learn.org/dev/versions.html">Other Versions</a>
        </li>
        <li class="nav-item dropdown nav-more-item-dropdown">
          <a class="sk-nav-link nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">More</a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdown">
              <a class="sk-nav-dropdown-item dropdown-item" href="getting_started.html">Getting Started</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="tutorial/index.html">Tutorial</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="whats_new/v0.23.html">What's new</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="#">Glossary</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="developers/index.html">Development</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="faq.html">FAQ</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="related_projects.html">Related packages</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="roadmap.html">Roadmap</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="about.html">About us</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://github.com/scikit-learn/scikit-learn">GitHub</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://scikit-learn.org/dev/versions.html">Other Versions</a>
          </div>
        </li>
      </ul>
      <div id="searchbox" role="search">
          <div class="searchformwrapper">
          <form class="search" action="search.html" method="get">
            <input class="sk-search-text-input" type="text" name="q" aria-labelledby="searchlabel" />
            <input class="sk-search-text-btn" type="submit" value="Go" />
          </form>
          </div>
      </div>
    </div>
  </div>
</nav>
<div class="d-flex" id="sk-doc-wrapper">
    <input type="checkbox" name="sk-toggle-checkbox" id="sk-toggle-checkbox">
    <label id="sk-sidemenu-toggle" class="sk-btn-toggle-toc btn sk-btn-primary" for="sk-toggle-checkbox">Toggle Menu</label>
    <div id="sk-sidebar-wrapper" class="border-right">
      <div class="sk-sidebar-toc-wrapper">
        <div class="sk-sidebar-toc-logo">
          <a href="index.html">
            <img
              class="sk-brand-img"
              src="_static/scikit-learn-logo-small.png"
              alt="logo"/>
          </a>
        </div>
        <div class="btn-group w-100 mb-2" role="group" aria-label="rellinks">
            <a href="modules/computing.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="8. Computing with scikit-learn">Prev</a>
            <a href="#" role="button" class="btn sk-btn-rellink disabled py-1">Up</a>
            <a href="auto_examples/index.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="Examples">Next</a>
        </div>
        <div class="alert alert-danger p-1 mb-2" role="alert">
          <p class="text-center mb-0">
          <strong>scikit-learn 0.23.2</strong><br/>
          <a href="http://scikit-learn.org/dev/versions.html">Other versions</a>
          </p>
        </div>
        <div class="alert alert-warning p-1 mb-2" role="alert">
          <p class="text-center mb-0">
            Please <a class="font-weight-bold" href="about.html#citing-scikit-learn"><string>cite us</string></a> if you use the software.
          </p>
        </div>
          <div class="sk-sidebar-toc">
            <ul>
<li><a class="reference internal" href="#">Glossary of Common Terms and API Elements</a><ul>
<li><a class="reference internal" href="#general-concepts">General Concepts</a></li>
<li><a class="reference internal" href="#class-apis-and-estimator-types">Class APIs and Estimator Types</a></li>
<li><a class="reference internal" href="#target-types">Target Types</a></li>
<li><a class="reference internal" href="#methods">Methods</a></li>
<li><a class="reference internal" href="#parameters">Parameters</a></li>
<li><a class="reference internal" href="#attributes">Attributes</a></li>
<li><a class="reference internal" href="#data-and-sample-properties">Data and sample properties</a></li>
</ul>
</li>
</ul>

          </div>
      </div>
    </div>
    <div id="sk-page-content-wrapper">
      <div class="sk-page-content container-fluid body px-md-3" role="main">
        
  <div class="section" id="glossary-of-common-terms-and-api-elements">
<span id="glossary"></span><h1>Glossary of Common Terms and API Elements<a class="headerlink" href="#glossary-of-common-terms-and-api-elements" title="Permalink to this headline">¶</a></h1>
<p>This glossary hopes to definitively represent the tacit and explicit
conventions applied in Scikit-learn and its API, while providing a reference
for users and contributors. It aims to describe the concepts and either detail
their corresponding API or link to other relevant parts of the documentation
which do so. By linking to glossary entries from the API Reference and User
Guide, we may minimize redundancy and inconsistency.</p>
<p>We begin by listing general concepts (and any that didn’t fit elsewhere), but
more specific sets of related terms are listed below:
<a class="reference internal" href="#glossary-estimator-types"><span class="std std-ref">Class APIs and Estimator Types</span></a>, <a class="reference internal" href="#glossary-target-types"><span class="std std-ref">Target Types</span></a>,
<a class="reference internal" href="#glossary-methods"><span class="std std-ref">Methods</span></a>, <a class="reference internal" href="#glossary-parameters"><span class="std std-ref">Parameters</span></a>,
<a class="reference internal" href="#glossary-attributes"><span class="std std-ref">Attributes</span></a>, <a class="reference internal" href="#glossary-sample-props"><span class="std std-ref">Data and sample properties</span></a>.</p>
<div class="section" id="general-concepts">
<h2>General Concepts<a class="headerlink" href="#general-concepts" title="Permalink to this headline">¶</a></h2>
<dl class="glossary">
<dt id="term-1d">1d</dt><dt id="term-1d-array">1d array</dt><dd><p>One-dimensional array. A NumPy array whose <code class="docutils literal notranslate"><span class="pre">.shape</span></code> has length 1.
A vector.</p>
</dd>
<dt id="term-2d">2d</dt><dt id="term-2d-array">2d array</dt><dd><p>Two-dimensional array. A NumPy array whose <code class="docutils literal notranslate"><span class="pre">.shape</span></code> has length 2.
Often represents a matrix.</p>
</dd>
<dt id="term-API">API</dt><dd><p>Refers to both the <em>specific</em> interfaces for estimators implemented in
Scikit-learn and the <em>generalized</em> conventions across types of
estimators as described in this glossary and <a class="reference internal" href="developers/develop.html#api-overview"><span class="std std-ref">overviewed in the
contributor documentation</span></a>.</p>
<p>The specific interfaces that constitute Scikit-learn’s public API are
largely documented in <a class="reference internal" href="modules/classes.html#api-ref"><span class="std std-ref">API Reference</span></a>. However, we less formally consider
anything as public API if none of the identifiers required to access it
begins with <code class="docutils literal notranslate"><span class="pre">_</span></code>.  We generally try to maintain <a class="reference internal" href="#term-backwards-compatibility"><span class="xref std std-term">backwards
compatibility</span></a> for all objects in the public API.</p>
<p>Private API, including functions, modules and methods beginning <code class="docutils literal notranslate"><span class="pre">_</span></code>
are not assured to be stable.</p>
</dd>
<dt id="term-array-like">array-like</dt><dd><p>The most common data format for <em>input</em> to Scikit-learn estimators and
functions, array-like is any type object for which
<a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.asarray.html#numpy.asarray" title="(in NumPy v1.19)"><code class="xref py py-func docutils literal notranslate"><span class="pre">numpy.asarray</span></code></a> will produce an array of appropriate shape
(usually 1 or 2-dimensional) of appropriate dtype (usually numeric).</p>
<p>This includes:</p>
<ul class="simple">
<li><p>a numpy array</p></li>
<li><p>a list of numbers</p></li>
<li><p>a list of length-k lists of numbers for some fixed length k</p></li>
<li><p>a <a class="reference external" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v1.1.4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code></a> with all columns numeric</p></li>
<li><p>a numeric <a class="reference external" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series" title="(in pandas v1.1.4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">pandas.Series</span></code></a></p></li>
</ul>
<p>It excludes:</p>
<ul class="simple">
<li><p>a <a class="reference internal" href="#term-sparse-matrix"><span class="xref std std-term">sparse matrix</span></a></p></li>
<li><p>an iterator</p></li>
<li><p>a generator</p></li>
</ul>
<p>Note that <em>output</em> from scikit-learn estimators and functions (e.g.
predictions) should generally be arrays or sparse matrices, or lists
thereof (as in multi-output <a class="reference internal" href="modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier" title="sklearn.tree.DecisionTreeClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">tree.DecisionTreeClassifier</span></code></a>’s
<code class="docutils literal notranslate"><span class="pre">predict_proba</span></code>). An estimator where <code class="docutils literal notranslate"><span class="pre">predict()</span></code> returns a list or
a <code class="docutils literal notranslate"><span class="pre">pandas.Series</span></code> is not valid.</p>
</dd>
<dt id="term-attribute">attribute</dt><dt id="term-attributes">attributes</dt><dd><p>We mostly use attribute to refer to how model information is stored on
an estimator during fitting.  Any public attribute stored on an
estimator instance is required to begin with an alphabetic character
and end in a single underscore if it is set in <a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a> or
<a class="reference internal" href="#term-partial_fit"><span class="xref std std-term">partial_fit</span></a>.  These are what is documented under an estimator’s
<em>Attributes</em> documentation.  The information stored in attributes is
usually either: sufficient statistics used for prediction or
transformation; <a class="reference internal" href="#term-transductive"><span class="xref std std-term">transductive</span></a> outputs such as <a class="reference internal" href="#term-labels_"><span class="xref std std-term">labels_</span></a> or
<a class="reference internal" href="#term-embedding_"><span class="xref std std-term">embedding_</span></a>; or diagnostic data, such as
<a class="reference internal" href="#term-feature_importances_"><span class="xref std std-term">feature_importances_</span></a>.
Common attributes are listed <a class="reference internal" href="#glossary-attributes"><span class="std std-ref">below</span></a>.</p>
<p>A public attribute may have the same name as a constructor
<a class="reference internal" href="#term-parameter"><span class="xref std std-term">parameter</span></a>, with a <code class="docutils literal notranslate"><span class="pre">_</span></code> appended.  This is used to store a
validated or estimated version of the user’s input. For example,
<a class="reference internal" href="modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA" title="sklearn.decomposition.PCA"><code class="xref py py-class docutils literal notranslate"><span class="pre">decomposition.PCA</span></code></a> is constructed with an <code class="docutils literal notranslate"><span class="pre">n_components</span></code>
parameter. From this, together with other parameters and the data,
PCA estimates the attribute <code class="docutils literal notranslate"><span class="pre">n_components_</span></code>.</p>
<p>Further private attributes used in prediction/transformation/etc. may
also be set when fitting.  These begin with a single underscore and are
not assured to be stable for public access.</p>
<p>A public attribute on an estimator instance that does not end in an
underscore should be the stored, unmodified value of an <code class="docutils literal notranslate"><span class="pre">__init__</span></code>
<a class="reference internal" href="#term-parameter"><span class="xref std std-term">parameter</span></a> of the same name.  Because of this equivalence, these
are documented under an estimator’s <em>Parameters</em> documentation.</p>
</dd>
<dt id="term-backwards-compatibility">backwards compatibility</dt><dd><p>We generally try to maintain backward compatibility (i.e. interfaces
and behaviors may be extended but not changed or removed) from release
to release but this comes with some exceptions:</p>
<dl class="simple">
<dt>Public API only</dt><dd><p>The behavior of objects accessed through private identifiers
(those beginning <code class="docutils literal notranslate"><span class="pre">_</span></code>) may be changed arbitrarily between
versions.</p>
</dd>
<dt>As documented</dt><dd><p>We will generally assume that the users have adhered to the
documented parameter types and ranges. If the documentation asks
for a list and the user gives a tuple, we do not assure consistent
behavior from version to version.</p>
</dd>
<dt>Deprecation</dt><dd><p>Behaviors may change following a <a class="reference internal" href="#term-deprecation"><span class="xref std std-term">deprecation</span></a> period
(usually two releases long).  Warnings are issued using Python’s
<a class="reference external" href="https://docs.python.org/3/library/warnings.html#module-warnings" title="(in Python v3.9)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">warnings</span></code></a> module.</p>
</dd>
<dt>Keyword arguments</dt><dd><p>We may sometimes assume that all optional parameters (other than X
and y to <a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a> and similar methods) are passed as keyword
arguments only and may be positionally reordered.</p>
</dd>
<dt>Bug fixes and enhancements</dt><dd><p>Bug fixes and – less often – enhancements may change the behavior
of estimators, including the predictions of an estimator trained on
the same data and <a class="reference internal" href="#term-random_state"><span class="xref std std-term">random_state</span></a>.  When this happens, we
attempt to note it clearly in the changelog.</p>
</dd>
<dt>Serialization</dt><dd><p>We make no assurances that pickling an estimator in one version
will allow it to be unpickled to an equivalent model in the
subsequent version.  (For estimators in the sklearn package, we
issue a warning when this unpickling is attempted, even if it may
happen to work.)  See <a class="reference internal" href="modules/model_persistence.html#persistence-limitations"><span class="std std-ref">Security &amp; maintainability limitations</span></a>.</p>
</dd>
<dt><a class="reference internal" href="modules/generated/sklearn.utils.estimator_checks.check_estimator.html#sklearn.utils.estimator_checks.check_estimator" title="sklearn.utils.estimator_checks.check_estimator"><code class="xref py py-func docutils literal notranslate"><span class="pre">utils.estimator_checks.check_estimator</span></code></a></dt><dd><p>We provide limited backwards compatibility assurances for the
estimator checks: we may add extra requirements on estimators
tested with this function, usually when these were informally
assumed but not formally tested.</p>
</dd>
</dl>
<p>Despite this informal contract with our users, the software is provided
as is, as stated in the license.  When a release inadvertently
introduces changes that are not backward compatible, these are known
as software regressions.</p>
</dd>
<dt id="term-callable">callable</dt><dd><p>A function, class or an object which implements the <code class="docutils literal notranslate"><span class="pre">__call__</span></code>
method; anything that returns True when the argument of <a class="reference external" href="https://docs.python.org/3/library/functions.html#callable">callable()</a>.</p>
</dd>
<dt id="term-categorical-feature">categorical feature</dt><dd><p>A categorical or nominal <a class="reference internal" href="#term-feature"><span class="xref std std-term">feature</span></a> is one that has a
finite set of discrete values across the population of data.
These are commonly represented as columns of integers or
strings. Strings will be rejected by most scikit-learn
estimators, and integers will be treated as ordinal or
count-valued. For the use with most estimators, categorical
variables should be one-hot encoded. Notable exceptions include
tree-based models such as random forests and gradient boosting
models that often work better and faster with integer-coded
categorical variables.
<a class="reference internal" href="modules/generated/sklearn.preprocessing.OrdinalEncoder.html#sklearn.preprocessing.OrdinalEncoder" title="sklearn.preprocessing.OrdinalEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">OrdinalEncoder</span></code></a> helps encoding
string-valued categorical features as ordinal integers, and
<a class="reference internal" href="modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder" title="sklearn.preprocessing.OneHotEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">OneHotEncoder</span></code></a> can be used to
one-hot encode categorical features.
See also <a class="reference internal" href="modules/preprocessing.html#preprocessing-categorical-features"><span class="std std-ref">Encoding categorical features</span></a> and the
<a class="reference external" href="https://contrib.scikit-learn.org/categorical-encoding">categorical-encoding</a>
package for tools related to encoding categorical features.</p>
</dd>
<dt id="term-clone">clone</dt><dt id="term-cloned">cloned</dt><dd><p>To copy an <a class="reference internal" href="#term-estimator-instance"><span class="xref std std-term">estimator instance</span></a> and create a new one with
identical <a class="reference internal" href="#term-parameters"><span class="xref std std-term">parameters</span></a>, but without any fitted
<a class="reference internal" href="#term-attributes"><span class="xref std std-term">attributes</span></a>, using <a class="reference internal" href="modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone"><code class="xref py py-func docutils literal notranslate"><span class="pre">clone</span></code></a>.</p>
<p>When <code class="docutils literal notranslate"><span class="pre">fit</span></code> is called, a <a class="reference internal" href="#term-meta-estimator"><span class="xref std std-term">meta-estimator</span></a> usually clones
a wrapped estimator instance before fitting the cloned instance.
(Exceptions, for legacy reasons, include
<a class="reference internal" href="modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code></a> and
<a class="reference internal" href="modules/generated/sklearn.pipeline.FeatureUnion.html#sklearn.pipeline.FeatureUnion" title="sklearn.pipeline.FeatureUnion"><code class="xref py py-class docutils literal notranslate"><span class="pre">FeatureUnion</span></code></a>.)</p>
</dd>
<dt id="term-common-tests">common tests</dt><dd><p>This refers to the tests run on almost every estimator class in
Scikit-learn to check they comply with basic API conventions.  They are
available for external use through
<a class="reference internal" href="modules/generated/sklearn.utils.estimator_checks.check_estimator.html#sklearn.utils.estimator_checks.check_estimator" title="sklearn.utils.estimator_checks.check_estimator"><code class="xref py py-func docutils literal notranslate"><span class="pre">utils.estimator_checks.check_estimator</span></code></a>, with most of the
implementation in <code class="docutils literal notranslate"><span class="pre">sklearn/utils/estimator_checks.py</span></code>.</p>
<p>Note: Some exceptions to the common testing regime are currently
hard-coded into the library, but we hope to replace this by marking
exceptional behaviours on the estimator using semantic <a class="reference internal" href="#term-estimator-tags"><span class="xref std std-term">estimator
tags</span></a>.</p>
</dd>
<dt id="term-deprecation">deprecation</dt><dd><p>We use deprecation to slowly violate our <a class="reference internal" href="#term-backwards-compatibility"><span class="xref std std-term">backwards
compatibility</span></a> assurances, usually to to:</p>
<ul class="simple">
<li><p>change the default value of a parameter; or</p></li>
<li><p>remove a parameter, attribute, method, class, etc.</p></li>
</ul>
<p>We will ordinarily issue a warning when a deprecated element is used,
although there may be limitations to this.  For instance, we will raise
a warning when someone sets a parameter that has been deprecated, but
may not when they access that parameter’s attribute on the estimator
instance.</p>
<p>See the <a class="reference internal" href="developers/contributing.html#contributing-deprecation"><span class="std std-ref">Contributors’ Guide</span></a>.</p>
</dd>
<dt id="term-dimensionality">dimensionality</dt><dd><p>May be used to refer to the number of <a class="reference internal" href="#term-features"><span class="xref std std-term">features</span></a> (i.e.
<a class="reference internal" href="#term-n_features"><span class="xref std std-term">n_features</span></a>), or columns in a 2d feature matrix.
Dimensions are, however, also used to refer to the length of a NumPy
array’s shape, distinguishing a 1d array from a 2d matrix.</p>
</dd>
<dt id="term-docstring">docstring</dt><dd><p>The embedded documentation for a module, class, function, etc., usually
in code as a string at the beginning of the object’s definition, and
accessible as the object’s <code class="docutils literal notranslate"><span class="pre">__doc__</span></code> attribute.</p>
<p>We try to adhere to <a class="reference external" href="https://www.python.org/dev/peps/pep-0257/">PEP257</a>, and follow <a class="reference external" href="https://numpydoc.readthedocs.io/en/latest/format.html">NumpyDoc
conventions</a>.</p>
</dd>
<dt id="term-double-underscore">double underscore</dt><dt id="term-double-underscore-notation">double underscore notation</dt><dd><p>When specifying parameter names for nested estimators, <code class="docutils literal notranslate"><span class="pre">__</span></code> may be
used to separate between parent and child in some contexts. The most
common use is when setting parameters through a meta-estimator with
<a class="reference internal" href="#term-set_params"><span class="xref std std-term">set_params</span></a> and hence in specifying a search grid in
<a class="reference internal" href="modules/grid_search.html#grid-search"><span class="std std-ref">parameter search</span></a>. See <a class="reference internal" href="#term-parameter"><span class="xref std std-term">parameter</span></a>.
It is also used in <a class="reference internal" href="modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline.fit" title="sklearn.pipeline.Pipeline.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">pipeline.Pipeline.fit</span></code></a> for passing
<a class="reference internal" href="#term-sample-properties"><span class="xref std std-term">sample properties</span></a> to the <code class="docutils literal notranslate"><span class="pre">fit</span></code> methods of estimators in
the pipeline.</p>
</dd>
<dt id="term-dtype">dtype</dt><dt id="term-data-type">data type</dt><dd><p>NumPy arrays assume a homogeneous data type throughout, available in
the <code class="docutils literal notranslate"><span class="pre">.dtype</span></code> attribute of an array (or sparse matrix). We generally
assume simple data types for scikit-learn data: float or integer.
We may support object or string data types for arrays before encoding
or vectorizing.  Our estimators do not work with struct arrays, for
instance.</p>
<p>TODO: Mention efficiency and precision issues; casting policy.</p>
</dd>
<dt id="term-duck-typing">duck typing</dt><dd><p>We try to apply <a class="reference external" href="https://en.wikipedia.org/wiki/Duck_typing">duck typing</a> to determine how to
handle some input values (e.g. checking whether a given estimator is
a classifier).  That is, we avoid using <code class="docutils literal notranslate"><span class="pre">isinstance</span></code> where possible,
and rely on the presence or absence of attributes to determine an
object’s behaviour.  Some nuance is required when following this
approach:</p>
<ul>
<li><p>For some estimators, an attribute may only be available once it is
<a class="reference internal" href="#term-fitted"><span class="xref std std-term">fitted</span></a>.  For instance, we cannot a priori determine if
<a class="reference internal" href="#term-predict_proba"><span class="xref std std-term">predict_proba</span></a> is available in a grid search where the grid
includes alternating between a probabilistic and a non-probabilistic
predictor in the final step of the pipeline.  In the following, we
can only determine if <code class="docutils literal notranslate"><span class="pre">clf</span></code> is probabilistic after fitting it on
some data:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">SGDClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">SGDClassifier</span><span class="p">(),</span>
<span class="gp">... </span>                   <span class="n">param_grid</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;log&#39;</span><span class="p">,</span> <span class="s1">&#39;hinge&#39;</span><span class="p">]})</span>
</pre></div>
</div>
<p>This means that we can only check for duck-typed attributes after
fitting, and that we must be careful to make <a class="reference internal" href="#term-meta-estimators"><span class="xref std std-term">meta-estimators</span></a>
only present attributes according to the state of the underlying
estimator after fitting.</p>
</li>
<li><p>Checking if an attribute is present (using <code class="docutils literal notranslate"><span class="pre">hasattr</span></code>) is in general
just as expensive as getting the attribute (<code class="docutils literal notranslate"><span class="pre">getattr</span></code> or dot
notation).  In some cases, getting the attribute may indeed be
expensive (e.g. for some implementations of
<a class="reference internal" href="#term-feature_importances_"><span class="xref std std-term">feature_importances_</span></a>, which may suggest this is an API design
flaw).  So code which does <code class="docutils literal notranslate"><span class="pre">hasattr</span></code> followed by <code class="docutils literal notranslate"><span class="pre">getattr</span></code> should
be avoided; <code class="docutils literal notranslate"><span class="pre">getattr</span></code> within a try-except block is preferred.</p></li>
<li><p>For determining some aspects of an estimator’s expectations or
support for some feature, we use <a class="reference internal" href="#term-estimator-tags"><span class="xref std std-term">estimator tags</span></a> instead of
duck typing.</p></li>
</ul>
</dd>
<dt id="term-early-stopping">early stopping</dt><dd><p>This consists in stopping an iterative optimization method before the
convergence of the training loss, to avoid over-fitting. This is
generally done by monitoring the generalization score on a validation
set. When available, it is activated through the parameter
<code class="docutils literal notranslate"><span class="pre">early_stopping</span></code> or by setting a positive <a class="reference internal" href="#term-n_iter_no_change"><span class="xref std std-term">n_iter_no_change</span></a>.</p>
</dd>
<dt id="term-estimator-instance">estimator instance</dt><dd><p>We sometimes use this terminology to distinguish an <a class="reference internal" href="#term-estimator"><span class="xref std std-term">estimator</span></a>
class from a constructed instance. For example, in the following,
<code class="docutils literal notranslate"><span class="pre">cls</span></code> is an estimator class, while <code class="docutils literal notranslate"><span class="pre">est1</span></code> and <code class="docutils literal notranslate"><span class="pre">est2</span></code> are
instances:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="bp">cls</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span>
<span class="n">est1</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">()</span>
<span class="n">est2</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">()</span>
</pre></div>
</div>
</dd>
<dt id="term-examples">examples</dt><dd><p>We try to give examples of basic usage for most functions and
classes in the API:</p>
<ul class="simple">
<li><p>as doctests in their docstrings (i.e. within the <code class="docutils literal notranslate"><span class="pre">sklearn/</span></code> library
code itself).</p></li>
<li><p>as examples in the <a class="reference internal" href="auto_examples/index.html#general-examples"><span class="std std-ref">example gallery</span></a>
rendered (using <a class="reference external" href="https://sphinx-gallery.readthedocs.io/">sphinx-gallery</a>) from scripts in the
<code class="docutils literal notranslate"><span class="pre">examples/</span></code> directory, exemplifying key features or parameters
of the estimator/function.  These should also be referenced from the
User Guide.</p></li>
<li><p>sometimes in the <a class="reference internal" href="user_guide.html#user-guide"><span class="std std-ref">User Guide</span></a> (built from <code class="docutils literal notranslate"><span class="pre">doc/</span></code>)
alongside a technical description of the estimator.</p></li>
</ul>
</dd>
<dt id="term-evaluation-metric">evaluation metric</dt><dt id="term-evaluation-metrics">evaluation metrics</dt><dd><p>Evaluation metrics give a measure of how well a model performs.  We may
use this term specifically to refer to the functions in <code class="xref py py-mod docutils literal notranslate"><span class="pre">metrics</span></code>
(disregarding <code class="xref py py-mod docutils literal notranslate"><span class="pre">metrics.pairwise</span></code>), as distinct from the
<a class="reference internal" href="#term-score"><span class="xref std std-term">score</span></a> method and the <a class="reference internal" href="#term-scoring"><span class="xref std std-term">scoring</span></a> API used in cross
validation. See <a class="reference internal" href="modules/model_evaluation.html#model-evaluation"><span class="std std-ref">Metrics and scoring: quantifying the quality of predictions</span></a>.</p>
<p>These functions usually accept a ground truth (or the raw data
where the metric evaluates clustering without a ground truth) and a
prediction, be it the output of <a class="reference internal" href="#term-predict"><span class="xref std std-term">predict</span></a> (<code class="docutils literal notranslate"><span class="pre">y_pred</span></code>),
of <a class="reference internal" href="#term-predict_proba"><span class="xref std std-term">predict_proba</span></a> (<code class="docutils literal notranslate"><span class="pre">y_proba</span></code>), or of an arbitrary score
function including <a class="reference internal" href="#term-decision_function"><span class="xref std std-term">decision_function</span></a> (<code class="docutils literal notranslate"><span class="pre">y_score</span></code>).
Functions are usually named to end with <code class="docutils literal notranslate"><span class="pre">_score</span></code> if a greater
score indicates a better model, and <code class="docutils literal notranslate"><span class="pre">_loss</span></code> if a lesser score
indicates a better model.  This diversity of interface motivates
the scoring API.</p>
<p>Note that some estimators can calculate metrics that are not included
in <code class="xref py py-mod docutils literal notranslate"><span class="pre">metrics</span></code> and are estimator-specific, notably model
likelihoods.</p>
</dd>
<dt id="term-estimator-tags">estimator tags</dt><dd><p>A proposed feature (e.g. <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/issues/8022">#8022</a>) by which the capabilities of an
estimator are described through a set of semantic tags.  This would
enable some runtime behaviors based on estimator inspection, but it
also allows each estimator to be tested for appropriate invariances
while being excepted from other <a class="reference internal" href="#term-common-tests"><span class="xref std std-term">common tests</span></a>.</p>
<p>Some aspects of estimator tags are currently determined through
the <a class="reference internal" href="#term-duck-typing"><span class="xref std std-term">duck typing</span></a> of methods like <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> and through
some special attributes on estimator objects:</p>
<dl class="glossary simple">
<dt id="term-_estimator_type"><code class="docutils literal notranslate"><span class="pre">_estimator_type</span></code></dt><dd><p>This string-valued attribute identifies an estimator as being a
classifier, regressor, etc. It is set by mixins such as
<a class="reference internal" href="modules/generated/sklearn.base.ClassifierMixin.html#sklearn.base.ClassifierMixin" title="sklearn.base.ClassifierMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">base.ClassifierMixin</span></code></a>, but needs to be more explicitly
adopted on a <a class="reference internal" href="#term-meta-estimator"><span class="xref std std-term">meta-estimator</span></a>.  Its value should usually be
checked by way of a helper such as <a class="reference internal" href="modules/generated/sklearn.base.is_classifier.html#sklearn.base.is_classifier" title="sklearn.base.is_classifier"><code class="xref py py-func docutils literal notranslate"><span class="pre">base.is_classifier</span></code></a>.</p>
</dd>
<dt id="term-_pairwise"><code class="docutils literal notranslate"><span class="pre">_pairwise</span></code></dt><dd><p>This boolean attribute indicates whether the data (<code class="docutils literal notranslate"><span class="pre">X</span></code>) passed to
<code class="xref py py-func docutils literal notranslate"><span class="pre">fit</span></code> and similar methods consists of pairwise measures over
samples rather than a feature representation for each sample.  It
is usually <code class="docutils literal notranslate"><span class="pre">True</span></code> where an estimator has a <code class="docutils literal notranslate"><span class="pre">metric</span></code> or
<code class="docutils literal notranslate"><span class="pre">affinity</span></code> or <code class="docutils literal notranslate"><span class="pre">kernel</span></code> parameter with value ‘precomputed’.
Its primary purpose is that when a <a class="reference internal" href="#term-meta-estimator"><span class="xref std std-term">meta-estimator</span></a>
extracts a sub-sample of data intended for a pairwise estimator,
the data needs to be indexed on both axes, while other data is
indexed only on the first axis.</p>
</dd>
</dl>
<p>For more detailed info, see <a class="reference internal" href="developers/develop.html#estimator-tags"><span class="std std-ref">Estimator Tags</span></a>.</p>
</dd>
<dt id="term-feature">feature</dt><dt id="term-features">features</dt><dt id="term-feature-vector">feature vector</dt><dd><p>In the abstract, a feature is a function (in its mathematical sense)
mapping a sampled object to a numeric or categorical quantity.
“Feature” is also commonly used to refer to these quantities, being the
individual elements of a vector representing a sample. In a data
matrix, features are represented as columns: each column contains the
result of applying a feature function to a set of samples.</p>
<p>Elsewhere features are known as attributes, predictors, regressors, or
independent variables.</p>
<p>Nearly all estimators in scikit-learn assume that features are numeric,
finite and not missing, even when they have semantically distinct
domains and distributions (categorical, ordinal, count-valued,
real-valued, interval). See also <a class="reference internal" href="#term-categorical-feature"><span class="xref std std-term">categorical feature</span></a> and
<a class="reference internal" href="#term-missing-values"><span class="xref std std-term">missing values</span></a>.</p>
<p><code class="docutils literal notranslate"><span class="pre">n_features</span></code> indicates the number of features in a dataset.</p>
</dd>
<dt id="term-fitting">fitting</dt><dd><p>Calling <a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a> (or <a class="reference internal" href="#term-fit_transform"><span class="xref std std-term">fit_transform</span></a>, <a class="reference internal" href="#term-fit_predict"><span class="xref std std-term">fit_predict</span></a>,
etc.) on an estimator.</p>
</dd>
<dt id="term-fitted">fitted</dt><dd><p>The state of an estimator after <a class="reference internal" href="#term-fitting"><span class="xref std std-term">fitting</span></a>.</p>
<p>There is no conventional procedure for checking if an estimator
is fitted.  However, an estimator that is not fitted:</p>
<ul class="simple">
<li><p>should raise <a class="reference internal" href="modules/generated/sklearn.exceptions.NotFittedError.html#sklearn.exceptions.NotFittedError" title="sklearn.exceptions.NotFittedError"><code class="xref py py-class docutils literal notranslate"><span class="pre">exceptions.NotFittedError</span></code></a> when a prediction
method (<a class="reference internal" href="#term-predict"><span class="xref std std-term">predict</span></a>, <a class="reference internal" href="#term-transform"><span class="xref std std-term">transform</span></a>, etc.) is called.
(<a class="reference internal" href="modules/generated/sklearn.utils.validation.check_is_fitted.html#sklearn.utils.validation.check_is_fitted" title="sklearn.utils.validation.check_is_fitted"><code class="xref py py-func docutils literal notranslate"><span class="pre">utils.validation.check_is_fitted</span></code></a> is used internally
for this purpose.)</p></li>
<li><p>should not have any <a class="reference internal" href="#term-attributes"><span class="xref std std-term">attributes</span></a> beginning with an alphabetic
character and ending with an underscore. (Note that a descriptor for
the attribute may still be present on the class, but hasattr should
return False)</p></li>
</ul>
</dd>
<dt id="term-function">function</dt><dd><p>We provide ad hoc function interfaces for many algorithms, while
<a class="reference internal" href="#term-estimator"><span class="xref std std-term">estimator</span></a> classes provide a more consistent interface.</p>
<p>In particular, Scikit-learn may provide a function interface that fits
a model to some data and returns the learnt model parameters, as in
<a class="reference internal" href="modules/generated/sklearn.linear_model.enet_path.html#sklearn.linear_model.enet_path" title="sklearn.linear_model.enet_path"><code class="xref py py-func docutils literal notranslate"><span class="pre">linear_model.enet_path</span></code></a>.  For transductive models, this also
returns the embedding or cluster labels, as in
<a class="reference internal" href="modules/generated/sklearn.manifold.spectral_embedding.html#sklearn.manifold.spectral_embedding" title="sklearn.manifold.spectral_embedding"><code class="xref py py-func docutils literal notranslate"><span class="pre">manifold.spectral_embedding</span></code></a> or <a class="reference internal" href="modules/generated/sklearn.cluster.dbscan.html#sklearn.cluster.dbscan" title="sklearn.cluster.dbscan"><code class="xref py py-func docutils literal notranslate"><span class="pre">cluster.dbscan</span></code></a>.  Many
preprocessing transformers also provide a function interface, akin to
calling <a class="reference internal" href="#term-fit_transform"><span class="xref std std-term">fit_transform</span></a>, as in
<a class="reference internal" href="modules/generated/sklearn.preprocessing.maxabs_scale.html#sklearn.preprocessing.maxabs_scale" title="sklearn.preprocessing.maxabs_scale"><code class="xref py py-func docutils literal notranslate"><span class="pre">preprocessing.maxabs_scale</span></code></a>.  Users should be careful to avoid
<a class="reference internal" href="#term-data-leakage"><span class="xref std std-term">data leakage</span></a> when making use of these
<code class="docutils literal notranslate"><span class="pre">fit_transform</span></code>-equivalent functions.</p>
<p>We do not have a strict policy about when to or when not to provide
function forms of estimators, but maintainers should consider
consistency with existing interfaces, and whether providing a function
would lead users astray from best practices (as regards data leakage,
etc.)</p>
</dd>
<dt id="term-gallery">gallery</dt><dd><p>See <a class="reference internal" href="#term-examples"><span class="xref std std-term">examples</span></a>.</p>
</dd>
<dt id="term-hyperparameter">hyperparameter</dt><dt id="term-hyper-parameter">hyper-parameter</dt><dd><p>See <a class="reference internal" href="#term-parameter"><span class="xref std std-term">parameter</span></a>.</p>
</dd>
<dt id="term-impute">impute</dt><dt id="term-imputation">imputation</dt><dd><p>Most machine learning algorithms require that their inputs have no
<a class="reference internal" href="#term-missing-values"><span class="xref std std-term">missing values</span></a>, and will not work if this requirement is
violated. Algorithms that attempt to fill in (or impute) missing values
are referred to as imputation algorithms.</p>
</dd>
<dt id="term-indexable">indexable</dt><dd><p>An <a class="reference internal" href="#term-array-like"><span class="xref std std-term">array-like</span></a>, <a class="reference internal" href="#term-sparse-matrix"><span class="xref std std-term">sparse matrix</span></a>, pandas DataFrame or
sequence (usually a list).</p>
</dd>
<dt id="term-induction">induction</dt><dt id="term-inductive">inductive</dt><dd><p>Inductive (contrasted with <a class="reference internal" href="#term-transductive"><span class="xref std std-term">transductive</span></a>) machine learning
builds a model of some data that can then be applied to new instances.
Most estimators in Scikit-learn are inductive, having <a class="reference internal" href="#term-predict"><span class="xref std std-term">predict</span></a>
and/or <a class="reference internal" href="#term-transform"><span class="xref std std-term">transform</span></a> methods.</p>
</dd>
<dt id="term-joblib">joblib</dt><dd><p>A Python library (<a class="reference external" href="https://joblib.readthedocs.io">https://joblib.readthedocs.io</a>) used in Scikit-learn to
facilite simple parallelism and caching.  Joblib is oriented towards
efficiently working with numpy arrays, such as through use of
<a class="reference internal" href="#term-memory-mapping"><span class="xref std std-term">memory mapping</span></a>. See <a class="reference internal" href="modules/computing.html#parallelism"><span class="std std-ref">Parallelism</span></a> for more
information.</p>
</dd>
<dt id="term-label-indicator-matrix">label indicator matrix</dt><dt id="term-multilabel-indicator-matrix">multilabel indicator matrix</dt><dt id="term-multilabel-indicator-matrices">multilabel indicator matrices</dt><dd><p>The format used to represent multilabel data, where each row of a 2d
array or sparse matrix corresponds to a sample, each column
corresponds to a class, and each element is 1 if the sample is labeled
with the class and 0 if not.</p>
</dd>
<dt id="term-leakage">leakage</dt><dt id="term-data-leakage">data leakage</dt><dd><p>A problem in cross validation where generalization performance can be
over-estimated since knowledge of the test data was inadvertently
included in training a model.  This is a risk, for instance, when
applying a <a class="reference internal" href="#term-transformer"><span class="xref std std-term">transformer</span></a> to the entirety of a dataset rather
than each training portion in a cross validation split.</p>
<p>We aim to provide interfaces (such as <code class="xref py py-mod docutils literal notranslate"><span class="pre">pipeline</span></code> and
<code class="xref py py-mod docutils literal notranslate"><span class="pre">model_selection</span></code>) that shield the user from data leakage.</p>
</dd>
<dt id="term-memmapping">memmapping</dt><dt id="term-memory-map">memory map</dt><dt id="term-memory-mapping">memory mapping</dt><dd><p>A memory efficiency strategy that keeps data on disk rather than
copying it into main memory.  Memory maps can be created for arrays
that can be read, written, or both, using <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.memmap.html#numpy.memmap" title="(in NumPy v1.19)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.memmap</span></code></a>. When
using <a class="reference internal" href="#term-joblib"><span class="xref std std-term">joblib</span></a> to parallelize operations in Scikit-learn, it
may automatically memmap large arrays to reduce memory duplication
overhead in multiprocessing.</p>
</dd>
<dt id="term-missing-values">missing values</dt><dd><p>Most Scikit-learn estimators do not work with missing values. When they
do (e.g. in <a class="reference internal" href="modules/generated/sklearn.impute.SimpleImputer.html#sklearn.impute.SimpleImputer" title="sklearn.impute.SimpleImputer"><code class="xref py py-class docutils literal notranslate"><span class="pre">impute.SimpleImputer</span></code></a>), NaN is the preferred
representation of missing values in float arrays.  If the array has
integer dtype, NaN cannot be represented. For this reason, we support
specifying another <code class="docutils literal notranslate"><span class="pre">missing_values</span></code> value when <a class="reference internal" href="#term-imputation"><span class="xref std std-term">imputation</span></a> or
learning can be performed in integer space.  <a class="reference internal" href="#term-unlabeled-data"><span class="xref std std-term">Unlabeled data</span></a>
is a special case of missing values in the <a class="reference internal" href="#term-target"><span class="xref std std-term">target</span></a>.</p>
</dd>
<dt id="term-n_features"><code class="docutils literal notranslate"><span class="pre">n_features</span></code></dt><dd><p>The number of <a class="reference internal" href="#term-features"><span class="xref std std-term">features</span></a>.</p>
</dd>
<dt id="term-n_outputs"><code class="docutils literal notranslate"><span class="pre">n_outputs</span></code></dt><dd><p>The number of <a class="reference internal" href="#term-outputs"><span class="xref std std-term">outputs</span></a> in the <a class="reference internal" href="#term-target"><span class="xref std std-term">target</span></a>.</p>
</dd>
<dt id="term-n_samples"><code class="docutils literal notranslate"><span class="pre">n_samples</span></code></dt><dd><p>The number of <a class="reference internal" href="#term-samples"><span class="xref std std-term">samples</span></a>.</p>
</dd>
<dt id="term-n_targets"><code class="docutils literal notranslate"><span class="pre">n_targets</span></code></dt><dd><p>Synonym for <a class="reference internal" href="#term-n_outputs"><span class="xref std std-term">n_outputs</span></a>.</p>
</dd>
<dt id="term-narrative-docs">narrative docs</dt><dt id="term-narrative-documentation">narrative documentation</dt><dd><p>An alias for <a class="reference internal" href="user_guide.html#user-guide"><span class="std std-ref">User Guide</span></a>, i.e. documentation written
in <code class="docutils literal notranslate"><span class="pre">doc/modules/</span></code>. Unlike the <a class="reference internal" href="modules/classes.html#api-ref"><span class="std std-ref">API reference</span></a> provided
through docstrings, the User Guide aims to:</p>
<ul class="simple">
<li><p>group tools provided by Scikit-learn together thematically or in
terms of usage;</p></li>
<li><p>motivate why someone would use each particular tool, often through
comparison;</p></li>
<li><p>provide both intuitive and technical descriptions of tools;</p></li>
<li><p>provide or link to <a class="reference internal" href="#term-examples"><span class="xref std std-term">examples</span></a> of using key features of a
tool.</p></li>
</ul>
</dd>
<dt id="term-np">np</dt><dd><p>A shorthand for Numpy due to the conventional import statement:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>
</div>
</dd>
<dt id="term-online-learning">online learning</dt><dd><p>Where a model is iteratively updated by receiving each batch of ground
truth <a class="reference internal" href="#term-targets"><span class="xref std std-term">targets</span></a> soon after making predictions on corresponding
batch of data.  Intrinsically, the model must be usable for prediction
after each batch. See <a class="reference internal" href="#term-partial_fit"><span class="xref std std-term">partial_fit</span></a>.</p>
</dd>
<dt id="term-out-of-core">out-of-core</dt><dd><p>An efficiency strategy where not all the data is stored in main memory
at once, usually by performing learning on batches of data. See
<a class="reference internal" href="#term-partial_fit"><span class="xref std std-term">partial_fit</span></a>.</p>
</dd>
<dt id="term-outputs">outputs</dt><dd><p>Individual scalar/categorical variables per sample in the
<a class="reference internal" href="#term-target"><span class="xref std std-term">target</span></a>.  For example, in multilabel classification each
possible label corresponds to a binary output. Also called <em>responses</em>,
<em>tasks</em> or <em>targets</em>.
See <a class="reference internal" href="#term-multiclass-multioutput"><span class="xref std std-term">multiclass multioutput</span></a> and <a class="reference internal" href="#term-continuous-multioutput"><span class="xref std std-term">continuous multioutput</span></a>.</p>
</dd>
<dt id="term-pair">pair</dt><dd><p>A tuple of length two.</p>
</dd>
<dt id="term-parameter">parameter</dt><dt id="term-parameters">parameters</dt><dt id="term-param">param</dt><dt id="term-params">params</dt><dd><p>We mostly use <em>parameter</em> to refer to the aspects of an estimator that
can be specified in its construction. For example, <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> and
<code class="docutils literal notranslate"><span class="pre">random_state</span></code> are parameters of <code class="xref py py-class docutils literal notranslate"><span class="pre">RandomForestClassifier</span></code>.
Parameters to an estimator’s constructor are stored unmodified as
attributes on the estimator instance, and conventionally start with an
alphabetic character and end with an alphanumeric character.  Each
estimator’s constructor parameters are described in the estimator’s
docstring.</p>
<p>We do not use parameters in the statistical sense, where parameters are
values that specify a model and can be estimated from data. What we
call parameters might be what statisticians call hyperparameters to the
model: aspects for configuring model structure that are often not
directly learnt from data.  However, our parameters are also used to
prescribe modeling operations that do not affect the learnt model, such
as <a class="reference internal" href="#term-n_jobs"><span class="xref std std-term">n_jobs</span></a> for controlling parallelism.</p>
<p>When talking about the parameters of a <a class="reference internal" href="#term-meta-estimator"><span class="xref std std-term">meta-estimator</span></a>, we may
also be including the parameters of the estimators wrapped by the
meta-estimator.  Ordinarily, these nested parameters are denoted by
using a <a class="reference internal" href="#term-double-underscore"><span class="xref std std-term">double underscore</span></a> (<code class="docutils literal notranslate"><span class="pre">__</span></code>) to separate between the
estimator-as-parameter and its parameter.  Thus <code class="docutils literal notranslate"><span class="pre">clf</span> <span class="pre">=</span>
<span class="pre">BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=3))</span></code>
has a deep parameter <code class="docutils literal notranslate"><span class="pre">base_estimator__max_depth</span></code> with value <code class="docutils literal notranslate"><span class="pre">3</span></code>,
which is accessible with <code class="docutils literal notranslate"><span class="pre">clf.base_estimator.max_depth</span></code> or
<code class="docutils literal notranslate"><span class="pre">clf.get_params()['base_estimator__max_depth']</span></code>.</p>
<p>The list of parameters and their current values can be retrieved from
an <a class="reference internal" href="#term-estimator-instance"><span class="xref std std-term">estimator instance</span></a> using its <a class="reference internal" href="#term-get_params"><span class="xref std std-term">get_params</span></a> method.</p>
<p>Between construction and fitting, parameters may be modified using
<a class="reference internal" href="#term-set_params"><span class="xref std std-term">set_params</span></a>.  To enable this, parameters are not ordinarily
validated or altered when the estimator is constructed, or when each
parameter is set. Parameter validation is performed when <a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a> is
called.</p>
<p>Common parameters are listed <a class="reference internal" href="#glossary-parameters"><span class="std std-ref">below</span></a>.</p>
</dd>
<dt id="term-pairwise-metric">pairwise metric</dt><dt id="term-pairwise-metrics">pairwise metrics</dt><dd><p>In its broad sense, a pairwise metric defines a function for measuring
similarity or dissimilarity between two samples (with each ordinarily
represented as a <a class="reference internal" href="#term-feature-vector"><span class="xref std std-term">feature vector</span></a>).  We particularly provide
implementations of distance metrics (as well as improper metrics like
Cosine Distance) through <a class="reference internal" href="modules/generated/sklearn.metrics.pairwise_distances.html#sklearn.metrics.pairwise_distances" title="sklearn.metrics.pairwise_distances"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.pairwise_distances</span></code></a>, and of
kernel functions (a constrained class of similarity functions) in
<code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.pairwise_kernels</span></code>.  These can compute pairwise distance
matrices that are symmetric and hence store data redundantly.</p>
<p>See also <a class="reference internal" href="#term-precomputed"><span class="xref std std-term">precomputed</span></a> and <a class="reference internal" href="#term-metric"><span class="xref std std-term">metric</span></a>.</p>
<p>Note that for most distance metrics, we rely on implementations from
<a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/spatial.distance.html#module-scipy.spatial.distance" title="(in SciPy v1.5.4)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">scipy.spatial.distance</span></code></a>, but may reimplement for efficiency in
our context.  The <code class="xref py py-mod docutils literal notranslate"><span class="pre">neighbors</span></code> module also duplicates some metric
implementations for integration with efficient binary tree search data
structures.</p>
</dd>
<dt id="term-pd">pd</dt><dd><p>A shorthand for <a class="reference external" href="https://pandas.pydata.org">Pandas</a> due to the
conventional import statement:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</pre></div>
</div>
</dd>
<dt id="term-precomputed">precomputed</dt><dd><p>Where algorithms rely on <a class="reference internal" href="#term-pairwise-metrics"><span class="xref std std-term">pairwise metrics</span></a>, and can be computed
from pairwise metrics alone, we often allow the user to specify that
the <a class="reference internal" href="#term-X"><span class="xref std std-term">X</span></a> provided is already in the pairwise (dis)similarity
space, rather than in a feature space.  That is, when passed to
<a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a>, it is a square, symmetric matrix, with each vector
indicating (dis)similarity to every sample, and when passed to
prediction/transformation methods, each row corresponds to a testing
sample and each column to a training sample.</p>
<p>Use of precomputed X is usually indicated by setting a <code class="docutils literal notranslate"><span class="pre">metric</span></code>,
<code class="docutils literal notranslate"><span class="pre">affinity</span></code> or <code class="docutils literal notranslate"><span class="pre">kernel</span></code> parameter to the string ‘precomputed’.  An
estimator should mark itself as being <a class="reference internal" href="#term-_pairwise"><span class="xref std std-term">_pairwise</span></a> if this is the
case.</p>
</dd>
<dt id="term-rectangular">rectangular</dt><dd><p>Data that can be represented as a matrix with <a class="reference internal" href="#term-samples"><span class="xref std std-term">samples</span></a> on the
first axis and a fixed, finite set of <a class="reference internal" href="#term-features"><span class="xref std std-term">features</span></a> on the second
is called rectangular.</p>
<p>This term excludes samples with non-vectorial structures, such as text,
an image of arbitrary size, a time series of arbitrary length, a set of
vectors, etc. The purpose of a <a class="reference internal" href="#term-vectorizer"><span class="xref std std-term">vectorizer</span></a> is to produce
rectangular forms of such data.</p>
</dd>
<dt id="term-sample">sample</dt><dt id="term-samples">samples</dt><dd><p>We usually use this term as a noun to indicate a single feature vector.
Elsewhere a sample is called an instance, data point, or observation.
<code class="docutils literal notranslate"><span class="pre">n_samples</span></code> indicates the number of samples in a dataset, being the
number of rows in a data array <a class="reference internal" href="#term-X"><span class="xref std std-term">X</span></a>.</p>
</dd>
<dt id="term-sample-property">sample property</dt><dt id="term-sample-properties">sample properties</dt><dd><p>A sample property is data for each sample (e.g. an array of length
n_samples) passed to an estimator method or a similar function,
alongside but distinct from the <a class="reference internal" href="#term-features"><span class="xref std std-term">features</span></a> (<code class="docutils literal notranslate"><span class="pre">X</span></code>) and
<a class="reference internal" href="#term-target"><span class="xref std std-term">target</span></a> (<code class="docutils literal notranslate"><span class="pre">y</span></code>). The most prominent example is
<a class="reference internal" href="#term-sample_weight"><span class="xref std std-term">sample_weight</span></a>; see others at <a class="reference internal" href="#glossary-sample-props"><span class="std std-ref">Data and sample properties</span></a>.</p>
<p>As of version 0.19 we do not have a consistent approach to handling
sample properties and their routing in <a class="reference internal" href="#term-meta-estimators"><span class="xref std std-term">meta-estimators</span></a>, though
a <code class="docutils literal notranslate"><span class="pre">fit_params</span></code> parameter is often used.</p>
</dd>
<dt id="term-scikit-learn-contrib">scikit-learn-contrib</dt><dd><p>A venue for publishing Scikit-learn-compatible libraries that are
broadly authorized by the core developers and the contrib community,
but not maintained by the core developer team.
See <a class="reference external" href="https://scikit-learn-contrib.github.io">https://scikit-learn-contrib.github.io</a>.</p>
</dd>
<dt id="term-scikit-learn-enhancement-proposals">scikit-learn enhancement proposals</dt><dt id="term-SLEP">SLEP</dt><dt id="term-SLEPs">SLEPs</dt><dd><p>Changes to the API principles and changes to dependencies or supported
versions happen via a <a class="reference internal" href="governance.html#slep"><span class="std std-ref">SLEP</span></a> and follows the
decision-making process outlined in <a class="reference internal" href="governance.html#governance"><span class="std std-ref">Scikit-learn governance and decision-making</span></a>.
For all votes, a proposal must have been made public and discussed before the
vote. Such a proposal must be a consolidated document, in the form of a
‘Scikit-Learn Enhancement Proposal’ (SLEP), rather than a long discussion on an
issue. A SLEP must be submitted as a pull-request to
<a class="reference external" href="https://scikit-learn-enhancement-proposals.readthedocs.io">enhancement proposals</a> using the
<a class="reference external" href="https://scikit-learn-enhancement-proposals.readthedocs.io/en/latest/slep_template.html">SLEP template</a>.</p>
</dd>
<dt id="term-semi-supervised">semi-supervised</dt><dt id="term-semi-supervised-learning">semi-supervised learning</dt><dt id="term-semisupervised">semisupervised</dt><dd><p>Learning where the expected prediction (label or ground truth) is only
available for some samples provided as training data when
<a class="reference internal" href="#term-fitting"><span class="xref std std-term">fitting</span></a> the model.  We conventionally apply the label <code class="docutils literal notranslate"><span class="pre">-1</span></code>
to <a class="reference internal" href="#term-unlabeled"><span class="xref std std-term">unlabeled</span></a> samples in semi-supervised classification.</p>
</dd>
<dt id="term-sparse-matrix">sparse matrix</dt><dt id="term-sparse-graph">sparse graph</dt><dd><p>A representation of two-dimensional numeric data that is more memory
efficient the corresponding dense numpy array where almost all elements
are zero. We use the <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/sparse.html#module-scipy.sparse" title="(in SciPy v1.5.4)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">scipy.sparse</span></code></a> framework, which provides
several underlying sparse data representations, or <em>formats</em>.
Some formats are more efficient than others for particular tasks, and
when a particular format provides especial benefit, we try to document
this fact in Scikit-learn parameter descriptions.</p>
<p>Some sparse matrix formats (notably CSR, CSC, COO and LIL) distinguish
between <em>implicit</em> and <em>explicit</em> zeros. Explicit zeros are stored
(i.e. they consume memory in a <code class="docutils literal notranslate"><span class="pre">data</span></code> array) in the data structure,
while implicit zeros correspond to every element not otherwise defined
in explicit storage.</p>
<p>Two semantics for sparse matrices are used in Scikit-learn:</p>
<dl class="simple">
<dt>matrix semantics</dt><dd><p>The sparse matrix is interpreted as an array with implicit and
explicit zeros being interpreted as the number 0.  This is the
interpretation most often adopted, e.g. when sparse matrices
are used for feature matrices or <a class="reference internal" href="#term-multilabel-indicator-matrices"><span class="xref std std-term">multilabel indicator
matrices</span></a>.</p>
</dd>
<dt>graph semantics</dt><dd><p>As with <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/sparse.csgraph.html#module-scipy.sparse.csgraph" title="(in SciPy v1.5.4)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">scipy.sparse.csgraph</span></code></a>, explicit zeros are
interpreted as the number 0, but implicit zeros indicate a masked
or absent value, such as the absence of an edge between two
vertices of a graph, where an explicit value indicates an edge’s
weight. This interpretation is adopted to represent connectivity
in clustering, in representations of nearest neighborhoods
(e.g. <a class="reference internal" href="modules/generated/sklearn.neighbors.kneighbors_graph.html#sklearn.neighbors.kneighbors_graph" title="sklearn.neighbors.kneighbors_graph"><code class="xref py py-func docutils literal notranslate"><span class="pre">neighbors.kneighbors_graph</span></code></a>), and for precomputed
distance representation where only distances in the neighborhood
of each point are required.</p>
</dd>
</dl>
<p>When working with sparse matrices, we assume that it is sparse for a
good reason, and avoid writing code that densifies a user-provided
sparse matrix, instead maintaining sparsity or raising an error if not
possible (i.e. if an estimator does not / cannot support sparse
matrices).</p>
</dd>
<dt id="term-supervised">supervised</dt><dt id="term-supervised-learning">supervised learning</dt><dd><p>Learning where the expected prediction (label or ground truth) is
available for each sample when <a class="reference internal" href="#term-fitting"><span class="xref std std-term">fitting</span></a> the model, provided as
<a class="reference internal" href="#term-y"><span class="xref std std-term">y</span></a>.  This is the approach taken in a <a class="reference internal" href="#term-classifier"><span class="xref std std-term">classifier</span></a> or
<a class="reference internal" href="#term-regressor"><span class="xref std std-term">regressor</span></a> among other estimators.</p>
</dd>
<dt id="term-target">target</dt><dt id="term-targets">targets</dt><dd><p>The <em>dependent variable</em> in <a class="reference internal" href="#term-supervised"><span class="xref std std-term">supervised</span></a> (and
<a class="reference internal" href="#term-semisupervised"><span class="xref std std-term">semisupervised</span></a>) learning, passed as <a class="reference internal" href="#term-y"><span class="xref std std-term">y</span></a> to an estimator’s
<a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a> method.  Also known as <em>dependent variable</em>, <em>outcome
variable</em>, <em>response variable</em>, <em>ground truth</em> or <em>label</em>. Scikit-learn
works with targets that have minimal structure: a class from a finite
set, a finite real-valued number, multiple classes, or multiple
numbers. See <a class="reference internal" href="#glossary-target-types"><span class="std std-ref">Target Types</span></a>.</p>
</dd>
<dt id="term-transduction">transduction</dt><dt id="term-transductive">transductive</dt><dd><p>A transductive (contrasted with <a class="reference internal" href="#term-inductive"><span class="xref std std-term">inductive</span></a>) machine learning
method is designed to model a specific dataset, but not to apply that
model to unseen data.  Examples include <a class="reference internal" href="modules/generated/sklearn.manifold.TSNE.html#sklearn.manifold.TSNE" title="sklearn.manifold.TSNE"><code class="xref py py-class docutils literal notranslate"><span class="pre">manifold.TSNE</span></code></a>,
<a class="reference internal" href="modules/generated/sklearn.cluster.AgglomerativeClustering.html#sklearn.cluster.AgglomerativeClustering" title="sklearn.cluster.AgglomerativeClustering"><code class="xref py py-class docutils literal notranslate"><span class="pre">cluster.AgglomerativeClustering</span></code></a> and
<a class="reference internal" href="modules/generated/sklearn.neighbors.LocalOutlierFactor.html#sklearn.neighbors.LocalOutlierFactor" title="sklearn.neighbors.LocalOutlierFactor"><code class="xref py py-class docutils literal notranslate"><span class="pre">neighbors.LocalOutlierFactor</span></code></a>.</p>
</dd>
<dt id="term-unlabeled">unlabeled</dt><dt id="term-unlabeled-data">unlabeled data</dt><dd><p>Samples with an unknown ground truth when fitting; equivalently,
<a class="reference internal" href="#term-missing-values"><span class="xref std std-term">missing values</span></a> in the <a class="reference internal" href="#term-target"><span class="xref std std-term">target</span></a>.  See also
<a class="reference internal" href="#term-semisupervised"><span class="xref std std-term">semisupervised</span></a> and <a class="reference internal" href="#term-unsupervised"><span class="xref std std-term">unsupervised</span></a> learning.</p>
</dd>
<dt id="term-unsupervised">unsupervised</dt><dt id="term-unsupervised-learning">unsupervised learning</dt><dd><p>Learning where the expected prediction (label or ground truth) is not
available for each sample when <a class="reference internal" href="#term-fitting"><span class="xref std std-term">fitting</span></a> the model, as in
<a class="reference internal" href="#term-clusterers"><span class="xref std std-term">clusterers</span></a> and <a class="reference internal" href="#term-outlier-detectors"><span class="xref std std-term">outlier detectors</span></a>.  Unsupervised
estimators ignore any <a class="reference internal" href="#term-y"><span class="xref std std-term">y</span></a> passed to <a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a>.</p>
</dd>
</dl>
</div>
<div class="section" id="class-apis-and-estimator-types">
<span id="glossary-estimator-types"></span><h2>Class APIs and Estimator Types<a class="headerlink" href="#class-apis-and-estimator-types" title="Permalink to this headline">¶</a></h2>
<dl class="glossary">
<dt id="term-classifier">classifier</dt><dt id="term-classifiers">classifiers</dt><dd><p>A <a class="reference internal" href="#term-supervised"><span class="xref std std-term">supervised</span></a> (or <a class="reference internal" href="#term-semi-supervised"><span class="xref std std-term">semi-supervised</span></a>) <a class="reference internal" href="#term-predictor"><span class="xref std std-term">predictor</span></a>
with a finite set of discrete possible output values.</p>
<p>A classifier supports modeling some of <a class="reference internal" href="#term-binary"><span class="xref std std-term">binary</span></a>,
<a class="reference internal" href="#term-multiclass"><span class="xref std std-term">multiclass</span></a>, <a class="reference internal" href="#term-multilabel"><span class="xref std std-term">multilabel</span></a>, or <a class="reference internal" href="#term-multiclass-multioutput"><span class="xref std std-term">multiclass
multioutput</span></a> targets.  Within scikit-learn, all classifiers support
multi-class classification, defaulting to using a one-vs-rest
strategy over the binary classification problem.</p>
<p>Classifiers must store a <a class="reference internal" href="#term-classes_"><span class="xref std std-term">classes_</span></a> attribute after fitting,
and usually inherit from <a class="reference internal" href="modules/generated/sklearn.base.ClassifierMixin.html#sklearn.base.ClassifierMixin" title="sklearn.base.ClassifierMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">base.ClassifierMixin</span></code></a>, which sets
their <a class="reference internal" href="#term-_estimator_type"><span class="xref std std-term">_estimator_type</span></a> attribute.</p>
<p>A classifier can be distinguished from other estimators with
<a class="reference internal" href="modules/generated/sklearn.base.is_classifier.html#sklearn.base.is_classifier" title="sklearn.base.is_classifier"><code class="xref py py-func docutils literal notranslate"><span class="pre">is_classifier</span></code></a>.</p>
<p>A classifier must implement:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a></p></li>
<li><p><a class="reference internal" href="#term-predict"><span class="xref std std-term">predict</span></a></p></li>
<li><p><a class="reference internal" href="#term-score"><span class="xref std std-term">score</span></a></p></li>
</ul>
<p>It may also be appropriate to implement <a class="reference internal" href="#term-decision_function"><span class="xref std std-term">decision_function</span></a>,
<a class="reference internal" href="#term-predict_proba"><span class="xref std std-term">predict_proba</span></a> and <a class="reference internal" href="#term-predict_log_proba"><span class="xref std std-term">predict_log_proba</span></a>.</p>
</dd>
<dt id="term-clusterer">clusterer</dt><dt id="term-clusterers">clusterers</dt><dd><p>A <a class="reference internal" href="#term-unsupervised"><span class="xref std std-term">unsupervised</span></a> <a class="reference internal" href="#term-predictor"><span class="xref std std-term">predictor</span></a> with a finite set of discrete
output values.</p>
<p>A clusterer usually stores <a class="reference internal" href="#term-labels_"><span class="xref std std-term">labels_</span></a> after fitting, and must do
so if it is <a class="reference internal" href="#term-transductive"><span class="xref std std-term">transductive</span></a>.</p>
<p>A clusterer must implement:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a></p></li>
<li><p><a class="reference internal" href="#term-fit_predict"><span class="xref std std-term">fit_predict</span></a> if <a class="reference internal" href="#term-transductive"><span class="xref std std-term">transductive</span></a></p></li>
<li><p><a class="reference internal" href="#term-predict"><span class="xref std std-term">predict</span></a> if <a class="reference internal" href="#term-inductive"><span class="xref std std-term">inductive</span></a></p></li>
</ul>
</dd>
<dt id="term-density-estimator">density estimator</dt><dd><p>TODO</p>
</dd>
<dt id="term-estimator">estimator</dt><dt id="term-estimators">estimators</dt><dd><p>An object which manages the estimation and decoding of a model. The
model is estimated as a deterministic function of:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#term-parameters"><span class="xref std std-term">parameters</span></a> provided in object construction or with
<a class="reference internal" href="#term-set_params"><span class="xref std std-term">set_params</span></a>;</p></li>
<li><p>the global <a class="reference external" href="https://numpy.org/doc/stable/reference/random/index.html#module-numpy.random" title="(in NumPy v1.19)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">numpy.random</span></code></a> random state if the estimator’s
<a class="reference internal" href="#term-random_state"><span class="xref std std-term">random_state</span></a> parameter is set to None; and</p></li>
<li><p>any data or <a class="reference internal" href="#term-sample-properties"><span class="xref std std-term">sample properties</span></a> passed to the most recent
call to <a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a>, <a class="reference internal" href="#term-fit_transform"><span class="xref std std-term">fit_transform</span></a> or <a class="reference internal" href="#term-fit_predict"><span class="xref std std-term">fit_predict</span></a>,
or data similarly passed in a sequence of calls to
<a class="reference internal" href="#term-partial_fit"><span class="xref std std-term">partial_fit</span></a>.</p></li>
</ul>
<p>The estimated model is stored in public and private <a class="reference internal" href="#term-attributes"><span class="xref std std-term">attributes</span></a>
on the estimator instance, facilitating decoding through prediction
and transformation methods.</p>
<p>Estimators must provide a <a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a> method, and should provide
<a class="reference internal" href="#term-set_params"><span class="xref std std-term">set_params</span></a> and <a class="reference internal" href="#term-get_params"><span class="xref std std-term">get_params</span></a>, although these are usually
provided by inheritance from <a class="reference internal" href="modules/generated/sklearn.base.BaseEstimator.html#sklearn.base.BaseEstimator" title="sklearn.base.BaseEstimator"><code class="xref py py-class docutils literal notranslate"><span class="pre">base.BaseEstimator</span></code></a>.</p>
<p>The core functionality of some estimators may also be available as a
<a class="reference internal" href="#term-function"><span class="xref std std-term">function</span></a>.</p>
</dd>
<dt id="term-feature-extractor">feature extractor</dt><dt id="term-feature-extractors">feature extractors</dt><dd><p>A <a class="reference internal" href="#term-transformer"><span class="xref std std-term">transformer</span></a> which takes input where each sample is not
represented as an <a class="reference internal" href="#term-array-like"><span class="xref std std-term">array-like</span></a> object of fixed length, and
produces an <a class="reference internal" href="#term-array-like"><span class="xref std std-term">array-like</span></a> object of <a class="reference internal" href="#term-features"><span class="xref std std-term">features</span></a> for each
sample (and thus a 2-dimensional array-like for a set of samples).  In
other words, it (lossily) maps a non-rectangular data representation
into <a class="reference internal" href="#term-rectangular"><span class="xref std std-term">rectangular</span></a> data.</p>
<p>Feature extractors must implement at least:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a></p></li>
<li><p><a class="reference internal" href="#term-transform"><span class="xref std std-term">transform</span></a></p></li>
<li><p><a class="reference internal" href="#term-get_feature_names"><span class="xref std std-term">get_feature_names</span></a></p></li>
</ul>
</dd>
<dt id="term-meta-estimator">meta-estimator</dt><dt id="term-meta-estimators">meta-estimators</dt><dt id="term-metaestimator">metaestimator</dt><dt id="term-metaestimators">metaestimators</dt><dd><p>An <a class="reference internal" href="#term-estimator"><span class="xref std std-term">estimator</span></a> which takes another estimator as a parameter.
Examples include <a class="reference internal" href="modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">pipeline.Pipeline</span></code></a>,
<a class="reference internal" href="modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV" title="sklearn.model_selection.GridSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">model_selection.GridSearchCV</span></code></a>,
<a class="reference internal" href="modules/generated/sklearn.feature_selection.SelectFromModel.html#sklearn.feature_selection.SelectFromModel" title="sklearn.feature_selection.SelectFromModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">feature_selection.SelectFromModel</span></code></a> and
<a class="reference internal" href="modules/generated/sklearn.ensemble.BaggingClassifier.html#sklearn.ensemble.BaggingClassifier" title="sklearn.ensemble.BaggingClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">ensemble.BaggingClassifier</span></code></a>.</p>
<p>In a meta-estimator’s <a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a> method, any contained estimators
should be <a class="reference internal" href="#term-cloned"><span class="xref std std-term">cloned</span></a> before they are fit (although FIXME: Pipeline
and FeatureUnion do not do this currently). An exception to this is
that an estimator may explicitly document that it accepts a pre-fitted
estimator (e.g. using <code class="docutils literal notranslate"><span class="pre">prefit=True</span></code> in
<a class="reference internal" href="modules/generated/sklearn.feature_selection.SelectFromModel.html#sklearn.feature_selection.SelectFromModel" title="sklearn.feature_selection.SelectFromModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">feature_selection.SelectFromModel</span></code></a>). One known issue with this
is that the pre-fitted estimator will lose its model if the
meta-estimator is cloned.  A meta-estimator should have <code class="docutils literal notranslate"><span class="pre">fit</span></code> called
before prediction, even if all contained estimators are pre-fitted.</p>
<p>In cases where a meta-estimator’s primary behaviors (e.g.
<a class="reference internal" href="#term-predict"><span class="xref std std-term">predict</span></a> or <a class="reference internal" href="#term-transform"><span class="xref std std-term">transform</span></a> implementation) are functions of
prediction/transformation methods of the provided <em>base estimator</em> (or
multiple base estimators), a meta-estimator should provide at least the
standard methods provided by the base estimator.  It may not be
possible to identify which methods are provided by the underlying
estimator until the meta-estimator has been <a class="reference internal" href="#term-fitted"><span class="xref std std-term">fitted</span></a> (see also
<a class="reference internal" href="#term-duck-typing"><span class="xref std std-term">duck typing</span></a>), for which
<a class="reference internal" href="modules/generated/sklearn.utils.metaestimators.if_delegate_has_method.html#sklearn.utils.metaestimators.if_delegate_has_method" title="sklearn.utils.metaestimators.if_delegate_has_method"><code class="xref py py-func docutils literal notranslate"><span class="pre">utils.metaestimators.if_delegate_has_method</span></code></a> may help.  It
should also provide (or modify) the <a class="reference internal" href="#term-estimator-tags"><span class="xref std std-term">estimator tags</span></a> and
<a class="reference internal" href="#term-classes_"><span class="xref std std-term">classes_</span></a> attribute provided by the base estimator.</p>
<p>Meta-estimators should be careful to validate data as minimally as
possible before passing it to an underlying estimator. This saves
computation time, and may, for instance, allow the underlying
estimator to easily work with data that is not <a class="reference internal" href="#term-rectangular"><span class="xref std std-term">rectangular</span></a>.</p>
</dd>
<dt id="term-outlier-detector">outlier detector</dt><dt id="term-outlier-detectors">outlier detectors</dt><dd><p>An <a class="reference internal" href="#term-unsupervised"><span class="xref std std-term">unsupervised</span></a> binary <a class="reference internal" href="#term-predictor"><span class="xref std std-term">predictor</span></a> which models the
distinction between core and outlying samples.</p>
<p>Outlier detectors must implement:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a></p></li>
<li><p><a class="reference internal" href="#term-fit_predict"><span class="xref std std-term">fit_predict</span></a> if <a class="reference internal" href="#term-transductive"><span class="xref std std-term">transductive</span></a></p></li>
<li><p><a class="reference internal" href="#term-predict"><span class="xref std std-term">predict</span></a> if <a class="reference internal" href="#term-inductive"><span class="xref std std-term">inductive</span></a></p></li>
</ul>
<p>Inductive outlier detectors may also implement
<a class="reference internal" href="#term-decision_function"><span class="xref std std-term">decision_function</span></a> to give a normalized inlier score where
outliers have score below 0.  <a class="reference internal" href="#term-score_samples"><span class="xref std std-term">score_samples</span></a> may provide an
unnormalized score per sample.</p>
</dd>
<dt id="term-predictor">predictor</dt><dt id="term-predictors">predictors</dt><dd><p>An <a class="reference internal" href="#term-estimator"><span class="xref std std-term">estimator</span></a> supporting <a class="reference internal" href="#term-predict"><span class="xref std std-term">predict</span></a> and/or
<a class="reference internal" href="#term-fit_predict"><span class="xref std std-term">fit_predict</span></a>. This encompasses <a class="reference internal" href="#term-classifier"><span class="xref std std-term">classifier</span></a>,
<a class="reference internal" href="#term-regressor"><span class="xref std std-term">regressor</span></a>, <a class="reference internal" href="#term-outlier-detector"><span class="xref std std-term">outlier detector</span></a> and <a class="reference internal" href="#term-clusterer"><span class="xref std std-term">clusterer</span></a>.</p>
<p>In statistics, “predictors” refers to <a class="reference internal" href="#term-features"><span class="xref std std-term">features</span></a>.</p>
</dd>
<dt id="term-regressor">regressor</dt><dt id="term-regressors">regressors</dt><dd><p>A <a class="reference internal" href="#term-supervised"><span class="xref std std-term">supervised</span></a> (or <a class="reference internal" href="#term-semi-supervised"><span class="xref std std-term">semi-supervised</span></a>) <a class="reference internal" href="#term-predictor"><span class="xref std std-term">predictor</span></a>
with <a class="reference internal" href="#term-continuous"><span class="xref std std-term">continuous</span></a> output values.</p>
<p>Regressors usually inherit from <a class="reference internal" href="modules/generated/sklearn.base.RegressorMixin.html#sklearn.base.RegressorMixin" title="sklearn.base.RegressorMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">base.RegressorMixin</span></code></a>, which
sets their <a class="reference internal" href="#term-_estimator_type"><span class="xref std std-term">_estimator_type</span></a> attribute.</p>
<p>A regressor can be distinguished from other estimators with
<a class="reference internal" href="modules/generated/sklearn.base.is_regressor.html#sklearn.base.is_regressor" title="sklearn.base.is_regressor"><code class="xref py py-func docutils literal notranslate"><span class="pre">is_regressor</span></code></a>.</p>
<p>A regressor must implement:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a></p></li>
<li><p><a class="reference internal" href="#term-predict"><span class="xref std std-term">predict</span></a></p></li>
<li><p><a class="reference internal" href="#term-score"><span class="xref std std-term">score</span></a></p></li>
</ul>
</dd>
<dt id="term-transformer">transformer</dt><dt id="term-transformers">transformers</dt><dd><p>An estimator supporting <a class="reference internal" href="#term-transform"><span class="xref std std-term">transform</span></a> and/or <a class="reference internal" href="#term-fit_transform"><span class="xref std std-term">fit_transform</span></a>.
A purely <a class="reference internal" href="#term-transductive"><span class="xref std std-term">transductive</span></a> transformer, such as
<a class="reference internal" href="modules/generated/sklearn.manifold.TSNE.html#sklearn.manifold.TSNE" title="sklearn.manifold.TSNE"><code class="xref py py-class docutils literal notranslate"><span class="pre">manifold.TSNE</span></code></a>, may not implement <code class="docutils literal notranslate"><span class="pre">transform</span></code>.</p>
</dd>
<dt id="term-vectorizer">vectorizer</dt><dt id="term-vectorizers">vectorizers</dt><dd><p>See <a class="reference internal" href="#term-feature-extractor"><span class="xref std std-term">feature extractor</span></a>.</p>
</dd>
</dl>
<p>There are further APIs specifically related to a small family of estimators,
such as:</p>
<dl class="glossary simple">
<dt id="term-cross-validation-splitter">cross-validation splitter</dt><dt id="term-CV-splitter">CV splitter</dt><dt id="term-cross-validation-generator">cross-validation generator</dt><dd><p>A non-estimator family of classes used to split a dataset into a
sequence of train and test portions (see <a class="reference internal" href="modules/cross_validation.html#cross-validation"><span class="std std-ref">Cross-validation: evaluating estimator performance</span></a>),
by providing <a class="reference internal" href="#term-split"><span class="xref std std-term">split</span></a> and <a class="reference internal" href="#term-get_n_splits"><span class="xref std std-term">get_n_splits</span></a> methods.
Note that unlike estimators, these do not have <a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a> methods
and do not provide <a class="reference internal" href="#term-set_params"><span class="xref std std-term">set_params</span></a> or <a class="reference internal" href="#term-get_params"><span class="xref std std-term">get_params</span></a>.
Parameter validation may be performed in <code class="docutils literal notranslate"><span class="pre">__init__</span></code>.</p>
</dd>
<dt id="term-cross-validation-estimator">cross-validation estimator</dt><dd><p>An estimator that has built-in cross-validation capabilities to
automatically select the best hyper-parameters (see the <a class="reference internal" href="modules/grid_search.html#grid-search"><span class="std std-ref">User
Guide</span></a>). Some example of cross-validation estimators
are <a class="reference internal" href="modules/generated/sklearn.linear_model.ElasticNetCV.html#sklearn.linear_model.ElasticNetCV" title="sklearn.linear_model.ElasticNetCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">ElasticNetCV</span></code></a> and
<a class="reference internal" href="modules/generated/sklearn.linear_model.LogisticRegressionCV.html#sklearn.linear_model.LogisticRegressionCV" title="sklearn.linear_model.LogisticRegressionCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">LogisticRegressionCV</span></code></a>.
Cross-validation estimators are named <code class="docutils literal notranslate"><span class="pre">EstimatorCV</span></code> and tend to be
roughly equivalent to <code class="docutils literal notranslate"><span class="pre">GridSearchCV(Estimator(),</span> <span class="pre">...)</span></code>. The
advantage of using a cross-validation estimator over the canonical
<a class="reference internal" href="#term-estimator"><span class="xref std std-term">Estimator</span></a> class along with <a class="reference internal" href="modules/grid_search.html#grid-search"><span class="std std-ref">grid search</span></a> is
that they can take advantage of warm-starting by reusing precomputed
results in the previous steps of the cross-validation process. This
generally leads to speed improvements. An exception is the
<a class="reference internal" href="modules/generated/sklearn.linear_model.RidgeCV.html#sklearn.linear_model.RidgeCV" title="sklearn.linear_model.RidgeCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">RidgeCV</span></code></a> class, which can instead
perform efficient Leave-One-Out CV.</p>
</dd>
<dt id="term-scorer">scorer</dt><dd><p>A non-estimator callable object which evaluates an estimator on given
test data, returning a number. Unlike <a class="reference internal" href="#term-evaluation-metrics"><span class="xref std std-term">evaluation metrics</span></a>,
a greater returned number must correspond with a <em>better</em> score.
See <a class="reference internal" href="modules/model_evaluation.html#scoring-parameter"><span class="std std-ref">The scoring parameter: defining model evaluation rules</span></a>.</p>
</dd>
</dl>
<p>Further examples:</p>
<ul class="simple">
<li><p><a class="reference internal" href="modules/generated/sklearn.neighbors.DistanceMetric.html#sklearn.neighbors.DistanceMetric" title="sklearn.neighbors.DistanceMetric"><code class="xref py py-class docutils literal notranslate"><span class="pre">neighbors.DistanceMetric</span></code></a></p></li>
<li><p><a class="reference internal" href="modules/generated/sklearn.gaussian_process.kernels.Kernel.html#sklearn.gaussian_process.kernels.Kernel" title="sklearn.gaussian_process.kernels.Kernel"><code class="xref py py-class docutils literal notranslate"><span class="pre">gaussian_process.kernels.Kernel</span></code></a></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tree.Criterion</span></code></p></li>
</ul>
</div>
<div class="section" id="target-types">
<span id="glossary-target-types"></span><h2>Target Types<a class="headerlink" href="#target-types" title="Permalink to this headline">¶</a></h2>
<dl class="glossary">
<dt id="term-binary">binary</dt><dd><p>A classification problem consisting of two classes.  A binary target
may  be represented as for a <a class="reference internal" href="#term-multiclass"><span class="xref std std-term">multiclass</span></a> problem but with only two
labels.  A binary decision function is represented as a 1d array.</p>
<p>Semantically, one class is often considered the “positive” class.
Unless otherwise specified (e.g. using <a class="reference internal" href="#term-pos_label"><span class="xref std std-term">pos_label</span></a> in
<a class="reference internal" href="#term-evaluation-metrics"><span class="xref std std-term">evaluation metrics</span></a>), we consider the class label with the
greater value (numerically or lexicographically) as the positive class:
of labels [0, 1], 1 is the positive class; of [1, 2], 2 is the positive
class; of [‘no’, ‘yes’], ‘yes’ is the positive class; of [‘no’, ‘YES’],
‘no’ is the positive class.  This affects the output of
<a class="reference internal" href="#term-decision_function"><span class="xref std std-term">decision_function</span></a>, for instance.</p>
<p>Note that a dataset sampled from a multiclass <code class="docutils literal notranslate"><span class="pre">y</span></code> or a continuous
<code class="docutils literal notranslate"><span class="pre">y</span></code> may appear to be binary.</p>
<p><a class="reference internal" href="modules/generated/sklearn.utils.multiclass.type_of_target.html#sklearn.utils.multiclass.type_of_target" title="sklearn.utils.multiclass.type_of_target"><code class="xref py py-func docutils literal notranslate"><span class="pre">type_of_target</span></code></a> will return ‘binary’ for
binary input, or a similar array with only a single class present.</p>
</dd>
<dt id="term-continuous">continuous</dt><dd><p>A regression problem where each sample’s target is a finite floating
point number represented as a 1-dimensional array of floats (or
sometimes ints).</p>
<p><a class="reference internal" href="modules/generated/sklearn.utils.multiclass.type_of_target.html#sklearn.utils.multiclass.type_of_target" title="sklearn.utils.multiclass.type_of_target"><code class="xref py py-func docutils literal notranslate"><span class="pre">type_of_target</span></code></a> will return ‘continuous’ for
continuous input, but if the data is all integers, it will be
identified as ‘multiclass’.</p>
</dd>
<dt id="term-continuous-multioutput">continuous multioutput</dt><dt id="term-multioutput-continuous">multioutput continuous</dt><dd><p>A regression problem where each sample’s target consists of <code class="docutils literal notranslate"><span class="pre">n_outputs</span></code>
<a class="reference internal" href="#term-outputs"><span class="xref std std-term">outputs</span></a>, each one a finite floating point number, for a
fixed int <code class="docutils literal notranslate"><span class="pre">n_outputs</span> <span class="pre">&gt;</span> <span class="pre">1</span></code> in a particular dataset.</p>
<p>Continuous multioutput targets are represented as multiple
<a class="reference internal" href="#term-continuous"><span class="xref std std-term">continuous</span></a> targets, horizontally stacked into an array
of shape <code class="docutils literal notranslate"><span class="pre">(n_samples,</span> <span class="pre">n_outputs)</span></code>.</p>
<p><a class="reference internal" href="modules/generated/sklearn.utils.multiclass.type_of_target.html#sklearn.utils.multiclass.type_of_target" title="sklearn.utils.multiclass.type_of_target"><code class="xref py py-func docutils literal notranslate"><span class="pre">type_of_target</span></code></a> will return
‘continuous-multioutput’ for continuous multioutput input, but if the
data is all integers, it will be identified as
‘multiclass-multioutput’.</p>
</dd>
<dt id="term-multiclass">multiclass</dt><dd><p>A classification problem consisting of more than two classes.  A
multiclass target may be represented as a 1-dimensional array of
strings or integers.  A 2d column vector of integers (i.e. a
single output in <a class="reference internal" href="#term-multioutput"><span class="xref std std-term">multioutput</span></a> terms) is also accepted.</p>
<p>We do not officially support other orderable, hashable objects as class
labels, even if estimators may happen to work when given classification
targets of such type.</p>
<p>For semi-supervised classification, <a class="reference internal" href="#term-unlabeled"><span class="xref std std-term">unlabeled</span></a> samples should
have the special label -1 in <code class="docutils literal notranslate"><span class="pre">y</span></code>.</p>
<p>Within sckit-learn, all estimators supporting binary classification
also support multiclass classification, using One-vs-Rest by default.</p>
<p>A <a class="reference internal" href="modules/generated/sklearn.preprocessing.LabelEncoder.html#sklearn.preprocessing.LabelEncoder" title="sklearn.preprocessing.LabelEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">preprocessing.LabelEncoder</span></code></a> helps to canonicalize multiclass
targets as integers.</p>
<p><a class="reference internal" href="modules/generated/sklearn.utils.multiclass.type_of_target.html#sklearn.utils.multiclass.type_of_target" title="sklearn.utils.multiclass.type_of_target"><code class="xref py py-func docutils literal notranslate"><span class="pre">type_of_target</span></code></a> will return ‘multiclass’ for
multiclass input. The user may also want to handle ‘binary’ input
identically to ‘multiclass’.</p>
</dd>
<dt id="term-multiclass-multioutput">multiclass multioutput</dt><dt id="term-multioutput-multiclass">multioutput multiclass</dt><dd><p>A classification problem where each sample’s target consists of
<code class="docutils literal notranslate"><span class="pre">n_outputs</span></code> <a class="reference internal" href="#term-outputs"><span class="xref std std-term">outputs</span></a>, each a class label, for a fixed int
<code class="docutils literal notranslate"><span class="pre">n_outputs</span> <span class="pre">&gt;</span> <span class="pre">1</span></code> in a particular dataset.  Each output has a
fixed set of available classes, and each sample is labeled with a
class for each output. An output may be binary or multiclass, and in
the case where all outputs are binary, the target is
<a class="reference internal" href="#term-multilabel"><span class="xref std std-term">multilabel</span></a>.</p>
<p>Multiclass multioutput targets are represented as multiple
<a class="reference internal" href="#term-multiclass"><span class="xref std std-term">multiclass</span></a> targets, horizontally stacked into an array
of shape <code class="docutils literal notranslate"><span class="pre">(n_samples,</span> <span class="pre">n_outputs)</span></code>.</p>
<p>XXX: For simplicity, we may not always support string class labels
for multiclass multioutput, and integer class labels should be used.</p>
<p><code class="xref py py-mod docutils literal notranslate"><span class="pre">multioutput</span></code> provides estimators which estimate multi-output
problems using multiple single-output estimators.  This may not fully
account for dependencies among the different outputs, which methods
natively handling the multioutput case (e.g. decision trees, nearest
neighbors, neural networks) may do better.</p>
<p><a class="reference internal" href="modules/generated/sklearn.utils.multiclass.type_of_target.html#sklearn.utils.multiclass.type_of_target" title="sklearn.utils.multiclass.type_of_target"><code class="xref py py-func docutils literal notranslate"><span class="pre">type_of_target</span></code></a> will return
‘multiclass-multioutput’ for multiclass multioutput input.</p>
</dd>
<dt id="term-multilabel">multilabel</dt><dd><p>A <a class="reference internal" href="#term-multiclass-multioutput"><span class="xref std std-term">multiclass multioutput</span></a> target where each output is
<a class="reference internal" href="#term-binary"><span class="xref std std-term">binary</span></a>.  This may be represented as a 2d (dense) array or
sparse matrix of integers, such that each column is a separate binary
target, where positive labels are indicated with 1 and negative labels
are usually -1 or 0.  Sparse multilabel targets are not supported
everywhere that dense multilabel targets are supported.</p>
<p>Semantically, a multilabel target can be thought of as a set of labels
for each sample.  While not used internally,
<a class="reference internal" href="modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html#sklearn.preprocessing.MultiLabelBinarizer" title="sklearn.preprocessing.MultiLabelBinarizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">preprocessing.MultiLabelBinarizer</span></code></a> is provided as a utility to
convert from a list of sets representation to a 2d array or sparse
matrix. One-hot encoding a multiclass target with
<a class="reference internal" href="modules/generated/sklearn.preprocessing.LabelBinarizer.html#sklearn.preprocessing.LabelBinarizer" title="sklearn.preprocessing.LabelBinarizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">preprocessing.LabelBinarizer</span></code></a> turns it into a multilabel
problem.</p>
<p><a class="reference internal" href="modules/generated/sklearn.utils.multiclass.type_of_target.html#sklearn.utils.multiclass.type_of_target" title="sklearn.utils.multiclass.type_of_target"><code class="xref py py-func docutils literal notranslate"><span class="pre">type_of_target</span></code></a> will return
‘multilabel-indicator’ for multilabel input, whether sparse or dense.</p>
</dd>
<dt id="term-multioutput">multioutput</dt><dt id="term-multi-output">multi-output</dt><dd><p>A target where each sample has multiple classification/regression
labels. See <a class="reference internal" href="#term-multiclass-multioutput"><span class="xref std std-term">multiclass multioutput</span></a> and <a class="reference internal" href="#term-continuous-multioutput"><span class="xref std std-term">continuous
multioutput</span></a>. We do not currently support modelling mixed
classification and regression targets.</p>
</dd>
</dl>
</div>
<div class="section" id="methods">
<span id="glossary-methods"></span><h2>Methods<a class="headerlink" href="#methods" title="Permalink to this headline">¶</a></h2>
<dl class="glossary">
<dt id="term-decision_function"><code class="docutils literal notranslate"><span class="pre">decision_function</span></code></dt><dd><p>In a fitted <a class="reference internal" href="#term-classifier"><span class="xref std std-term">classifier</span></a> or <a class="reference internal" href="#term-outlier-detector"><span class="xref std std-term">outlier detector</span></a>, predicts a
“soft” score for each sample in relation to each class, rather than the
“hard” categorical prediction produced by <a class="reference internal" href="#term-predict"><span class="xref std std-term">predict</span></a>.  Its input
is usually only some observed data, <a class="reference internal" href="#term-X"><span class="xref std std-term">X</span></a>.</p>
<p>If the estimator was not already <a class="reference internal" href="#term-fitted"><span class="xref std std-term">fitted</span></a>, calling this method
should raise a <a class="reference internal" href="modules/generated/sklearn.exceptions.NotFittedError.html#sklearn.exceptions.NotFittedError" title="sklearn.exceptions.NotFittedError"><code class="xref py py-class docutils literal notranslate"><span class="pre">exceptions.NotFittedError</span></code></a>.</p>
<p>Output conventions:</p>
<dl>
<dt>binary classification</dt><dd><p>A 1-dimensional array, where values strictly greater than zero
indicate the positive class (i.e. the last class in
<a class="reference internal" href="#term-classes_"><span class="xref std std-term">classes_</span></a>).</p>
</dd>
<dt>multiclass classification</dt><dd><p>A 2-dimensional array, where the row-wise arg-maximum is the
predicted class.  Columns are ordered according to
<a class="reference internal" href="#term-classes_"><span class="xref std std-term">classes_</span></a>.</p>
</dd>
<dt>multilabel classification</dt><dd><p>Scikit-learn is inconsistent in its representation of multilabel
decision functions.  Some estimators represent it like multiclass
multioutput, i.e. a list of 2d arrays, each with two columns. Others
represent it with a single 2d array, whose columns correspond to
the individual binary classification decisions. The latter
representation is ambiguously identical to the multiclass
classification format, though its semantics differ: it should be
interpreted, like in the binary case, by thresholding at 0.</p>
<p>TODO: <a class="reference external" href="https://gist.github.com/jnothman/4807b1b0266613c20ba4d1f88d0f8cf5">This gist</a>
highlights the use of the different formats for multilabel.</p>
</dd>
<dt>multioutput classification</dt><dd><p>A list of 2d arrays, corresponding to each multiclass decision
function.</p>
</dd>
<dt>outlier detection</dt><dd><p>A 1-dimensional array, where a value greater than or equal to zero
indicates an inlier.</p>
</dd>
</dl>
</dd>
<dt id="term-fit"><code class="docutils literal notranslate"><span class="pre">fit</span></code></dt><dd><p>The <code class="docutils literal notranslate"><span class="pre">fit</span></code> method is provided on every estimator. It usually takes some
<a class="reference internal" href="#term-samples"><span class="xref std std-term">samples</span></a> <code class="docutils literal notranslate"><span class="pre">X</span></code>, <a class="reference internal" href="#term-targets"><span class="xref std std-term">targets</span></a> <code class="docutils literal notranslate"><span class="pre">y</span></code> if the model is supervised,
and potentially other <a class="reference internal" href="#term-sample-properties"><span class="xref std std-term">sample properties</span></a> such as
<a class="reference internal" href="#term-sample_weight"><span class="xref std std-term">sample_weight</span></a>.  It should:</p>
<ul class="simple">
<li><p>clear any prior <a class="reference internal" href="#term-attributes"><span class="xref std std-term">attributes</span></a> stored on the estimator, unless
<a class="reference internal" href="#term-warm_start"><span class="xref std std-term">warm_start</span></a> is used;</p></li>
<li><p>validate and interpret any <a class="reference internal" href="#term-parameters"><span class="xref std std-term">parameters</span></a>, ideally raising an
error if invalid;</p></li>
<li><p>validate the input data;</p></li>
<li><p>estimate and store model attributes from the estimated parameters and
provided data; and</p></li>
<li><p>return the now <a class="reference internal" href="#term-fitted"><span class="xref std std-term">fitted</span></a> estimator to facilitate method
chaining.</p></li>
</ul>
<p><a class="reference internal" href="#glossary-target-types"><span class="std std-ref">Target Types</span></a> describes possible formats for <code class="docutils literal notranslate"><span class="pre">y</span></code>.</p>
</dd>
<dt id="term-fit_predict"><code class="docutils literal notranslate"><span class="pre">fit_predict</span></code></dt><dd><p>Used especially for <a class="reference internal" href="#term-unsupervised"><span class="xref std std-term">unsupervised</span></a>, <a class="reference internal" href="#term-transductive"><span class="xref std std-term">transductive</span></a>
estimators, this fits the model and returns the predictions (similar to
<a class="reference internal" href="#term-predict"><span class="xref std std-term">predict</span></a>) on the training data. In clusterers, these predictions
are also stored in the <a class="reference internal" href="#term-labels_"><span class="xref std std-term">labels_</span></a> attribute, and the output of
<code class="docutils literal notranslate"><span class="pre">.fit_predict(X)</span></code> is usually equivalent to <code class="docutils literal notranslate"><span class="pre">.fit(X).predict(X)</span></code>.
The parameters to <code class="docutils literal notranslate"><span class="pre">fit_predict</span></code> are the same as those to <code class="docutils literal notranslate"><span class="pre">fit</span></code>.</p>
</dd>
<dt id="term-fit_transform"><code class="docutils literal notranslate"><span class="pre">fit_transform</span></code></dt><dd><p>A method on <a class="reference internal" href="#term-transformers"><span class="xref std std-term">transformers</span></a> which fits the estimator and returns
the transformed training data. It takes parameters as in <a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a>
and its output should have the same shape as calling <code class="docutils literal notranslate"><span class="pre">.fit(X,</span>
<span class="pre">...).transform(X)</span></code>. There are nonetheless rare cases where
<code class="docutils literal notranslate"><span class="pre">.fit_transform(X,</span> <span class="pre">...)</span></code> and <code class="docutils literal notranslate"><span class="pre">.fit(X,</span> <span class="pre">...).transform(X)</span></code> do not
return the same value, wherein training data needs to be handled
differently (due to model blending in stacked ensembles, for instance;
such cases should be clearly documented).
<a class="reference internal" href="#term-transductive"><span class="xref std std-term">Transductive</span></a> transformers may also provide <code class="docutils literal notranslate"><span class="pre">fit_transform</span></code>
but not <a class="reference internal" href="#term-transform"><span class="xref std std-term">transform</span></a>.</p>
<p>One reason to implement <code class="docutils literal notranslate"><span class="pre">fit_transform</span></code> is that performing <code class="docutils literal notranslate"><span class="pre">fit</span></code>
and <code class="docutils literal notranslate"><span class="pre">transform</span></code> separately would be less efficient than together.
<a class="reference internal" href="modules/generated/sklearn.base.TransformerMixin.html#sklearn.base.TransformerMixin" title="sklearn.base.TransformerMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">base.TransformerMixin</span></code></a> provides a default implementation,
providing a consistent interface across transformers where
<code class="docutils literal notranslate"><span class="pre">fit_transform</span></code> is or is not specialized.</p>
<p>In <a class="reference internal" href="#term-inductive"><span class="xref std std-term">inductive</span></a> learning – where the goal is to learn a
generalized model that can be applied to new data – users should be
careful not to apply <code class="docutils literal notranslate"><span class="pre">fit_transform</span></code> to the entirety of a dataset
(i.e. training and test data together) before further modelling, as
this results in <a class="reference internal" href="#term-data-leakage"><span class="xref std std-term">data leakage</span></a>.</p>
</dd>
<dt id="term-get_feature_names"><code class="docutils literal notranslate"><span class="pre">get_feature_names</span></code></dt><dd><p>Primarily for <a class="reference internal" href="#term-feature-extractors"><span class="xref std std-term">feature extractors</span></a>, but also used for other
transformers to provide string names for each column in the output of
the estimator’s <a class="reference internal" href="#term-transform"><span class="xref std std-term">transform</span></a> method.  It outputs a list of
strings and may take a list of strings as input, corresponding
to the names of input columns from which output column names can
be generated.  By default input features are named x0, x1, ….</p>
</dd>
<dt id="term-get_n_splits"><code class="docutils literal notranslate"><span class="pre">get_n_splits</span></code></dt><dd><p>On a <a class="reference internal" href="#term-CV-splitter"><span class="xref std std-term">CV splitter</span></a> (not an estimator), returns the number of
elements one would get if iterating through the return value of
<a class="reference internal" href="#term-split"><span class="xref std std-term">split</span></a> given the same parameters.  Takes the same parameters as
split.</p>
</dd>
<dt id="term-get_params"><code class="docutils literal notranslate"><span class="pre">get_params</span></code></dt><dd><p>Gets all <a class="reference internal" href="#term-parameters"><span class="xref std std-term">parameters</span></a>, and their values, that can be set using
<a class="reference internal" href="#term-set_params"><span class="xref std std-term">set_params</span></a>.  A parameter <code class="docutils literal notranslate"><span class="pre">deep</span></code> can be used, when set to
False to only return those parameters not including <code class="docutils literal notranslate"><span class="pre">__</span></code>, i.e.  not
due to indirection via contained estimators.</p>
<p>Most estimators adopt the definition from <a class="reference internal" href="modules/generated/sklearn.base.BaseEstimator.html#sklearn.base.BaseEstimator" title="sklearn.base.BaseEstimator"><code class="xref py py-class docutils literal notranslate"><span class="pre">base.BaseEstimator</span></code></a>,
which simply adopts the parameters defined for <code class="docutils literal notranslate"><span class="pre">__init__</span></code>.
<a class="reference internal" href="modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">pipeline.Pipeline</span></code></a>, among others, reimplements <code class="docutils literal notranslate"><span class="pre">get_params</span></code>
to declare the estimators named in its <code class="docutils literal notranslate"><span class="pre">steps</span></code> parameters as
themselves being parameters.</p>
</dd>
<dt id="term-partial_fit"><code class="docutils literal notranslate"><span class="pre">partial_fit</span></code></dt><dd><p>Facilitates fitting an estimator in an online fashion.  Unlike <code class="docutils literal notranslate"><span class="pre">fit</span></code>,
repeatedly calling <code class="docutils literal notranslate"><span class="pre">partial_fit</span></code> does not clear the model, but
updates it with the data provided. The portion of data
provided to <code class="docutils literal notranslate"><span class="pre">partial_fit</span></code> may be called a mini-batch.
Each mini-batch must be of consistent shape, etc. In iterative
estimators, <code class="docutils literal notranslate"><span class="pre">partial_fit</span></code> often only performs a single iteration.</p>
<p><code class="docutils literal notranslate"><span class="pre">partial_fit</span></code> may also be used for <a class="reference internal" href="#term-out-of-core"><span class="xref std std-term">out-of-core</span></a> learning,
although usually limited to the case where learning can be performed
online, i.e. the model is usable after each <code class="docutils literal notranslate"><span class="pre">partial_fit</span></code> and there
is no separate processing needed to finalize the model.
<a class="reference internal" href="modules/generated/sklearn.cluster.Birch.html#sklearn.cluster.Birch" title="sklearn.cluster.Birch"><code class="xref py py-class docutils literal notranslate"><span class="pre">cluster.Birch</span></code></a> introduces the convention that calling
<code class="docutils literal notranslate"><span class="pre">partial_fit(X)</span></code> will produce a model that is not finalized, but the
model can be finalized by calling <code class="docutils literal notranslate"><span class="pre">partial_fit()</span></code> i.e. without
passing a further mini-batch.</p>
<p>Generally, estimator parameters should not be modified between calls
to <code class="docutils literal notranslate"><span class="pre">partial_fit</span></code>, although <code class="docutils literal notranslate"><span class="pre">partial_fit</span></code> should validate them
as well as the new mini-batch of data.  In contrast, <code class="docutils literal notranslate"><span class="pre">warm_start</span></code>
is used to repeatedly fit the same estimator with the same data
but varying parameters.</p>
<p>Like <code class="docutils literal notranslate"><span class="pre">fit</span></code>, <code class="docutils literal notranslate"><span class="pre">partial_fit</span></code> should return the estimator object.</p>
<p>To clear the model, a new estimator should be constructed, for instance
with <a class="reference internal" href="modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone"><code class="xref py py-func docutils literal notranslate"><span class="pre">base.clone</span></code></a>.</p>
<p>NOTE: Using <code class="docutils literal notranslate"><span class="pre">partial_fit</span></code> after <code class="docutils literal notranslate"><span class="pre">fit</span></code> results in undefined behavior.</p>
</dd>
<dt id="term-predict"><code class="docutils literal notranslate"><span class="pre">predict</span></code></dt><dd><p>Makes a prediction for each sample, usually only taking <a class="reference internal" href="#term-X"><span class="xref std std-term">X</span></a> as
input (but see under regressor output conventions below). In a
<a class="reference internal" href="#term-classifier"><span class="xref std std-term">classifier</span></a> or <a class="reference internal" href="#term-regressor"><span class="xref std std-term">regressor</span></a>, this prediction is in the same
target space used in fitting (e.g. one of {‘red’, ‘amber’, ‘green’} if
the <code class="docutils literal notranslate"><span class="pre">y</span></code> in fitting consisted of these strings).  Despite this, even
when <code class="docutils literal notranslate"><span class="pre">y</span></code> passed to <a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a> is a list or other array-like, the
output of <code class="docutils literal notranslate"><span class="pre">predict</span></code> should always be an array or sparse matrix. In a
<a class="reference internal" href="#term-clusterer"><span class="xref std std-term">clusterer</span></a> or <a class="reference internal" href="#term-outlier-detector"><span class="xref std std-term">outlier detector</span></a> the prediction is an
integer.</p>
<p>If the estimator was not already <a class="reference internal" href="#term-fitted"><span class="xref std std-term">fitted</span></a>, calling this method
should raise a <a class="reference internal" href="modules/generated/sklearn.exceptions.NotFittedError.html#sklearn.exceptions.NotFittedError" title="sklearn.exceptions.NotFittedError"><code class="xref py py-class docutils literal notranslate"><span class="pre">exceptions.NotFittedError</span></code></a>.</p>
<p>Output conventions:</p>
<dl class="simple">
<dt>classifier</dt><dd><p>An array of shape <code class="docutils literal notranslate"><span class="pre">(n_samples,)</span></code> <code class="docutils literal notranslate"><span class="pre">(n_samples,</span> <span class="pre">n_outputs)</span></code>.
<a class="reference internal" href="#term-multilabel"><span class="xref std std-term">Multilabel</span></a> data may be represented as a sparse matrix if
a sparse matrix was used in fitting. Each element should be one
of the values in the classifier’s <a class="reference internal" href="#term-classes_"><span class="xref std std-term">classes_</span></a> attribute.</p>
</dd>
<dt>clusterer</dt><dd><p>An array of shape <code class="docutils literal notranslate"><span class="pre">(n_samples,)</span></code> where each value is from 0 to
<code class="docutils literal notranslate"><span class="pre">n_clusters</span> <span class="pre">-</span> <span class="pre">1</span></code> if the corresponding sample is clustered,
and -1 if the sample is not clustered, as in
<a class="reference internal" href="modules/generated/sklearn.cluster.dbscan.html#sklearn.cluster.dbscan" title="sklearn.cluster.dbscan"><code class="xref py py-func docutils literal notranslate"><span class="pre">cluster.dbscan</span></code></a>.</p>
</dd>
<dt>outlier detector</dt><dd><p>An array of shape <code class="docutils literal notranslate"><span class="pre">(n_samples,)</span></code> where each value is -1 for an
outlier and 1 otherwise.</p>
</dd>
<dt>regressor</dt><dd><p>A numeric array of shape <code class="docutils literal notranslate"><span class="pre">(n_samples,)</span></code>, usually float64.
Some regressors have extra options in their <code class="docutils literal notranslate"><span class="pre">predict</span></code> method,
allowing them to return standard deviation (<code class="docutils literal notranslate"><span class="pre">return_std=True</span></code>)
or covariance (<code class="docutils literal notranslate"><span class="pre">return_cov=True</span></code>) relative to the predicted
value.  In this case, the return value is a tuple of arrays
corresponding to (prediction mean, std, cov) as required.</p>
</dd>
</dl>
</dd>
<dt id="term-predict_log_proba"><code class="docutils literal notranslate"><span class="pre">predict_log_proba</span></code></dt><dd><p>The natural logarithm of the output of <a class="reference internal" href="#term-predict_proba"><span class="xref std std-term">predict_proba</span></a>, provided
to facilitate numerical stability.</p>
</dd>
<dt id="term-predict_proba"><code class="docutils literal notranslate"><span class="pre">predict_proba</span></code></dt><dd><p>A method in <a class="reference internal" href="#term-classifiers"><span class="xref std std-term">classifiers</span></a> and <a class="reference internal" href="#term-clusterers"><span class="xref std std-term">clusterers</span></a> that can
return probability estimates for each class/cluster.  Its input is
usually only some observed data, <a class="reference internal" href="#term-X"><span class="xref std std-term">X</span></a>.</p>
<p>If the estimator was not already <a class="reference internal" href="#term-fitted"><span class="xref std std-term">fitted</span></a>, calling this method
should raise a <a class="reference internal" href="modules/generated/sklearn.exceptions.NotFittedError.html#sklearn.exceptions.NotFittedError" title="sklearn.exceptions.NotFittedError"><code class="xref py py-class docutils literal notranslate"><span class="pre">exceptions.NotFittedError</span></code></a>.</p>
<p>Output conventions are like those for <a class="reference internal" href="#term-decision_function"><span class="xref std std-term">decision_function</span></a> except
in the <a class="reference internal" href="#term-binary"><span class="xref std std-term">binary</span></a> classification case, where one column is output
for each class (while <code class="docutils literal notranslate"><span class="pre">decision_function</span></code> outputs a 1d array). For
binary and multiclass predictions, each row should add to 1.</p>
<p>Like other methods, <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> should only be present when the
estimator can make probabilistic predictions (see <a class="reference internal" href="#term-duck-typing"><span class="xref std std-term">duck typing</span></a>).
This means that the presence of the method may depend on estimator
parameters (e.g. in <a class="reference internal" href="modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier" title="sklearn.linear_model.SGDClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">linear_model.SGDClassifier</span></code></a>) or training
data (e.g. in <a class="reference internal" href="modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV" title="sklearn.model_selection.GridSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">model_selection.GridSearchCV</span></code></a>) and may only
appear after fitting.</p>
</dd>
<dt id="term-score"><code class="docutils literal notranslate"><span class="pre">score</span></code></dt><dd><p>A method on an estimator, usually a <a class="reference internal" href="#term-predictor"><span class="xref std std-term">predictor</span></a>, which evaluates
its predictions on a given dataset, and returns a single numerical
score.  A greater return value should indicate better predictions;
accuracy is used for classifiers and R^2 for regressors by default.</p>
<p>If the estimator was not already <a class="reference internal" href="#term-fitted"><span class="xref std std-term">fitted</span></a>, calling this method
should raise a <a class="reference internal" href="modules/generated/sklearn.exceptions.NotFittedError.html#sklearn.exceptions.NotFittedError" title="sklearn.exceptions.NotFittedError"><code class="xref py py-class docutils literal notranslate"><span class="pre">exceptions.NotFittedError</span></code></a>.</p>
<p>Some estimators implement a custom, estimator-specific score function,
often the likelihood of the data under the model.</p>
</dd>
<dt id="term-score_samples"><code class="docutils literal notranslate"><span class="pre">score_samples</span></code></dt><dd><p>TODO</p>
<p>If the estimator was not already <a class="reference internal" href="#term-fitted"><span class="xref std std-term">fitted</span></a>, calling this method
should raise a <a class="reference internal" href="modules/generated/sklearn.exceptions.NotFittedError.html#sklearn.exceptions.NotFittedError" title="sklearn.exceptions.NotFittedError"><code class="xref py py-class docutils literal notranslate"><span class="pre">exceptions.NotFittedError</span></code></a>.</p>
</dd>
<dt id="term-set_params"><code class="docutils literal notranslate"><span class="pre">set_params</span></code></dt><dd><p>Available in any estimator, takes keyword arguments corresponding to
keys in <a class="reference internal" href="#term-get_params"><span class="xref std std-term">get_params</span></a>.  Each is provided a new value to assign
such that calling <code class="docutils literal notranslate"><span class="pre">get_params</span></code> after <code class="docutils literal notranslate"><span class="pre">set_params</span></code> will reflect the
changed <a class="reference internal" href="#term-parameters"><span class="xref std std-term">parameters</span></a>.  Most estimators use the implementation in
<a class="reference internal" href="modules/generated/sklearn.base.BaseEstimator.html#sklearn.base.BaseEstimator" title="sklearn.base.BaseEstimator"><code class="xref py py-class docutils literal notranslate"><span class="pre">base.BaseEstimator</span></code></a>, which handles nested parameters and
otherwise sets the parameter as an attribute on the estimator.
The method is overridden in <a class="reference internal" href="modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">pipeline.Pipeline</span></code></a> and related
estimators.</p>
</dd>
<dt id="term-split"><code class="docutils literal notranslate"><span class="pre">split</span></code></dt><dd><p>On a <a class="reference internal" href="#term-CV-splitter"><span class="xref std std-term">CV splitter</span></a> (not an estimator), this method accepts
parameters (<a class="reference internal" href="#term-X"><span class="xref std std-term">X</span></a>, <a class="reference internal" href="#term-y"><span class="xref std std-term">y</span></a>, <a class="reference internal" href="#term-groups"><span class="xref std std-term">groups</span></a>), where all may be
optional, and returns an iterator over <code class="docutils literal notranslate"><span class="pre">(train_idx,</span> <span class="pre">test_idx)</span></code>
pairs.  Each of {train,test}_idx is a 1d integer array, with values
from 0 from <code class="docutils literal notranslate"><span class="pre">X.shape[0]</span> <span class="pre">-</span> <span class="pre">1</span></code> of any length, such that no values
appear in both some <code class="docutils literal notranslate"><span class="pre">train_idx</span></code> and its corresponding <code class="docutils literal notranslate"><span class="pre">test_idx</span></code>.</p>
</dd>
<dt id="term-transform"><code class="docutils literal notranslate"><span class="pre">transform</span></code></dt><dd><p>In a <a class="reference internal" href="#term-transformer"><span class="xref std std-term">transformer</span></a>, transforms the input, usually only <a class="reference internal" href="#term-X"><span class="xref std std-term">X</span></a>,
into some transformed space (conventionally notated as <a class="reference internal" href="#term-Xt"><span class="xref std std-term">Xt</span></a>).
Output is an array or sparse matrix of length <a class="reference internal" href="#term-n_samples"><span class="xref std std-term">n_samples</span></a> and
with the number of columns fixed after <a class="reference internal" href="#term-fitting"><span class="xref std std-term">fitting</span></a>.</p>
<p>If the estimator was not already <a class="reference internal" href="#term-fitted"><span class="xref std std-term">fitted</span></a>, calling this method
should raise a <a class="reference internal" href="modules/generated/sklearn.exceptions.NotFittedError.html#sklearn.exceptions.NotFittedError" title="sklearn.exceptions.NotFittedError"><code class="xref py py-class docutils literal notranslate"><span class="pre">exceptions.NotFittedError</span></code></a>.</p>
</dd>
</dl>
</div>
<div class="section" id="parameters">
<span id="glossary-parameters"></span><h2>Parameters<a class="headerlink" href="#parameters" title="Permalink to this headline">¶</a></h2>
<p>These common parameter names, specifically used in estimator construction
(see concept <a class="reference internal" href="#term-parameter"><span class="xref std std-term">parameter</span></a>), sometimes also appear as parameters of
functions or non-estimator constructors.</p>
<dl class="glossary">
<dt id="term-class_weight"><code class="docutils literal notranslate"><span class="pre">class_weight</span></code></dt><dd><p>Used to specify sample weights when fitting classifiers as a function
of the <a class="reference internal" href="#term-target"><span class="xref std std-term">target</span></a> class.  Where <a class="reference internal" href="#term-sample_weight"><span class="xref std std-term">sample_weight</span></a> is also
supported and given, it is multiplied by the <code class="docutils literal notranslate"><span class="pre">class_weight</span></code>
contribution. Similarly, where <code class="docutils literal notranslate"><span class="pre">class_weight</span></code> is used in a
<a class="reference internal" href="#term-multioutput"><span class="xref std std-term">multioutput</span></a> (including <a class="reference internal" href="#term-multilabel"><span class="xref std std-term">multilabel</span></a>) tasks, the weights
are multiplied across outputs (i.e. columns of <code class="docutils literal notranslate"><span class="pre">y</span></code>).</p>
<p>By default, all samples have equal weight such that classes are
effectively weighted by their prevalence in the training data.
This could be achieved explicitly with <code class="docutils literal notranslate"><span class="pre">class_weight={label1:</span> <span class="pre">1,</span>
<span class="pre">label2:</span> <span class="pre">1,</span> <span class="pre">...}</span></code> for all class labels.</p>
<p>More generally, <code class="docutils literal notranslate"><span class="pre">class_weight</span></code> is specified as a dict mapping class
labels to weights (<code class="docutils literal notranslate"><span class="pre">{class_label:</span> <span class="pre">weight}</span></code>), such that each sample
of the named class is given that weight.</p>
<p><code class="docutils literal notranslate"><span class="pre">class_weight='balanced'</span></code> can be used to give all classes
equal weight by giving each sample a weight inversely related
to its class’s prevalence in the training data:
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">/</span> <span class="pre">(n_classes</span> <span class="pre">*</span> <span class="pre">np.bincount(y))</span></code>. Class weights will be
used differently depending on the algorithm: for linear models (such
as linear SVM or logistic regression), the class weights will alter the
loss function by weighting the loss of each sample by its class weight.
For tree-based algorithms, the class weights will be used for
reweighting the splitting criterion.
<strong>Note</strong> however that this rebalancing does not take the weight of
samples in each class into account.</p>
<p>For multioutput classification, a list of dicts is used to specify
weights for each output. For example, for four-class multilabel
classification weights should be <code class="docutils literal notranslate"><span class="pre">[{0:</span> <span class="pre">1,</span> <span class="pre">1:</span> <span class="pre">1},</span> <span class="pre">{0:</span> <span class="pre">1,</span> <span class="pre">1:</span> <span class="pre">5},</span> <span class="pre">{0:</span> <span class="pre">1,</span>
<span class="pre">1:</span> <span class="pre">1},</span> <span class="pre">{0:</span> <span class="pre">1,</span> <span class="pre">1:</span> <span class="pre">1}]</span></code> instead of <code class="docutils literal notranslate"><span class="pre">[{1:1},</span> <span class="pre">{2:5},</span> <span class="pre">{3:1},</span> <span class="pre">{4:1}]</span></code>.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">class_weight</span></code> parameter is validated and interpreted with
<code class="xref py py-func docutils literal notranslate"><span class="pre">utils.compute_class_weight</span></code>.</p>
</dd>
<dt id="term-cv"><code class="docutils literal notranslate"><span class="pre">cv</span></code></dt><dd><p>Determines a cross validation splitting strategy, as used in
cross-validation based routines. <code class="docutils literal notranslate"><span class="pre">cv</span></code> is also available in estimators
such as <a class="reference internal" href="modules/generated/sklearn.multioutput.ClassifierChain.html#sklearn.multioutput.ClassifierChain" title="sklearn.multioutput.ClassifierChain"><code class="xref py py-class docutils literal notranslate"><span class="pre">multioutput.ClassifierChain</span></code></a> or
<a class="reference internal" href="modules/generated/sklearn.calibration.CalibratedClassifierCV.html#sklearn.calibration.CalibratedClassifierCV" title="sklearn.calibration.CalibratedClassifierCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">calibration.CalibratedClassifierCV</span></code></a> which use the predictions
of one estimator as training data for another, to not overfit the
training supervision.</p>
<p>Possible inputs for <code class="docutils literal notranslate"><span class="pre">cv</span></code> are usually:</p>
<ul class="simple">
<li><p>An integer, specifying the number of folds in K-fold cross
validation. K-fold will be stratified over classes if the estimator
is a classifier (determined by <a class="reference internal" href="modules/generated/sklearn.base.is_classifier.html#sklearn.base.is_classifier" title="sklearn.base.is_classifier"><code class="xref py py-func docutils literal notranslate"><span class="pre">base.is_classifier</span></code></a>) and the
<a class="reference internal" href="#term-targets"><span class="xref std std-term">targets</span></a> may represent a binary or multiclass (but not
multioutput) classification problem (determined by
<a class="reference internal" href="modules/generated/sklearn.utils.multiclass.type_of_target.html#sklearn.utils.multiclass.type_of_target" title="sklearn.utils.multiclass.type_of_target"><code class="xref py py-func docutils literal notranslate"><span class="pre">utils.multiclass.type_of_target</span></code></a>).</p></li>
<li><p>A <a class="reference internal" href="#term-cross-validation-splitter"><span class="xref std std-term">cross-validation splitter</span></a> instance. Refer to the
<a class="reference internal" href="modules/cross_validation.html#cross-validation"><span class="std std-ref">User Guide</span></a> for splitters available
within Scikit-learn.</p></li>
<li><p>An iterable yielding train/test splits.</p></li>
</ul>
<p>With some exceptions (especially where not using cross validation at
all is an option), the default is 5-fold.</p>
<p><code class="docutils literal notranslate"><span class="pre">cv</span></code> values are validated and interpreted with <code class="xref py py-func docutils literal notranslate"><span class="pre">utils.check_cv</span></code>.</p>
</dd>
<dt id="term-kernel"><code class="docutils literal notranslate"><span class="pre">kernel</span></code></dt><dd><p>TODO</p>
</dd>
<dt id="term-max_iter"><code class="docutils literal notranslate"><span class="pre">max_iter</span></code></dt><dd><p>For estimators involving iterative optimization, this determines the
maximum number of iterations to be performed in <a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a>.  If
<code class="docutils literal notranslate"><span class="pre">max_iter</span></code> iterations are run without convergence, a
<a class="reference internal" href="modules/generated/sklearn.exceptions.ConvergenceWarning.html#sklearn.exceptions.ConvergenceWarning" title="sklearn.exceptions.ConvergenceWarning"><code class="xref py py-class docutils literal notranslate"><span class="pre">exceptions.ConvergenceWarning</span></code></a> should be raised.  Note that the
interpretation of “a single iteration” is inconsistent across
estimators: some, but not all, use it to mean a single epoch (i.e. a
pass over every sample in the data).</p>
<p>FIXME perhaps we should have some common tests about the relationship
between ConvergenceWarning and max_iter.</p>
</dd>
<dt id="term-memory"><code class="docutils literal notranslate"><span class="pre">memory</span></code></dt><dd><p>Some estimators make use of <a class="reference external" href="https://joblib.readthedocs.io/en/latest/generated/joblib.Memory.html#joblib.Memory" title="(in joblib v0.18.0.dev0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">joblib.Memory</span></code></a> to
store partial solutions during fitting. Thus when <code class="docutils literal notranslate"><span class="pre">fit</span></code> is called
again, those partial solutions have been memoized and can be reused.</p>
<p>A <code class="docutils literal notranslate"><span class="pre">memory</span></code> parameter can be specified as a string with a path to a
directory, or a <a class="reference external" href="https://joblib.readthedocs.io/en/latest/generated/joblib.Memory.html#joblib.Memory" title="(in joblib v0.18.0.dev0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">joblib.Memory</span></code></a> instance (or an object with a
similar interface, i.e. a <code class="docutils literal notranslate"><span class="pre">cache</span></code> method) can be used.</p>
<p><code class="docutils literal notranslate"><span class="pre">memory</span></code> values are validated and interpreted with
<a class="reference internal" href="modules/generated/sklearn.utils.validation.check_memory.html#sklearn.utils.validation.check_memory" title="sklearn.utils.validation.check_memory"><code class="xref py py-func docutils literal notranslate"><span class="pre">utils.validation.check_memory</span></code></a>.</p>
</dd>
<dt id="term-metric"><code class="docutils literal notranslate"><span class="pre">metric</span></code></dt><dd><p>As a parameter, this is the scheme for determining the distance between
two data points.  See <a class="reference internal" href="modules/generated/sklearn.metrics.pairwise_distances.html#sklearn.metrics.pairwise_distances" title="sklearn.metrics.pairwise_distances"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.pairwise_distances</span></code></a>.  In practice,
for some algorithms, an improper distance metric (one that does not
obey the triangle inequality, such as Cosine Distance) may be used.</p>
<p>XXX: hierarchical clustering uses <code class="docutils literal notranslate"><span class="pre">affinity</span></code> with this meaning.</p>
<p>We also use <em>metric</em> to refer to <a class="reference internal" href="#term-evaluation-metrics"><span class="xref std std-term">evaluation metrics</span></a>, but avoid
using this sense as a parameter name.</p>
</dd>
<dt id="term-n_components"><code class="docutils literal notranslate"><span class="pre">n_components</span></code></dt><dd><p>The number of features which a <a class="reference internal" href="#term-transformer"><span class="xref std std-term">transformer</span></a> should transform the
input into. See <a class="reference internal" href="#term-components_"><span class="xref std std-term">components_</span></a> for the special case of affine
projection.</p>
</dd>
<dt id="term-n_iter_no_change"><code class="docutils literal notranslate"><span class="pre">n_iter_no_change</span></code></dt><dd><p>Number of iterations with no improvement to wait before stopping the
iterative procedure. This is also known as a <em>patience</em> parameter. It
is typically used with <a class="reference internal" href="#term-early-stopping"><span class="xref std std-term">early stopping</span></a> to avoid stopping too
early.</p>
</dd>
<dt id="term-n_jobs"><code class="docutils literal notranslate"><span class="pre">n_jobs</span></code></dt><dd><p>This parameter is used to specify how many concurrent processes or
threads should be used for routines that are parallelized with
<a class="reference internal" href="#term-joblib"><span class="xref std std-term">joblib</span></a>.</p>
<p><code class="docutils literal notranslate"><span class="pre">n_jobs</span></code> is an integer, specifying the maximum number of concurrently
running workers. If 1 is given, no joblib parallelism is used at all,
which is useful for debugging. If set to -1, all CPUs are used. For
<code class="docutils literal notranslate"><span class="pre">n_jobs</span></code> below -1, (n_cpus + 1 + n_jobs) are used. For example with
<code class="docutils literal notranslate"><span class="pre">n_jobs=-2</span></code>, all CPUs but one are used.</p>
<p><code class="docutils literal notranslate"><span class="pre">n_jobs</span></code> is <code class="docutils literal notranslate"><span class="pre">None</span></code> by default, which means <em>unset</em>; it will
generally be interpreted as <code class="docutils literal notranslate"><span class="pre">n_jobs=1</span></code>, unless the current
<a class="reference external" href="https://joblib.readthedocs.io/en/latest/generated/joblib.Parallel.html#joblib.Parallel" title="(in joblib v0.18.0.dev0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">joblib.Parallel</span></code></a> backend context specifies otherwise.</p>
<p>For more details on the use of <code class="docutils literal notranslate"><span class="pre">joblib</span></code> and its interactions with
scikit-learn, please refer to our <a class="reference internal" href="modules/computing.html#parallelism"><span class="std std-ref">parallelism notes</span></a>.</p>
</dd>
<dt id="term-pos_label"><code class="docutils literal notranslate"><span class="pre">pos_label</span></code></dt><dd><p>Value with which positive labels must be encoded in binary
classification problems in which the positive class is not assumed.
This value is typically required to compute asymmetric evaluation
metrics such as precision and recall.</p>
</dd>
<dt id="term-random_state"><code class="docutils literal notranslate"><span class="pre">random_state</span></code></dt><dd><p>Whenever randomization is part of a Scikit-learn algorithm, a
<code class="docutils literal notranslate"><span class="pre">random_state</span></code> parameter may be provided to control the random number
generator used.  Note that the mere presence of <code class="docutils literal notranslate"><span class="pre">random_state</span></code> doesn’t
mean that randomization is always used, as it may be dependent on
another parameter, e.g. <code class="docutils literal notranslate"><span class="pre">shuffle</span></code>, being set.</p>
<p>The passed value will have an effect on the reproducibility of the
results returned by the function (<a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a>, <a class="reference internal" href="#term-split"><span class="xref std std-term">split</span></a>, or any
other function like <a class="reference internal" href="modules/generated/sklearn.cluster.k_means.html#sklearn.cluster.k_means" title="sklearn.cluster.k_means"><code class="xref py py-func docutils literal notranslate"><span class="pre">k_means</span></code></a>). <code class="docutils literal notranslate"><span class="pre">random_state</span></code>’s
value may be:</p>
<dl class="simple">
<dt>None (default)</dt><dd><p>Use the global random state instance from <a class="reference external" href="https://numpy.org/doc/stable/reference/random/index.html#module-numpy.random" title="(in NumPy v1.19)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">numpy.random</span></code></a>.
Calling the function multiple times will reuse
the same instance, and will produce different results.</p>
</dd>
<dt>An integer</dt><dd><p>Use a new random number generator seeded by the given integer.
Using an int will produce the same results across different calls.
However, it may be
worthwhile checking that your results are stable across a
number of different distinct random seeds. Popular integer
random seeds are 0 and <a class="reference external" href="https://en.wikipedia.org/wiki/Answer_to_the_Ultimate_Question_of_Life%2C_the_Universe%2C_and_Everything">42</a>.</p>
</dd>
<dt>A <a class="reference external" href="https://numpy.org/doc/stable/reference/random/legacy.html#numpy.random.RandomState" title="(in NumPy v1.19)"><code class="xref py py-class docutils literal notranslate"><span class="pre">numpy.random.RandomState</span></code></a> instance</dt><dd><p>Use the provided random state, only affecting other users
of that same random state instance. Calling the function
multiple times will reuse the same instance, and
will produce different results.</p>
</dd>
</dl>
<p><a class="reference internal" href="modules/generated/sklearn.utils.check_random_state.html#sklearn.utils.check_random_state" title="sklearn.utils.check_random_state"><code class="xref py py-func docutils literal notranslate"><span class="pre">utils.check_random_state</span></code></a> is used internally to validate the
input <code class="docutils literal notranslate"><span class="pre">random_state</span></code> and return a <a class="reference external" href="https://numpy.org/doc/stable/reference/random/legacy.html#numpy.random.RandomState" title="(in NumPy v1.19)"><code class="xref py py-class docutils literal notranslate"><span class="pre">RandomState</span></code></a>
instance.</p>
</dd>
<dt id="term-scoring"><code class="docutils literal notranslate"><span class="pre">scoring</span></code></dt><dd><p>Specifies the score function to be maximized (usually by <a class="reference internal" href="modules/cross_validation.html#cross-validation"><span class="std std-ref">cross
validation</span></a>), or – in some cases – multiple score
functions to be reported. The score function can be a string accepted
by <a class="reference internal" href="modules/generated/sklearn.metrics.get_scorer.html#sklearn.metrics.get_scorer" title="sklearn.metrics.get_scorer"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.get_scorer</span></code></a> or a callable <a class="reference internal" href="#term-scorer"><span class="xref std std-term">scorer</span></a>, not to be
confused with an <a class="reference internal" href="#term-evaluation-metric"><span class="xref std std-term">evaluation metric</span></a>, as the latter have a more
diverse API.  <code class="docutils literal notranslate"><span class="pre">scoring</span></code> may also be set to None, in which case the
estimator’s <a class="reference internal" href="#term-score"><span class="xref std std-term">score</span></a> method is used.  See <a class="reference internal" href="modules/model_evaluation.html#scoring-parameter"><span class="std std-ref">The scoring parameter: defining model evaluation rules</span></a>
in the User Guide.</p>
<p>Where multiple metrics can be evaluated, <code class="docutils literal notranslate"><span class="pre">scoring</span></code> may be given
either as a list of unique strings or a dictionary with names as keys
and callables as values. Note that this does <em>not</em> specify which score
function is to be maximized, and another parameter such as <code class="docutils literal notranslate"><span class="pre">refit</span></code>
maybe used for this purpose.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">scoring</span></code> parameter is validated and interpreted using
<a class="reference internal" href="modules/generated/sklearn.metrics.check_scoring.html#sklearn.metrics.check_scoring" title="sklearn.metrics.check_scoring"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.check_scoring</span></code></a>.</p>
</dd>
<dt id="term-verbose"><code class="docutils literal notranslate"><span class="pre">verbose</span></code></dt><dd><p>Logging is not handled very consistently in Scikit-learn at present,
but when it is provided as an option, the <code class="docutils literal notranslate"><span class="pre">verbose</span></code> parameter is
usually available to choose no logging (set to False). Any True value
should enable some logging, but larger integers (e.g. above 10) may be
needed for full verbosity.  Verbose logs are usually printed to
Standard Output.
Estimators should not produce any output on Standard Output with the
default <code class="docutils literal notranslate"><span class="pre">verbose</span></code> setting.</p>
</dd>
<dt id="term-warm_start"><code class="docutils literal notranslate"><span class="pre">warm_start</span></code></dt><dd><p>When fitting an estimator repeatedly on the same dataset, but for
multiple parameter values (such as to find the value maximizing
performance as in <a class="reference internal" href="modules/grid_search.html#grid-search"><span class="std std-ref">grid search</span></a>), it may be possible
to reuse aspects of the model learned from the previous parameter value,
saving time.  When <code class="docutils literal notranslate"><span class="pre">warm_start</span></code> is true, the existing <a class="reference internal" href="#term-fitted"><span class="xref std std-term">fitted</span></a>
model <a class="reference internal" href="#term-attributes"><span class="xref std std-term">attributes</span></a> are used to initialize the new model
in a subsequent call to <a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a>.</p>
<p>Note that this is only applicable for some models and some
parameters, and even some orders of parameter values. For example,
<code class="docutils literal notranslate"><span class="pre">warm_start</span></code> may be used when building random forests to add more
trees to the forest (increasing <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code>) but not to reduce
their number.</p>
<p><a class="reference internal" href="#term-partial_fit"><span class="xref std std-term">partial_fit</span></a> also retains the model between calls, but differs:
with <code class="docutils literal notranslate"><span class="pre">warm_start</span></code> the parameters change and the data is
(more-or-less) constant across calls to <code class="docutils literal notranslate"><span class="pre">fit</span></code>; with <code class="docutils literal notranslate"><span class="pre">partial_fit</span></code>,
the mini-batch of data changes and model parameters stay fixed.</p>
<p>There are cases where you want to use <code class="docutils literal notranslate"><span class="pre">warm_start</span></code> to fit on
different, but closely related data. For example, one may initially fit
to a subset of the data, then fine-tune the parameter search on the
full dataset. For classification, all data in a sequence of
<code class="docutils literal notranslate"><span class="pre">warm_start</span></code> calls to <code class="docutils literal notranslate"><span class="pre">fit</span></code> must include samples from each class.</p>
</dd>
</dl>
</div>
<div class="section" id="attributes">
<span id="glossary-attributes"></span><h2>Attributes<a class="headerlink" href="#attributes" title="Permalink to this headline">¶</a></h2>
<p>See concept <a class="reference internal" href="#term-attribute"><span class="xref std std-term">attribute</span></a>.</p>
<dl class="glossary">
<dt id="term-classes_"><code class="docutils literal notranslate"><span class="pre">classes_</span></code></dt><dd><p>A list of class labels known to the <a class="reference internal" href="#term-classifier"><span class="xref std std-term">classifier</span></a>, mapping each
label to a numerical index used in the model representation our output.
For instance, the array output from <a class="reference internal" href="#term-predict_proba"><span class="xref std std-term">predict_proba</span></a> has columns
aligned with <code class="docutils literal notranslate"><span class="pre">classes_</span></code>. For <a class="reference internal" href="#term-multi-output"><span class="xref std std-term">multi-output</span></a> classifiers,
<code class="docutils literal notranslate"><span class="pre">classes_</span></code> should be a list of lists, with one class listing for
each output.  For each output, the classes should be sorted
(numerically, or lexicographically for strings).</p>
<p><code class="docutils literal notranslate"><span class="pre">classes_</span></code> and the mapping to indices is often managed with
<a class="reference internal" href="modules/generated/sklearn.preprocessing.LabelEncoder.html#sklearn.preprocessing.LabelEncoder" title="sklearn.preprocessing.LabelEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">preprocessing.LabelEncoder</span></code></a>.</p>
</dd>
<dt id="term-components_"><code class="docutils literal notranslate"><span class="pre">components_</span></code></dt><dd><p>An affine transformation matrix of shape <code class="docutils literal notranslate"><span class="pre">(n_components,</span> <span class="pre">n_features)</span></code>
used in many linear <a class="reference internal" href="#term-transformers"><span class="xref std std-term">transformers</span></a> where <a class="reference internal" href="#term-n_components"><span class="xref std std-term">n_components</span></a> is
the number of output features and <a class="reference internal" href="#term-n_features"><span class="xref std std-term">n_features</span></a> is the number of
input features.</p>
<p>See also <a class="reference internal" href="#term-components_"><span class="xref std std-term">components_</span></a> which is a similar attribute for linear
predictors.</p>
</dd>
<dt id="term-coef_"><code class="docutils literal notranslate"><span class="pre">coef_</span></code></dt><dd><p>The weight/coefficient matrix of a generalised linear model
<a class="reference internal" href="#term-predictor"><span class="xref std std-term">predictor</span></a>, of shape <code class="docutils literal notranslate"><span class="pre">(n_features,)</span></code> for binary classification
and single-output regression, <code class="docutils literal notranslate"><span class="pre">(n_classes,</span> <span class="pre">n_features)</span></code> for
multiclass classification and <code class="docutils literal notranslate"><span class="pre">(n_targets,</span> <span class="pre">n_features)</span></code> for
multi-output regression. Note this does not include the intercept
(or bias) term, which is stored in <code class="docutils literal notranslate"><span class="pre">intercept_</span></code>.</p>
<p>When available, <code class="docutils literal notranslate"><span class="pre">feature_importances_</span></code> is not usually provided as
well, but can be calculated as the  norm of each feature’s entry in
<code class="docutils literal notranslate"><span class="pre">coef_</span></code>.</p>
<p>See also <a class="reference internal" href="#term-components_"><span class="xref std std-term">components_</span></a> which is a similar attribute for linear
transformers.</p>
</dd>
<dt id="term-embedding_"><code class="docutils literal notranslate"><span class="pre">embedding_</span></code></dt><dd><p>An embedding of the training data in <a class="reference internal" href="modules/manifold.html#manifold"><span class="std std-ref">manifold learning</span></a> estimators, with shape <code class="docutils literal notranslate"><span class="pre">(n_samples,</span> <span class="pre">n_components)</span></code>,
identical to the output of <a class="reference internal" href="#term-fit_transform"><span class="xref std std-term">fit_transform</span></a>.  See also
<a class="reference internal" href="#term-labels_"><span class="xref std std-term">labels_</span></a>.</p>
</dd>
<dt id="term-n_iter_"><code class="docutils literal notranslate"><span class="pre">n_iter_</span></code></dt><dd><p>The number of iterations actually performed when fitting an iterative
estimator that may stop upon convergence. See also <a class="reference internal" href="#term-max_iter"><span class="xref std std-term">max_iter</span></a>.</p>
</dd>
<dt id="term-feature_importances_"><code class="docutils literal notranslate"><span class="pre">feature_importances_</span></code></dt><dd><p>A vector of shape <code class="docutils literal notranslate"><span class="pre">(n_features,)</span></code> available in some
<a class="reference internal" href="#term-predictors"><span class="xref std std-term">predictors</span></a> to provide a relative measure of the importance of
each feature in the predictions of the model.</p>
</dd>
<dt id="term-labels_"><code class="docutils literal notranslate"><span class="pre">labels_</span></code></dt><dd><p>A vector containing a cluster label for each sample of the training
data in <a class="reference internal" href="#term-clusterers"><span class="xref std std-term">clusterers</span></a>, identical to the output of
<a class="reference internal" href="#term-fit_predict"><span class="xref std std-term">fit_predict</span></a>.  See also <a class="reference internal" href="#term-embedding_"><span class="xref std std-term">embedding_</span></a>.</p>
</dd>
</dl>
</div>
<div class="section" id="data-and-sample-properties">
<span id="glossary-sample-props"></span><h2>Data and sample properties<a class="headerlink" href="#data-and-sample-properties" title="Permalink to this headline">¶</a></h2>
<p>See concept <a class="reference internal" href="#term-sample-property"><span class="xref std std-term">sample property</span></a>.</p>
<dl class="glossary">
<dt id="term-groups"><code class="docutils literal notranslate"><span class="pre">groups</span></code></dt><dd><p>Used in cross-validation routines to identify samples that are correlated.
Each value is an identifier such that, in a supporting
<a class="reference internal" href="#term-CV-splitter"><span class="xref std std-term">CV splitter</span></a>, samples from some <code class="docutils literal notranslate"><span class="pre">groups</span></code> value may not
appear in both a training set and its corresponding test set.
See <a class="reference internal" href="modules/cross_validation.html#group-cv"><span class="std std-ref">Cross-validation iterators for grouped data.</span></a>.</p>
</dd>
<dt id="term-sample_weight"><code class="docutils literal notranslate"><span class="pre">sample_weight</span></code></dt><dd><p>A relative weight for each sample.  Intuitively, if all weights are
integers, a weighted model or score should be equivalent to that
calculated when repeating the sample the number of times specified in
the weight.  Weights may be specified as floats, so that sample weights
are usually equivalent up to a constant positive scaling factor.</p>
<p>FIXME  Is this interpretation always the case in practice? We have no
common tests.</p>
<p>Some estimators, such as decision trees, support negative weights.
FIXME: This feature or its absence may not be tested or documented in
many estimators.</p>
<p>This is not entirely the case where other parameters of the model
consider the number of samples in a region, as with <code class="docutils literal notranslate"><span class="pre">min_samples</span></code> in
<a class="reference internal" href="modules/generated/sklearn.cluster.DBSCAN.html#sklearn.cluster.DBSCAN" title="sklearn.cluster.DBSCAN"><code class="xref py py-class docutils literal notranslate"><span class="pre">cluster.DBSCAN</span></code></a>.  In this case, a count of samples becomes
to a sum of their weights.</p>
<p>In classification, sample weights can also be specified as a function
of class with the <a class="reference internal" href="#term-class_weight"><span class="xref std std-term">class_weight</span></a> estimator <a class="reference internal" href="#term-parameter"><span class="xref std std-term">parameter</span></a>.</p>
</dd>
<dt id="term-X"><code class="docutils literal notranslate"><span class="pre">X</span></code></dt><dd><p>Denotes data that is observed at training and prediction time, used as
independent variables in learning.  The notation is uppercase to denote
that it is ordinarily a matrix (see <a class="reference internal" href="#term-rectangular"><span class="xref std std-term">rectangular</span></a>).
When a matrix, each sample may be represented by a <a class="reference internal" href="#term-feature"><span class="xref std std-term">feature</span></a>
vector, or a vector of <a class="reference internal" href="#term-precomputed"><span class="xref std std-term">precomputed</span></a> (dis)similarity with each
training sample. <code class="docutils literal notranslate"><span class="pre">X</span></code> may also not be a matrix, and may require a
<a class="reference internal" href="#term-feature-extractor"><span class="xref std std-term">feature extractor</span></a> or a <a class="reference internal" href="#term-pairwise-metric"><span class="xref std std-term">pairwise metric</span></a> to turn it into
one before learning a model.</p>
</dd>
<dt id="term-Xt"><code class="docutils literal notranslate"><span class="pre">Xt</span></code></dt><dd><p>Shorthand for “transformed <a class="reference internal" href="#term-X"><span class="xref std std-term">X</span></a>”.</p>
</dd>
<dt id="term-y"><code class="docutils literal notranslate"><span class="pre">y</span></code></dt><dt id="term-Y"><code class="docutils literal notranslate"><span class="pre">Y</span></code></dt><dd><p>Denotes data that may be observed at training time as the dependent
variable in learning, but which is unavailable at prediction time, and
is usually the <a class="reference internal" href="#term-target"><span class="xref std std-term">target</span></a> of prediction.  The notation may be
uppercase to denote that it is a matrix, representing
<a class="reference internal" href="#term-multi-output"><span class="xref std std-term">multi-output</span></a> targets, for instance; but usually we use <code class="docutils literal notranslate"><span class="pre">y</span></code>
and sometimes do so even when multiple outputs are assumed.</p>
</dd>
</dl>
</div>
</div>


      </div>
    <div class="container">
      <footer class="sk-content-footer">
            &copy; 2007 - 2020, scikit-learn developers (BSD License).
          <a href="_sources/glossary.rst.txt" rel="nofollow">Show this page source</a>
      </footer>
    </div>
  </div>
</div>
<script src="_static/js/vendor/bootstrap.min.js"></script>

<script>
    window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
    ga('create', 'UA-22606712-2', 'auto');
    ga('set', 'anonymizeIp', true);
    ga('send', 'pageview');
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


<script>
$(document).ready(function() {
    /* Add a [>>>] button on the top-right corner of code samples to hide
     * the >>> and ... prompts and the output and thus make the code
     * copyable. */
    var div = $('.highlight-python .highlight,' +
                '.highlight-python3 .highlight,' +
                '.highlight-pycon .highlight,' +
		'.highlight-default .highlight')
    var pre = div.find('pre');

    // get the styles from the current theme
    pre.parent().parent().css('position', 'relative');
    var hide_text = 'Hide prompts and outputs';
    var show_text = 'Show prompts and outputs';

    // create and add the button to all the code blocks that contain >>>
    div.each(function(index) {
        var jthis = $(this);
        if (jthis.find('.gp').length > 0) {
            var button = $('<span class="copybutton">&gt;&gt;&gt;</span>');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
            jthis.prepend(button);
        }
        // tracebacks (.gt) contain bare text elements that need to be
        // wrapped in a span to work with .nextUntil() (see later)
        jthis.find('pre:has(.gt)').contents().filter(function() {
            return ((this.nodeType == 3) && (this.data.trim().length > 0));
        }).wrap('<span>');
    });

    // define the behavior of the button when it's clicked
    $('.copybutton').click(function(e){
        e.preventDefault();
        var button = $(this);
        if (button.data('hidden') === 'false') {
            // hide the code output
            button.parent().find('.go, .gp, .gt').hide();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'hidden');
            button.css('text-decoration', 'line-through');
            button.attr('title', show_text);
            button.data('hidden', 'true');
        } else {
            // show the code output
            button.parent().find('.go, .gp, .gt').show();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'visible');
            button.css('text-decoration', 'none');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
        }
    });

	/*** Add permalink buttons next to glossary terms ***/
	$('dl.glossary > dt[id]').append(function() {
		return ('<a class="headerlink" href="#' +
			    this.getAttribute('id') +
			    '" title="Permalink to this term">¶</a>');
	});
  /*** Hide navbar when scrolling down ***/
  // Returns true when headerlink target matches hash in url
  (function() {
    hashTargetOnTop = function() {
        var hash = window.location.hash;
        if ( hash.length < 2 ) { return false; }

        var target = document.getElementById( hash.slice(1) );
        if ( target === null ) { return false; }

        var top = target.getBoundingClientRect().top;
        return (top < 2) && (top > -2);
    };

    // Hide navbar on load if hash target is on top
    var navBar = document.getElementById("navbar");
    var navBarToggler = document.getElementById("sk-navbar-toggler");
    var navBarHeightHidden = "-" + navBar.getBoundingClientRect().height + "px";
    var $window = $(window);

    hideNavBar = function() {
        navBar.style.top = navBarHeightHidden;
    };

    showNavBar = function() {
        navBar.style.top = "0";
    }

    if (hashTargetOnTop()) {
        hideNavBar()
    }

    var prevScrollpos = window.pageYOffset;
    hideOnScroll = function(lastScrollTop) {
        if (($window.width() < 768) && (navBarToggler.getAttribute("aria-expanded") === 'true')) {
            return;
        }
        if (lastScrollTop > 2 && (prevScrollpos <= lastScrollTop) || hashTargetOnTop()){
            hideNavBar()
        } else {
            showNavBar()
        }
        prevScrollpos = lastScrollTop;
    };

    /*** high performance scroll event listener***/
    var raf = window.requestAnimationFrame ||
        window.webkitRequestAnimationFrame ||
        window.mozRequestAnimationFrame ||
        window.msRequestAnimationFrame ||
        window.oRequestAnimationFrame;
    var lastScrollTop = $window.scrollTop();

    if (raf) {
        loop();
    }

    function loop() {
        var scrollTop = $window.scrollTop();
        if (lastScrollTop === scrollTop) {
            raf(loop);
            return;
        } else {
            lastScrollTop = scrollTop;
            hideOnScroll(lastScrollTop);
            raf(loop);
        }
    }
  })();
});

</script>
    
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    
</body>
</html>