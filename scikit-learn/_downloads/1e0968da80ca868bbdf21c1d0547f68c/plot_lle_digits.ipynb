{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Manifold learning on handwritten digits: Locally Linear Embedding, Isomap...\n\nAn illustration of various embeddings on the digits dataset.\n\nThe RandomTreesEmbedding, from the :mod:`sklearn.ensemble` module, is not\ntechnically a manifold embedding method, as it learn a high-dimensional\nrepresentation on which we apply a dimensionality reduction method.\nHowever, it is often useful to cast a dataset into a representation in\nwhich the classes are linearly-separable.\n\nt-SNE will be initialized with the embedding that is generated by PCA in\nthis example, which is not the default setting. It ensures global stability\nof the embedding, i.e., the embedding does not depend on random\ninitialization.\n\nLinear Discriminant Analysis, from the :mod:`sklearn.discriminant_analysis`\nmodule, and Neighborhood Components Analysis, from the :mod:`sklearn.neighbors`\nmodule, are supervised dimensionality reduction method, i.e. they make use of\nthe provided labels, contrary to other methods.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Fabian Pedregosa <fabian.pedregosa@inria.fr>\n#          Olivier Grisel <olivier.grisel@ensta.org>\n#          Mathieu Blondel <mathieu@mblondel.org>\n#          Gael Varoquaux\n# License: BSD 3 clause (C) INRIA 2011\n\nfrom time import time\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import offsetbox\nfrom sklearn import (manifold, datasets, decomposition, ensemble,\n                     discriminant_analysis, random_projection, neighbors)\nprint(__doc__)\n\ndigits = datasets.load_digits(n_class=6)\nX = digits.data\ny = digits.target\nn_samples, n_features = X.shape\nn_neighbors = 30\n\n\n# ----------------------------------------------------------------------\n# Scale and visualize the embedding vectors\ndef plot_embedding(X, title=None):\n    x_min, x_max = np.min(X, 0), np.max(X, 0)\n    X = (X - x_min) / (x_max - x_min)\n\n    plt.figure()\n    ax = plt.subplot(111)\n    for i in range(X.shape[0]):\n        plt.text(X[i, 0], X[i, 1], str(y[i]),\n                 color=plt.cm.Set1(y[i] / 10.),\n                 fontdict={'weight': 'bold', 'size': 9})\n\n    if hasattr(offsetbox, 'AnnotationBbox'):\n        # only print thumbnails with matplotlib > 1.0\n        shown_images = np.array([[1., 1.]])  # just something big\n        for i in range(X.shape[0]):\n            dist = np.sum((X[i] - shown_images) ** 2, 1)\n            if np.min(dist) < 4e-3:\n                # don't show points that are too close\n                continue\n            shown_images = np.r_[shown_images, [X[i]]]\n            imagebox = offsetbox.AnnotationBbox(\n                offsetbox.OffsetImage(digits.images[i], cmap=plt.cm.gray_r),\n                X[i])\n            ax.add_artist(imagebox)\n    plt.xticks([]), plt.yticks([])\n    if title is not None:\n        plt.title(title)\n\n\n# ----------------------------------------------------------------------\n# Plot images of the digits\nn_img_per_row = 20\nimg = np.zeros((10 * n_img_per_row, 10 * n_img_per_row))\nfor i in range(n_img_per_row):\n    ix = 10 * i + 1\n    for j in range(n_img_per_row):\n        iy = 10 * j + 1\n        img[ix:ix + 8, iy:iy + 8] = X[i * n_img_per_row + j].reshape((8, 8))\n\nplt.imshow(img, cmap=plt.cm.binary)\nplt.xticks([])\nplt.yticks([])\nplt.title('A selection from the 64-dimensional digits dataset')\n\n\n# ----------------------------------------------------------------------\n# Random 2D projection using a random unitary matrix\nprint(\"Computing random projection\")\nrp = random_projection.SparseRandomProjection(n_components=2, random_state=42)\nX_projected = rp.fit_transform(X)\nplot_embedding(X_projected, \"Random Projection of the digits\")\n\n\n# ----------------------------------------------------------------------\n# Projection on to the first 2 principal components\n\nprint(\"Computing PCA projection\")\nt0 = time()\nX_pca = decomposition.TruncatedSVD(n_components=2).fit_transform(X)\nplot_embedding(X_pca,\n               \"Principal Components projection of the digits (time %.2fs)\" %\n               (time() - t0))\n\n# ----------------------------------------------------------------------\n# Projection on to the first 2 linear discriminant components\n\nprint(\"Computing Linear Discriminant Analysis projection\")\nX2 = X.copy()\nX2.flat[::X.shape[1] + 1] += 0.01  # Make X invertible\nt0 = time()\nX_lda = discriminant_analysis.LinearDiscriminantAnalysis(n_components=2\n                                                         ).fit_transform(X2, y)\nplot_embedding(X_lda,\n               \"Linear Discriminant projection of the digits (time %.2fs)\" %\n               (time() - t0))\n\n\n# ----------------------------------------------------------------------\n# Isomap projection of the digits dataset\nprint(\"Computing Isomap projection\")\nt0 = time()\nX_iso = manifold.Isomap(n_neighbors=n_neighbors, n_components=2\n                        ).fit_transform(X)\nprint(\"Done.\")\nplot_embedding(X_iso,\n               \"Isomap projection of the digits (time %.2fs)\" %\n               (time() - t0))\n\n\n# ----------------------------------------------------------------------\n# Locally linear embedding of the digits dataset\nprint(\"Computing LLE embedding\")\nclf = manifold.LocallyLinearEmbedding(n_neighbors=n_neighbors, n_components=2,\n                                      method='standard')\nt0 = time()\nX_lle = clf.fit_transform(X)\nprint(\"Done. Reconstruction error: %g\" % clf.reconstruction_error_)\nplot_embedding(X_lle,\n               \"Locally Linear Embedding of the digits (time %.2fs)\" %\n               (time() - t0))\n\n\n# ----------------------------------------------------------------------\n# Modified Locally linear embedding of the digits dataset\nprint(\"Computing modified LLE embedding\")\nclf = manifold.LocallyLinearEmbedding(n_neighbors=n_neighbors, n_components=2,\n                                      method='modified')\nt0 = time()\nX_mlle = clf.fit_transform(X)\nprint(\"Done. Reconstruction error: %g\" % clf.reconstruction_error_)\nplot_embedding(X_mlle,\n               \"Modified Locally Linear Embedding of the digits (time %.2fs)\" %\n               (time() - t0))\n\n\n# ----------------------------------------------------------------------\n# HLLE embedding of the digits dataset\nprint(\"Computing Hessian LLE embedding\")\nclf = manifold.LocallyLinearEmbedding(n_neighbors=n_neighbors, n_components=2,\n                                      method='hessian')\nt0 = time()\nX_hlle = clf.fit_transform(X)\nprint(\"Done. Reconstruction error: %g\" % clf.reconstruction_error_)\nplot_embedding(X_hlle,\n               \"Hessian Locally Linear Embedding of the digits (time %.2fs)\" %\n               (time() - t0))\n\n\n# ----------------------------------------------------------------------\n# LTSA embedding of the digits dataset\nprint(\"Computing LTSA embedding\")\nclf = manifold.LocallyLinearEmbedding(n_neighbors=n_neighbors, n_components=2,\n                                      method='ltsa')\nt0 = time()\nX_ltsa = clf.fit_transform(X)\nprint(\"Done. Reconstruction error: %g\" % clf.reconstruction_error_)\nplot_embedding(X_ltsa,\n               \"Local Tangent Space Alignment of the digits (time %.2fs)\" %\n               (time() - t0))\n\n# ----------------------------------------------------------------------\n# MDS  embedding of the digits dataset\nprint(\"Computing MDS embedding\")\nclf = manifold.MDS(n_components=2, n_init=1, max_iter=100)\nt0 = time()\nX_mds = clf.fit_transform(X)\nprint(\"Done. Stress: %f\" % clf.stress_)\nplot_embedding(X_mds,\n               \"MDS embedding of the digits (time %.2fs)\" %\n               (time() - t0))\n\n# ----------------------------------------------------------------------\n# Random Trees embedding of the digits dataset\nprint(\"Computing Totally Random Trees embedding\")\nhasher = ensemble.RandomTreesEmbedding(n_estimators=200, random_state=0,\n                                       max_depth=5)\nt0 = time()\nX_transformed = hasher.fit_transform(X)\npca = decomposition.TruncatedSVD(n_components=2)\nX_reduced = pca.fit_transform(X_transformed)\n\nplot_embedding(X_reduced,\n               \"Random forest embedding of the digits (time %.2fs)\" %\n               (time() - t0))\n\n# ----------------------------------------------------------------------\n# Spectral embedding of the digits dataset\nprint(\"Computing Spectral embedding\")\nembedder = manifold.SpectralEmbedding(n_components=2, random_state=0,\n                                      eigen_solver=\"arpack\")\nt0 = time()\nX_se = embedder.fit_transform(X)\n\nplot_embedding(X_se,\n               \"Spectral embedding of the digits (time %.2fs)\" %\n               (time() - t0))\n\n# ----------------------------------------------------------------------\n# t-SNE embedding of the digits dataset\nprint(\"Computing t-SNE embedding\")\ntsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\nt0 = time()\nX_tsne = tsne.fit_transform(X)\n\nplot_embedding(X_tsne,\n               \"t-SNE embedding of the digits (time %.2fs)\" %\n               (time() - t0))\n\n# ----------------------------------------------------------------------\n# NCA projection of the digits dataset\nprint(\"Computing NCA projection\")\nnca = neighbors.NeighborhoodComponentsAnalysis(init='random',\n                                               n_components=2, random_state=0)\nt0 = time()\nX_nca = nca.fit_transform(X, y)\n\nplot_embedding(X_nca,\n               \"NCA embedding of the digits (time %.2fs)\" %\n               (time() - t0))\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}