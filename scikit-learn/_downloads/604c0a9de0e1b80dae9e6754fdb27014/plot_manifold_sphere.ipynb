{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Manifold Learning methods on a severed sphere\n\nAn application of the different `manifold` techniques\non a spherical data-set. Here one can see the use of\ndimensionality reduction in order to gain some intuition\nregarding the manifold learning methods. Regarding the dataset,\nthe poles are cut from the sphere, as well as a thin slice down its\nside. This enables the manifold learning techniques to\n'spread it open' whilst projecting it onto two dimensions.\n\nFor a similar example, where the methods are applied to the\nS-curve dataset, see `sphx_glr_auto_examples_manifold_plot_compare_methods.py`\n\nNote that the purpose of the `MDS <multidimensional_scaling>` is\nto find a low-dimensional representation of the data (here 2D) in\nwhich the distances respect well the distances in the original\nhigh-dimensional space, unlike other manifold-learning algorithms,\nit does not seeks an isotropic representation of the data in\nthe low-dimensional space. Here the manifold problem matches fairly\nthat of representing a flat map of the Earth, as with\n`map projection <https://en.wikipedia.org/wiki/Map_projection>`_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Jaques Grobler <jaques.grobler@inria.fr>\n# License: BSD 3 clause\n\nprint(__doc__)\n\nfrom time import time\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib.ticker import NullFormatter\n\nfrom sklearn import manifold\nfrom sklearn.utils import check_random_state\n\n# Next line to silence pyflakes.\nAxes3D\n\n# Variables for manifold learning.\nn_neighbors = 10\nn_samples = 1000\n\n# Create our sphere.\nrandom_state = check_random_state(0)\np = random_state.rand(n_samples) * (2 * np.pi - 0.55)\nt = random_state.rand(n_samples) * np.pi\n\n# Sever the poles from the sphere.\nindices = ((t < (np.pi - (np.pi / 8))) & (t > ((np.pi / 8))))\ncolors = p[indices]\nx, y, z = np.sin(t[indices]) * np.cos(p[indices]), \\\n    np.sin(t[indices]) * np.sin(p[indices]), \\\n    np.cos(t[indices])\n\n# Plot our dataset.\nfig = plt.figure(figsize=(15, 8))\nplt.suptitle(\"Manifold Learning with %i points, %i neighbors\"\n             % (1000, n_neighbors), fontsize=14)\n\nax = fig.add_subplot(251, projection='3d')\nax.scatter(x, y, z, c=p[indices], cmap=plt.cm.rainbow)\nax.view_init(40, -10)\n\nsphere_data = np.array([x, y, z]).T\n\n# Perform Locally Linear Embedding Manifold learning\nmethods = ['standard', 'ltsa', 'hessian', 'modified']\nlabels = ['LLE', 'LTSA', 'Hessian LLE', 'Modified LLE']\n\nfor i, method in enumerate(methods):\n    t0 = time()\n    trans_data = manifold\\\n        .LocallyLinearEmbedding(n_neighbors, 2,\n                                method=method).fit_transform(sphere_data).T\n    t1 = time()\n    print(\"%s: %.2g sec\" % (methods[i], t1 - t0))\n\n    ax = fig.add_subplot(252 + i)\n    plt.scatter(trans_data[0], trans_data[1], c=colors, cmap=plt.cm.rainbow)\n    plt.title(\"%s (%.2g sec)\" % (labels[i], t1 - t0))\n    ax.xaxis.set_major_formatter(NullFormatter())\n    ax.yaxis.set_major_formatter(NullFormatter())\n    plt.axis('tight')\n\n# Perform Isomap Manifold learning.\nt0 = time()\ntrans_data = manifold.Isomap(n_neighbors, n_components=2)\\\n    .fit_transform(sphere_data).T\nt1 = time()\nprint(\"%s: %.2g sec\" % ('ISO', t1 - t0))\n\nax = fig.add_subplot(257)\nplt.scatter(trans_data[0], trans_data[1], c=colors, cmap=plt.cm.rainbow)\nplt.title(\"%s (%.2g sec)\" % ('Isomap', t1 - t0))\nax.xaxis.set_major_formatter(NullFormatter())\nax.yaxis.set_major_formatter(NullFormatter())\nplt.axis('tight')\n\n# Perform Multi-dimensional scaling.\nt0 = time()\nmds = manifold.MDS(2, max_iter=100, n_init=1)\ntrans_data = mds.fit_transform(sphere_data).T\nt1 = time()\nprint(\"MDS: %.2g sec\" % (t1 - t0))\n\nax = fig.add_subplot(258)\nplt.scatter(trans_data[0], trans_data[1], c=colors, cmap=plt.cm.rainbow)\nplt.title(\"MDS (%.2g sec)\" % (t1 - t0))\nax.xaxis.set_major_formatter(NullFormatter())\nax.yaxis.set_major_formatter(NullFormatter())\nplt.axis('tight')\n\n# Perform Spectral Embedding.\nt0 = time()\nse = manifold.SpectralEmbedding(n_components=2,\n                                n_neighbors=n_neighbors)\ntrans_data = se.fit_transform(sphere_data).T\nt1 = time()\nprint(\"Spectral Embedding: %.2g sec\" % (t1 - t0))\n\nax = fig.add_subplot(259)\nplt.scatter(trans_data[0], trans_data[1], c=colors, cmap=plt.cm.rainbow)\nplt.title(\"Spectral Embedding (%.2g sec)\" % (t1 - t0))\nax.xaxis.set_major_formatter(NullFormatter())\nax.yaxis.set_major_formatter(NullFormatter())\nplt.axis('tight')\n\n# Perform t-distributed stochastic neighbor embedding.\nt0 = time()\ntsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\ntrans_data = tsne.fit_transform(sphere_data).T\nt1 = time()\nprint(\"t-SNE: %.2g sec\" % (t1 - t0))\n\nax = fig.add_subplot(2, 5, 10)\nplt.scatter(trans_data[0], trans_data[1], c=colors, cmap=plt.cm.rainbow)\nplt.title(\"t-SNE (%.2g sec)\" % (t1 - t0))\nax.xaxis.set_major_formatter(NullFormatter())\nax.yaxis.set_major_formatter(NullFormatter())\nplt.axis('tight')\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}